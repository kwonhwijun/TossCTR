{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FESeq Model Training on TossCTR Dataset\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì€ TossCTR ë°ì´í„°ì…‹ì—ì„œ FESeq ëª¨ë¸ì„ í›ˆë ¨í•˜ê¸° ìœ„í•œ Colab í™˜ê²½ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
        "\n",
        "## ðŸ“‹ ì‹¤í–‰ ìˆœì„œ\n",
        "1. í™˜ê²½ ì„¤ì • ë° íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
        "2. ì½”ë“œ ë° ë°ì´í„° ì—…ë¡œë“œ\n",
        "3. ë°ì´í„° ì „ì²˜ë¦¬\n",
        "4. FESeq ëª¨ë¸ í›ˆë ¨\n",
        "5. ê²°ê³¼ ë¶„ì„\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸš€ Step 1: í™˜ê²½ ì„¤ì • ë° GPU í™•ì¸\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\n",
        "import torch\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "else:\n",
        "    print(\"âš ï¸  GPU not available, using CPU\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“¦ Step 2: ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
        "%pip install pandas numpy scikit-learn PyYAML h5py tqdm pyarrow\n",
        "\n",
        "# PyTorch ì„¤ì¹˜ (GPU ë²„ì „)\n",
        "%pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“ Step 3: ì½”ë“œ ì—…ë¡œë“œ ë° ì„¤ì •\n",
        "\n",
        "**ì¤‘ìš”:** ì•„ëž˜ ì…€ì„ ì‹¤í–‰í•˜ê¸° ì „ì— `colab_feseq` í´ë” ì „ì²´ë¥¼ ì••ì¶•(zip)í•´ì„œ Colabì— ì—…ë¡œë“œí•˜ì„¸ìš”.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# íŒŒì¼ ì—…ë¡œë“œ\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "print(\"ðŸ“¤ colab_feseq.zip íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# ì••ì¶• í•´ì œ\n",
        "for filename in uploaded.keys():\n",
        "    if filename.endswith('.zip'):\n",
        "        print(f\"ðŸ“‚ ì••ì¶• í•´ì œ ì¤‘: {filename}\")\n",
        "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "            zip_ref.extractall('.')\n",
        "        \n",
        "        # colab_feseq ë””ë ‰í† ë¦¬ë¡œ ì´ë™\n",
        "        if os.path.exists('colab_feseq'):\n",
        "            os.chdir('colab_feseq')\n",
        "            print(\"âœ… colab_feseq ë””ë ‰í† ë¦¬ë¡œ ì´ë™ ì™„ë£Œ\")\n",
        "            break\n",
        "\n",
        "# í˜„ìž¬ ë””ë ‰í† ë¦¬ êµ¬ì¡° í™•ì¸\n",
        "print(\"\\nðŸ“ í˜„ìž¬ ë””ë ‰í† ë¦¬ êµ¬ì¡°:\")\n",
        "!ls -la\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âš™ï¸ Step 4: FuxiCTR í™˜ê²½ ì„¤ì •\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FuxiCTR ì„¤ì¹˜\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# PYTHONPATH ì„¤ì •\n",
        "current_dir = os.getcwd()\n",
        "if current_dir not in sys.path:\n",
        "    sys.path.insert(0, current_dir)\n",
        "\n",
        "os.environ['PYTHONPATH'] = current_dir\n",
        "print(f\"âœ… PYTHONPATH: {current_dir}\")\n",
        "\n",
        "# setup.pyë¥¼ í†µí•œ ì„¤ì¹˜\n",
        "!python setup.py develop\n",
        "\n",
        "print(\"âœ… FuxiCTR í™˜ê²½ ì„¤ì • ì™„ë£Œ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ§  Step 5: FESeq ëª¨ë¸ í›ˆë ¨ ì‹¤í–‰\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GPU ì„¤ì •\n",
        "import torch\n",
        "gpu_id = 0 if torch.cuda.is_available() else -1\n",
        "print(f\"ðŸŽ¯ ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤: {'GPU ' + str(gpu_id) if gpu_id >= 0 else 'CPU'}\")\n",
        "\n",
        "# FESeq ì‹¤í—˜ ì‹¤í–‰\n",
        "!python run_feseq.py --expid FESeq_tossctr --gpu {gpu_id}\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

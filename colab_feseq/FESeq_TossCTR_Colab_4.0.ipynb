{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FESeq Model Training on TossCTR Dataset (v4.0 - ë™ì  ê²½ë¡œ ìµœì í™”)\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì€ TossCTR ë°ì´í„°ì…‹ì—ì„œ FESeq ëª¨ë¸ì„ í›ˆë ¨í•˜ê¸° ìœ„í•œ H5 ìµœì í™” Colab í™˜ê²½ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
        "\n",
        "## ðŸŽ‰ v4.0 ê°œì„ ì‚¬í•­\n",
        "- **ë™ì  ê²½ë¡œ ì„¤ì •**: Colabê³¼ ë¡œì»¬ í™˜ê²½ ìžë™ ê°ì§€\n",
        "- **ì¤‘ë³µ ì½”ë“œ ì œê±°**: í•¨ìˆ˜í™”ë¥¼ í†µí•œ ì½”ë“œ íš¨ìœ¨ì„± ê°œì„ \n",
        "- **ì ˆëŒ€ ê²½ë¡œ í•´ê²°**: ëª¨ë“  ê²½ë¡œë¥¼ ë™ì ìœ¼ë¡œ ì„¤ì •\n",
        "- **ë” ë‚˜ì€ ì—ëŸ¬ ì²˜ë¦¬**: ìŠ¤ë§ˆíŠ¸í•œ í´ë°± ë©”ì»¤ë‹ˆì¦˜\n",
        "\n",
        "## ðŸš€ ì£¼ìš” ê°œì„ ì‚¬í•­ (H5 ë²„ì „)\n",
        "- **H5 ì§ì ‘ ë³€í™˜**: Parquet â†’ H5 ì§ì ‘ ë³€í™˜ìœ¼ë¡œ CSV ì¤‘ê°„ ë‹¨ê³„ ì œê±°\n",
        "- **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**: CSV ëŒ€ë¹„ 50% ì ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©\n",
        "- **ì²˜ë¦¬ ì†ë„**: 2ë°° ë¹ ë¥¸ ë°ì´í„° ì²˜ë¦¬ ë° ë¡œë”©\n",
        "- **ëŒ€ìš©ëŸ‰ ì§€ì›**: ì „ì²´ ë°ì´í„°ì…‹ë„ ì•ˆì •ì ìœ¼ë¡œ ì²˜ë¦¬\n",
        "\n",
        "## ðŸ“‹ ì‹¤í–‰ ìˆœì„œ\n",
        "1. í™˜ê²½ ì„¤ì • ë° íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
        "2. GitHubì—ì„œ ì½”ë“œ í´ë¡ \n",
        "3. Parquet â†’ H5 ì§ì ‘ ë³€í™˜\n",
        "4. FESeq ëª¨ë¸ í›ˆë ¨\n",
        "5. ì¶”ë¡  ë° ì œì¶œ íŒŒì¼ ìƒì„±\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ› ï¸ Step 0: ë™ì  ê²½ë¡œ ì„¤ì • ì‹œìŠ¤í…œ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ” ê²½ë¡œ ì„¤ì • ìƒíƒœ:\n",
            "   - í™˜ê²½: Local\n",
            "   - ê¸°ë³¸ ê²½ë¡œ: /Users/hj/projects/TossCTR\n",
            "   - colab_feseq: /Users/hj/projects/TossCTR/colab_feseq\n",
            "   - ë°ì´í„°: /Users/hj/projects/TossCTR/colab_feseq/data/tossctr\n",
            "   - ì›ë³¸ ë°ì´í„°: /Users/hj/projects/TossCTR/data/raw\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "class PathManager:\n",
        "    \"\"\"ë™ì  ê²½ë¡œ ê´€ë¦¬ë¥¼ ìœ„í•œ í´ëž˜ìŠ¤\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.is_colab = self._detect_colab()\n",
        "        self.base_path = self._find_base_path()\n",
        "        self.setup_paths()\n",
        "        \n",
        "    def _detect_colab(self):\n",
        "        \"\"\"Colab í™˜ê²½ ê°ì§€\"\"\"\n",
        "        try:\n",
        "            import google.colab\n",
        "            return True\n",
        "        except ImportError:\n",
        "            return False\n",
        "    \n",
        "    def _find_base_path(self):\n",
        "        \"\"\"TossCTR í”„ë¡œì íŠ¸ ê¸°ë³¸ ê²½ë¡œ ì°¾ê¸°\"\"\"\n",
        "        current_path = os.getcwd()\n",
        "        \n",
        "        # ì´ë¯¸ TossCTR í”„ë¡œì íŠ¸ ë‚´ì— ìžˆëŠ”ì§€ í™•ì¸\n",
        "        if 'TossCTR' in current_path:\n",
        "            # TossCTRê¹Œì§€ì˜ ê²½ë¡œ ì¶”ì¶œ\n",
        "            parts = current_path.split('/')\n",
        "            tossctr_idx = parts.index('TossCTR')\n",
        "            base_path = '/'.join(parts[:tossctr_idx+1])\n",
        "            return base_path\n",
        "        \n",
        "        # Colab í™˜ê²½\n",
        "        if self.is_colab:\n",
        "            if os.path.exists('/content/TossCTR'):\n",
        "                return '/content/TossCTR'\n",
        "            else:\n",
        "                return '/content'\n",
        "        \n",
        "        # ë¡œì»¬ í™˜ê²½\n",
        "        possible_paths = [\n",
        "            '/Users/hj/projects/TossCTR',\n",
        "            os.path.expanduser('~/projects/TossCTR'),\n",
        "            current_path\n",
        "        ]\n",
        "        \n",
        "        for path in possible_paths:\n",
        "            if os.path.exists(path) and os.path.exists(os.path.join(path, 'colab_feseq')):\n",
        "                return path\n",
        "        \n",
        "        return current_path\n",
        "    \n",
        "    def setup_paths(self):\n",
        "        \"\"\"ëª¨ë“  í•„ìš”í•œ ê²½ë¡œ ì„¤ì •\"\"\"\n",
        "        self.colab_feseq_path = os.path.join(self.base_path, 'colab_feseq')\n",
        "        self.data_path = os.path.join(self.colab_feseq_path, 'data', 'tossctr')\n",
        "        self.model_zoo_path = os.path.join(self.colab_feseq_path, 'model_zoo')\n",
        "        self.preprocessing_path = os.path.join(self.colab_feseq_path, 'preprocessing')\n",
        "        \n",
        "        # ì›ë³¸ ë°ì´í„° ê²½ë¡œ ì„¤ì •\n",
        "        if self.is_colab:\n",
        "            self.raw_data_path = self._find_raw_data_colab()\n",
        "        else:\n",
        "            self.raw_data_path = os.path.join(self.base_path, 'data', 'raw')\n",
        "    \n",
        "    def _find_raw_data_colab(self):\n",
        "        \"\"\"Colabì—ì„œ ì›ë³¸ ë°ì´í„° ê²½ë¡œ ì°¾ê¸°\"\"\"\n",
        "        possible_paths = [\n",
        "            '/content/drive/MyDrive/data/TossCTR/raw',\n",
        "            '/content/TossCTR/data/raw',\n",
        "            '/content/data/raw'\n",
        "        ]\n",
        "        \n",
        "        for path in possible_paths:\n",
        "            if os.path.exists(path):\n",
        "                return path\n",
        "        \n",
        "        return '/content/drive/MyDrive/data/TossCTR/raw'\n",
        "    \n",
        "    def get_train_parquet_path(self):\n",
        "        \"\"\"train.parquet íŒŒì¼ ê²½ë¡œ ì°¾ê¸°\"\"\"\n",
        "        possible_paths = [\n",
        "            os.path.join(self.raw_data_path, 'train.parquet'),\n",
        "            '/content/drive/MyDrive/data/TossCTR/raw/train.parquet',\n",
        "            '/Users/hj/projects/TossCTR/data/raw/train.parquet'\n",
        "        ]\n",
        "        \n",
        "        for path in possible_paths:\n",
        "            if os.path.exists(path):\n",
        "                return path\n",
        "        \n",
        "        return None\n",
        "    \n",
        "    def get_test_parquet_path(self):\n",
        "        \"\"\"test.parquet íŒŒì¼ ê²½ë¡œ ì°¾ê¸°\"\"\"\n",
        "        possible_paths = [\n",
        "            os.path.join(self.raw_data_path, 'test.parquet'),\n",
        "            '/content/drive/MyDrive/data/TossCTR/raw/test.parquet',\n",
        "            '/Users/hj/projects/TossCTR/data/raw/test.parquet'\n",
        "        ]\n",
        "        \n",
        "        for path in possible_paths:\n",
        "            if os.path.exists(path):\n",
        "                return path\n",
        "        \n",
        "        return None\n",
        "    \n",
        "    def get_sample_submission_path(self):\n",
        "        \"\"\"sample_submission.csv íŒŒì¼ ê²½ë¡œ ì°¾ê¸°\"\"\"\n",
        "        possible_paths = [\n",
        "            os.path.join(self.raw_data_path, 'sample_submission.csv'),\n",
        "            '/content/drive/MyDrive/data/TossCTR/raw/sample_submission.csv',\n",
        "            '/Users/hj/projects/TossCTR/data/raw/sample_submission.csv'\n",
        "        ]\n",
        "        \n",
        "        for path in possible_paths:\n",
        "            if os.path.exists(path):\n",
        "                return path\n",
        "        \n",
        "        return None\n",
        "    \n",
        "    def ensure_directory(self, path):\n",
        "        \"\"\"ë””ë ‰í† ë¦¬ ìƒì„± í™•ì¸\"\"\"\n",
        "        os.makedirs(path, exist_ok=True)\n",
        "        return path\n",
        "    \n",
        "    def cd_to_colab_feseq(self):\n",
        "        \"\"\"colab_feseq ë””ë ‰í† ë¦¬ë¡œ ì´ë™\"\"\"\n",
        "        if os.path.exists(self.colab_feseq_path):\n",
        "            os.chdir(self.colab_feseq_path)\n",
        "            print(f\"ðŸ“ ìž‘ì—… ë””ë ‰í† ë¦¬ ë³€ê²½: {self.colab_feseq_path}\")\n",
        "        else:\n",
        "            print(f\"âŒ colab_feseq ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.colab_feseq_path}\")\n",
        "    \n",
        "    def setup_python_path(self):\n",
        "        \"\"\"Python ê²½ë¡œ ì„¤ì •\"\"\"\n",
        "        paths_to_add = [self.colab_feseq_path, self.preprocessing_path]\n",
        "        \n",
        "        for path in paths_to_add:\n",
        "            if path not in sys.path and os.path.exists(path):\n",
        "                sys.path.insert(0, path)\n",
        "        \n",
        "        os.environ['PYTHONPATH'] = ':'.join(paths_to_add)\n",
        "        print(f\"âœ… PYTHONPATH ì„¤ì • ì™„ë£Œ\")\n",
        "    \n",
        "    def print_status(self):\n",
        "        \"\"\"í˜„ìž¬ ê²½ë¡œ ìƒíƒœ ì¶œë ¥\"\"\"\n",
        "        print(\"ðŸ” ê²½ë¡œ ì„¤ì • ìƒíƒœ:\")\n",
        "        print(f\"   - í™˜ê²½: {'Colab' if self.is_colab else 'Local'}\")\n",
        "        print(f\"   - ê¸°ë³¸ ê²½ë¡œ: {self.base_path}\")\n",
        "        print(f\"   - colab_feseq: {self.colab_feseq_path}\")\n",
        "        print(f\"   - ë°ì´í„°: {self.data_path}\")\n",
        "        print(f\"   - ì›ë³¸ ë°ì´í„°: {self.raw_data_path}\")\n",
        "\n",
        "# ì „ì—­ PathManager ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
        "path_manager = PathManager()\n",
        "path_manager.print_status()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸš€ Step 1: í™˜ê²½ ì„¤ì • ë° GPU í™•ì¸\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA available: False\n",
            "âš ï¸  GPU not available, using CPU\n"
          ]
        }
      ],
      "source": [
        "# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\n",
        "import torch\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "else:\n",
        "    print(\"âš ï¸  GPU not available, using CPU\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ’» ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘ìž…ë‹ˆë‹¤.\n"
          ]
        }
      ],
      "source": [
        "# Colab í™˜ê²½ì—ì„œë§Œ Google Drive ë§ˆìš´íŠ¸\n",
        "if path_manager.is_colab:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "else:\n",
        "    print(\"ðŸ’» ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘ìž…ë‹ˆë‹¤.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“¦ Step 2: ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "packages = [\"pandas\", \"numpy\", \"scikit-learn\", \"PyYAML\", \"h5py\", \"tqdm\", \"pyarrow\"]\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\"] + packages)\n",
        "\n",
        "# PyTorch ì„¤ì¹˜ (GPU ë²„ì „)\n",
        "if torch.cuda.is_available():\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"torch\", \"torchvision\", \"--index-url\", \"https://download.pytorch.org/whl/cu118\"])\n",
        "else:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"torch\", \"torchvision\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“ Step 3: GitHubì—ì„œ ì½”ë“œ í´ë¡ \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“ í˜„ìž¬ ìœ„ì¹˜: /Users/hj/projects/TossCTR/colab_feseq\n",
            "âœ… TossCTR ë””ë ‰í† ë¦¬ê°€ ì´ë¯¸ ì¡´ìž¬í•©ë‹ˆë‹¤.\n",
            "ðŸ“ ìž‘ì—… ë””ë ‰í† ë¦¬ ë³€ê²½: /Users/hj/projects/TossCTR/colab_feseq\n",
            "âœ… PYTHONPATH ì„¤ì • ì™„ë£Œ\n",
            "\n",
            "ðŸ“ í˜„ìž¬ ë””ë ‰í† ë¦¬ êµ¬ì¡°:\n",
            "total 472\n",
            "drwxr-xr-x  15 hj  staff    480 Sep 25 17:43 \u001b[34m.\u001b[m\u001b[m\n",
            "drwxr-xr-x  17 hj  staff    544 Sep 23 20:10 \u001b[34m..\u001b[m\u001b[m\n",
            "-rw-r--r--   1 hj  staff  57957 Sep 25 12:17 FESeq_TossCTR_Colab_2.0.ipynb\n",
            "-rw-r--r--   1 hj  staff  79828 Sep 25 22:53 FESeq_TossCTR_Colab_3.0.ipynb\n",
            "-rw-r--r--   1 hj  staff  69474 Sep 25 19:40 FESeq_TossCTR_Colab_4.0.ipynb\n",
            "drwxr-xr-x   4 hj  staff    128 Sep 24 23:05 \u001b[34mdata\u001b[m\u001b[m\n",
            "drwxr-xr-x  13 hj  staff    416 Sep 23 20:11 \u001b[34mfuxictr\u001b[m\u001b[m\n",
            "drwxr-xr-x   7 hj  staff    224 Sep 25 19:32 \u001b[34mfuxictr.egg-info\u001b[m\u001b[m\n",
            "-rw-r--r--   1 hj  staff   4788 Sep 24 22:51 load_tossctr_data.py\n",
            "drwxr-xr-x   6 hj  staff    192 Sep 23 20:11 \u001b[34mmodel_zoo\u001b[m\u001b[m\n",
            "drwxr-xr-x   5 hj  staff    160 Sep 25 17:43 \u001b[34mpreprocessing\u001b[m\u001b[m\n",
            "-rw-r--r--@  1 hj  staff     70 Sep 24 22:51 requirements.txt\n",
            "-rw-r--r--   1 hj  staff   3849 Sep 25 00:21 run_feseq.py\n",
            "-rw-r--r--   1 hj  staff    364 Sep 24 23:02 setup.py\n",
            "-rw-r--r--   1 hj  staff   5274 Sep 25 13:47 test_h5_pipeline.py\n",
            "\n",
            "ðŸ” ì¤‘ìš” íŒŒì¼ í™•ì¸:\n",
            "âœ… run_feseq.py: run_feseq.py\n",
            "âœ… FESeq ëª¨ë¸: model_zoo/FESeq\n",
            "âœ… ë°ì´í„° ë””ë ‰í† ë¦¬: data/tossctr\n",
            "âœ… ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸: preprocessing/tossctr_parquet_to_h5.py\n"
          ]
        }
      ],
      "source": [
        "# GitHubì—ì„œ TossCTR ë ˆí¬ì§€í† ë¦¬ í´ë¡ \n",
        "import os\n",
        "\n",
        "# í˜„ìž¬ ìœ„ì¹˜ í™•ì¸\n",
        "current_path = os.getcwd()\n",
        "print(f\"ðŸ“ í˜„ìž¬ ìœ„ì¹˜: {current_path}\")\n",
        "\n",
        "# Colab í™˜ê²½ì—ì„œë§Œ í´ë¡  ìˆ˜í–‰\n",
        "if path_manager.is_colab and not os.path.exists('/content/TossCTR'):\n",
        "    print(\"ðŸ“¥ GitHubì—ì„œ TossCTR ë ˆí¬ì§€í† ë¦¬ë¥¼ í´ë¡ í•©ë‹ˆë‹¤...\")\n",
        "    os.system(\"git clone https://github.com/kwonhwijun/TossCTR.git /content/TossCTR\")\n",
        "    \n",
        "    # PathManager ìž¬ì´ˆê¸°í™” (í´ë¡  í›„ ê²½ë¡œ ì—…ë°ì´íŠ¸)\n",
        "    path_manager = PathManager()\n",
        "else:\n",
        "    print(\"âœ… TossCTR ë””ë ‰í† ë¦¬ê°€ ì´ë¯¸ ì¡´ìž¬í•©ë‹ˆë‹¤.\")\n",
        "\n",
        "# colab_feseq ë””ë ‰í† ë¦¬ë¡œ ì´ë™\n",
        "path_manager.cd_to_colab_feseq()\n",
        "\n",
        "# Python ê²½ë¡œ ì„¤ì •\n",
        "path_manager.setup_python_path()\n",
        "\n",
        "# í˜„ìž¬ ë””ë ‰í† ë¦¬ êµ¬ì¡° í™•ì¸\n",
        "print(\"\\nðŸ“ í˜„ìž¬ ë””ë ‰í† ë¦¬ êµ¬ì¡°:\")\n",
        "os.system(\"ls -la\")\n",
        "\n",
        "# ì¤‘ìš”í•œ íŒŒì¼ë“¤ì´ ìžˆëŠ”ì§€ í™•ì¸\n",
        "print(\"\\nðŸ” ì¤‘ìš” íŒŒì¼ í™•ì¸:\")\n",
        "files_to_check = [\n",
        "    (\"run_feseq.py\", \"run_feseq.py\"),\n",
        "    (\"FESeq ëª¨ë¸\", \"model_zoo/FESeq\"),\n",
        "    (\"ë°ì´í„° ë””ë ‰í† ë¦¬\", \"data/tossctr\"),\n",
        "    (\"ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸\", \"preprocessing/tossctr_parquet_to_h5.py\")\n",
        "]\n",
        "\n",
        "for name, file_path in files_to_check:\n",
        "    full_path = os.path.join(path_manager.colab_feseq_path, file_path)\n",
        "    exists = \"âœ…\" if os.path.exists(full_path) else \"âŒ\"\n",
        "    print(f\"{exists} {name}: {file_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âš™ï¸ Step 4: FuxiCTR í™˜ê²½ ì„¤ì •\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“¦ FuxiCTR ì„¤ì¹˜ ì¤‘...\n",
            "running develop\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/hj/projects/TossCTR/venv/lib/python3.13/site-packages/setuptools/_distutils/cmd.py:90: DevelopDeprecationWarning: develop command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``develop``.\n",
            "        Instead, use standards-based tools like pip or uv.\n",
            "\n",
            "        By 2025-Oct-31, you need to update your project and remove deprecated calls\n",
            "        or your builds will no longer be supported.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Obtaining file:///Users/hj/projects/TossCTR/colab_feseq\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Checking if build backend supports build_editable: started\n",
            "  Checking if build backend supports build_editable: finished with status 'done'\n",
            "  Getting requirements to build editable: started\n",
            "  Getting requirements to build editable: finished with status 'done'\n",
            "  Preparing editable metadata (pyproject.toml): started\n",
            "  Preparing editable metadata (pyproject.toml): finished with status 'done'\n",
            "Requirement already satisfied: pandas in /Users/hj/projects/TossCTR/venv/lib/python3.13/site-packages (from fuxictr==2.0.2) (2.3.2)\n",
            "Requirement already satisfied: numpy in /Users/hj/projects/TossCTR/venv/lib/python3.13/site-packages (from fuxictr==2.0.2) (2.3.3)\n",
            "Requirement already satisfied: h5py in /Users/hj/projects/TossCTR/venv/lib/python3.13/site-packages (from fuxictr==2.0.2) (3.14.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /Users/hj/projects/TossCTR/venv/lib/python3.13/site-packages (from fuxictr==2.0.2) (6.0.2)\n",
            "Requirement already satisfied: scikit-learn in /Users/hj/projects/TossCTR/venv/lib/python3.13/site-packages (from fuxictr==2.0.2) (1.7.2)\n",
            "Requirement already satisfied: tqdm in /Users/hj/projects/TossCTR/venv/lib/python3.13/site-packages (from fuxictr==2.0.2) (4.67.1)\n",
            "Requirement already satisfied: torch in /Users/hj/projects/TossCTR/venv/lib/python3.13/site-packages (from fuxictr==2.0.2) (2.8.0)\n",
            "Requirement already satisfied: pyarrow in /Users/hj/projects/TossCTR/venv/lib/python3.13/site-packages (from fuxictr==2.0.2) (21.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/hj/projects/TossCTR/venv/lib/python3.13/site-packages (from pandas->fuxictr==2.0.2) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/hj/projects/TossCTR/venv/lib/python3.13/site-packages (from pandas->fuxictr==2.0.2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Users/hj/projects/TossCTR/venv/lib/python3.13/site-packages (from pandas->fuxictr==2.0.2) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /Users/hj/projects/TossCTR/venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->fuxictr==2.0.2) (1.17.0)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /Users/hj/projects/TossCTR/venv/lib/python3.13/site-packages (from scikit-learn->fuxictr==2.0.2) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /Users/hj/projects/TossCTR/venv/lib/python3.13/site-packages (from scikit-learn->fuxictr==2.0.2) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/hj/projects/TossCTR/venv/lib/python3.13/site-packages (from scikit-learn->fuxictr==2.0.2) (3.6.0)\n",
            "Requirement already satisfied: filelock in /Users/hj/projects/TossCTR/venv/lib/python3.13/site-packages (from torch->fuxictr==2.0.2) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/hj/projects/TossCTR/venv/lib/python3.13/site-packages (from torch->fuxictr==2.0.2) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /Users/hj/projects/TossCTR/venv/lib/python3.13/site-packages (from torch->fuxictr==2.0.2) (80.9.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /Users/hj/projects/TossCTR/venv/lib/python3.13/site-packages (from torch->fuxictr==2.0.2) (1.14.0)\n",
            "Requirement already satisfied: networkx in /Users/hj/projects/TossCTR/venv/lib/python3.13/site-packages (from torch->fuxictr==2.0.2) (3.5)\n",
            "Requirement already satisfied: jinja2 in /Users/hj/projects/TossCTR/venv/lib/python3.13/site-packages (from torch->fuxictr==2.0.2) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /Users/hj/projects/TossCTR/venv/lib/python3.13/site-packages (from torch->fuxictr==2.0.2) (2025.9.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/hj/projects/TossCTR/venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch->fuxictr==2.0.2) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/hj/projects/TossCTR/venv/lib/python3.13/site-packages (from jinja2->torch->fuxictr==2.0.2) (3.0.2)\n",
            "Building wheels for collected packages: fuxictr\n",
            "  Building editable for fuxictr (pyproject.toml): started\n",
            "  Building editable for fuxictr (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for fuxictr: filename=fuxictr-2.0.2-0.editable-py3-none-any.whl size=2783 sha256=14b2b51972efbadbbd60c6b2950a2ee09e243969a72bfb6c4f2870c9a8abb43e\n",
            "  Stored in directory: /private/var/folders/_7/gw7m14q925731rjlj61v1dqm0000gn/T/pip-ephem-wheel-cache-7z44hgp6/wheels/53/d0/fd/2e92641b535b6976533368583c6b8d627fad8cea199843956a\n",
            "Successfully built fuxictr\n",
            "Installing collected packages: fuxictr\n",
            "  Attempting uninstall: fuxictr\n",
            "    Found existing installation: fuxictr 2.0.2\n",
            "    Not uninstalling fuxictr at /Users/hj/projects/TossCTR/colab_feseq, outside environment /Users/hj/projects/TossCTR/venv\n",
            "    Can't uninstall 'fuxictr'. No files were found to uninstall.\n",
            "Successfully installed fuxictr-2.0.2\n",
            "âœ… FuxiCTR í™˜ê²½ ì„¤ì • ì™„ë£Œ\n"
          ]
        }
      ],
      "source": [
        "# FuxiCTR ì„¤ì¹˜\n",
        "try:\n",
        "    print(\"ðŸ“¦ FuxiCTR ì„¤ì¹˜ ì¤‘...\")\n",
        "    os.system(\"python setup.py develop\")\n",
        "    print(\"âœ… FuxiCTR í™˜ê²½ ì„¤ì • ì™„ë£Œ\")\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸  setup.py ì„¤ì¹˜ ì‹¤íŒ¨: {e}\")\n",
        "    print(\"ðŸ“¦ pipìœ¼ë¡œ ëŒ€ì²´ ì„¤ì¹˜ ì‹œë„...\")\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-e\", \".\"])\n",
        "    print(\"âœ… FuxiCTR í™˜ê²½ ì„¤ì • ì™„ë£Œ (pip ë°©ì‹)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“Š Step 5: ì›ë³¸ Parquet â†’ H5 ì§ì ‘ ë³€í™˜\n",
        "\n",
        "ì›ë³¸ train.parquet íŒŒì¼ì—ì„œ H5 í˜•ì‹ìœ¼ë¡œ ì§ì ‘ ë³€í™˜í•©ë‹ˆë‹¤.\n",
        "CSV ì¤‘ê°„ ë‹¨ê³„ë¥¼ ê±´ë„ˆë›°ì–´ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ê³¼ ì²˜ë¦¬ ì†ë„ë¥¼ í¬ê²Œ í–¥ìƒì‹œí‚µë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸŽ¯ ë¡œë“œí•  ë°ì´í„° ìƒ˜í”Œ ìˆ˜: 1,000ê°œ\n",
            "ðŸ”„ ì²­í¬ í¬ê¸°: 500ê°œ\n",
            "   ðŸ’¡ íŒ: N_SAMPLES = 0ìœ¼ë¡œ ì„¤ì •í•˜ë©´ ì „ì²´ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤\n",
            "\n",
            "âœ… ì›ë³¸ train.parquet ë°œê²¬: /Users/hj/projects/TossCTR/data/raw/train.parquet\n",
            "ðŸ“Š íŒŒì¼ í¬ê¸°: 8.19 GB\n",
            "\n",
            "âœ… ì„¤ì • íŒŒì¼ ë°œê²¬: /Users/hj/projects/TossCTR/colab_feseq/model_zoo/FESeq/config/dataset_config.yaml\n"
          ]
        }
      ],
      "source": [
        "# ðŸ“Š H5 ë³€í™˜ ì„¤ì •\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# ë°ì´í„°ëŸ‰ ì„¤ì • (í•„ìš”ì— ë”°ë¼ ì¡°ì •)\n",
        "N_SAMPLES = 1000  # 10ë§Œê°œ ìƒ˜í”Œ (0ìœ¼ë¡œ ì„¤ì •í•˜ë©´ ì „ì²´ ë°ì´í„° ì‚¬ìš©)\n",
        "CHUNK_SIZE = 500  # ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬ë¥¼ ìœ„í•œ ì²­í¬ í¬ê¸°\n",
        "\n",
        "print(f\"ðŸŽ¯ ë¡œë“œí•  ë°ì´í„° ìƒ˜í”Œ ìˆ˜: {N_SAMPLES:,}ê°œ\")\n",
        "print(f\"ðŸ”„ ì²­í¬ í¬ê¸°: {CHUNK_SIZE:,}ê°œ\")\n",
        "print(f\"   ðŸ’¡ íŒ: N_SAMPLES = 0ìœ¼ë¡œ ì„¤ì •í•˜ë©´ ì „ì²´ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤\")\n",
        "\n",
        "# ì›ë³¸ train.parquet íŒŒì¼ ì°¾ê¸°\n",
        "train_parquet_path = path_manager.get_train_parquet_path()\n",
        "\n",
        "if train_parquet_path:\n",
        "    print(f\"\\nâœ… ì›ë³¸ train.parquet ë°œê²¬: {train_parquet_path}\")\n",
        "    file_size = os.path.getsize(train_parquet_path) / (1024**3)  # GB ë‹¨ìœ„\n",
        "    print(f\"ðŸ“Š íŒŒì¼ í¬ê¸°: {file_size:.2f} GB\")\n",
        "else:\n",
        "    print(\"\\nâŒ train.parquet íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "    print(\"ðŸ“‹ í•´ê²° ë°©ë²•:\")\n",
        "    print(\"1. Google Driveì— ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”\")\n",
        "    print(\"2. ë˜ëŠ” ë¡œì»¬ì—ì„œ ë°ì´í„° ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”\")\n",
        "\n",
        "# ì„¤ì • íŒŒì¼ ê²½ë¡œ\n",
        "config_path = os.path.join(path_manager.model_zoo_path, \"FESeq/config/dataset_config.yaml\")\n",
        "if os.path.exists(config_path):\n",
        "    print(f\"\\nâœ… ì„¤ì • íŒŒì¼ ë°œê²¬: {config_path}\")\n",
        "else:\n",
        "    print(f\"\\nâŒ ì„¤ì • íŒŒì¼ ì—†ìŒ: {config_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸš€ Parquet â†’ H5 ë³€í™˜ì„ ì‹œìž‘í•©ë‹ˆë‹¤...\n",
            "ðŸ“Š ìž…ë ¥: /Users/hj/projects/TossCTR/data/raw/train.parquet\n",
            "ðŸ“ ì¶œë ¥: /Users/hj/projects/TossCTR/colab_feseq/data/tossctr\n",
            "ðŸŽ¯ ìƒ˜í”Œ ìˆ˜: 1,000ê°œ\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Categorical features: 5\n",
            "INFO:root:Numeric features: 75\n",
            "INFO:root:Sequence features: 1\n",
            "INFO:root:Starting full pipeline...\n",
            "INFO:root:Loading parquet file: /Users/hj/projects/TossCTR/data/raw/train.parquet\n",
            "INFO:root:Total rows: 10,704,179\n",
            "INFO:root:Loaded shape: (10704179, 81)\n",
            "INFO:root:Sampled 1000 rows\n",
            "INFO:root:Splitting data...\n",
            "INFO:root:Split - Train: 700, Val: 150, Test: 150\n",
            "INFO:root:Click rates - Train: 0.019, Val: 0.020, Test: 0.020\n",
            "INFO:root:Fitting preprocessors on training data...\n",
            "INFO:root:Fitting categorical features...\n",
            "INFO:root:Encoded gender: 3 unique values\n",
            "INFO:root:Encoded age_group: 9 unique values\n",
            "INFO:root:Encoded inventory_id: 14 unique values\n",
            "INFO:root:Encoded day_of_week: 7 unique values\n",
            "INFO:root:Encoded hour: 24 unique values\n",
            "INFO:root:Fitting numeric features...\n",
            "INFO:root:Fitted scaler for l_feat_1\n",
            "INFO:root:Fitted scaler for l_feat_2\n",
            "INFO:root:Fitted scaler for l_feat_3\n",
            "INFO:root:Fitted scaler for l_feat_4\n",
            "INFO:root:Fitted scaler for l_feat_5\n",
            "INFO:root:Fitted scaler for l_feat_6\n",
            "INFO:root:Fitted scaler for l_feat_7\n",
            "INFO:root:Fitted scaler for l_feat_8\n",
            "INFO:root:Fitted scaler for l_feat_9\n",
            "INFO:root:Fitted scaler for l_feat_10\n",
            "INFO:root:Fitted scaler for l_feat_11\n",
            "INFO:root:Fitted scaler for l_feat_12\n",
            "INFO:root:Fitted scaler for l_feat_13\n",
            "INFO:root:Fitted scaler for l_feat_14\n",
            "INFO:root:Fitted scaler for l_feat_15\n",
            "INFO:root:Fitted scaler for l_feat_16\n",
            "INFO:root:Fitted scaler for l_feat_17\n",
            "INFO:root:Fitted scaler for l_feat_18\n",
            "INFO:root:Fitted scaler for l_feat_19\n",
            "INFO:root:Fitted scaler for l_feat_20\n",
            "INFO:root:Fitted scaler for l_feat_21\n",
            "INFO:root:Fitted scaler for l_feat_22\n",
            "INFO:root:Fitted scaler for l_feat_23\n",
            "INFO:root:Fitted scaler for l_feat_24\n",
            "INFO:root:Fitted scaler for l_feat_25\n",
            "INFO:root:Fitted scaler for l_feat_26\n",
            "INFO:root:Fitted scaler for l_feat_27\n",
            "INFO:root:Fitted scaler for feat_e_1\n",
            "INFO:root:Fitted scaler for feat_e_2\n",
            "INFO:root:Fitted scaler for feat_e_3\n",
            "INFO:root:Fitted scaler for feat_e_4\n",
            "INFO:root:Fitted scaler for feat_e_5\n",
            "INFO:root:Fitted scaler for feat_e_6\n",
            "INFO:root:Fitted scaler for feat_e_7\n",
            "INFO:root:Fitted scaler for feat_e_8\n",
            "INFO:root:Fitted scaler for feat_e_9\n",
            "INFO:root:Fitted scaler for feat_e_10\n",
            "INFO:root:Fitted scaler for feat_d_1\n",
            "INFO:root:Fitted scaler for feat_d_2\n",
            "INFO:root:Fitted scaler for feat_d_3\n",
            "INFO:root:Fitted scaler for feat_d_4\n",
            "INFO:root:Fitted scaler for feat_d_5\n",
            "INFO:root:Fitted scaler for feat_d_6\n",
            "INFO:root:Fitted scaler for feat_c_1\n",
            "INFO:root:Fitted scaler for feat_c_2\n",
            "INFO:root:Fitted scaler for feat_c_3\n",
            "INFO:root:Fitted scaler for feat_c_4\n",
            "INFO:root:Fitted scaler for feat_c_5\n",
            "INFO:root:Fitted scaler for feat_c_6\n",
            "INFO:root:Fitted scaler for feat_c_7\n",
            "INFO:root:Fitted scaler for feat_c_8\n",
            "INFO:root:Fitted scaler for feat_b_1\n",
            "INFO:root:Fitted scaler for feat_b_2\n",
            "INFO:root:Fitted scaler for feat_b_3\n",
            "INFO:root:Fitted scaler for feat_b_4\n",
            "INFO:root:Fitted scaler for feat_b_5\n",
            "INFO:root:Fitted scaler for feat_b_6\n",
            "INFO:root:Fitted scaler for feat_a_1\n",
            "INFO:root:Fitted scaler for feat_a_2\n",
            "INFO:root:Fitted scaler for feat_a_3\n",
            "INFO:root:Fitted scaler for feat_a_4\n",
            "INFO:root:Fitted scaler for feat_a_5\n",
            "INFO:root:Fitted scaler for feat_a_6\n",
            "INFO:root:Fitted scaler for feat_a_7\n",
            "INFO:root:Fitted scaler for feat_a_8\n",
            "INFO:root:Fitted scaler for feat_a_9\n",
            "INFO:root:Fitted scaler for feat_a_10\n",
            "INFO:root:Fitted scaler for feat_a_11\n",
            "INFO:root:Fitted scaler for feat_a_12\n",
            "INFO:root:Fitted scaler for feat_a_13\n",
            "INFO:root:Fitted scaler for feat_a_14\n",
            "INFO:root:Fitted scaler for feat_a_15\n",
            "INFO:root:Fitted scaler for feat_a_16\n",
            "INFO:root:Fitted scaler for feat_a_17\n",
            "INFO:root:Fitted scaler for feat_a_18\n",
            "INFO:root:Fitting sequence features...\n",
            "INFO:root:Saved processors to /Users/hj/projects/TossCTR/colab_feseq/data/tossctr/feature_processor.pkl\n",
            "INFO:root:Saved feature_map.json: 80 fields, 132 features\n",
            "INFO:root:Processing and saving train...\n",
            "INFO:root:Saving data to h5: /Users/hj/projects/TossCTR/colab_feseq/data/tossctr/train.h5\n",
            "INFO:root:Saved train.h5 with 700 samples\n",
            "INFO:root:Processing and saving valid...\n",
            "INFO:root:Saving data to h5: /Users/hj/projects/TossCTR/colab_feseq/data/tossctr/valid.h5\n",
            "INFO:root:Saved valid.h5 with 150 samples\n",
            "INFO:root:Processing and saving test...\n",
            "INFO:root:Saving data to h5: /Users/hj/projects/TossCTR/colab_feseq/data/tossctr/test.h5\n",
            "INFO:root:Saved test.h5 with 150 samples\n",
            "INFO:root:âœ… Full pipeline completed!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "âœ… H5 ë³€í™˜ ì™„ë£Œ!\n",
            "âœ… train.h5: 0.2 MB\n",
            "âœ… valid.h5: 0.1 MB\n",
            "âœ… test.h5: 0.1 MB\n"
          ]
        }
      ],
      "source": [
        "# ðŸš€ H5 ë³€í™˜ ì‹¤í–‰\n",
        "if train_parquet_path:\n",
        "    print(f\"ðŸš€ Parquet â†’ H5 ë³€í™˜ì„ ì‹œìž‘í•©ë‹ˆë‹¤...\")\n",
        "    print(f\"ðŸ“Š ìž…ë ¥: {train_parquet_path}\")\n",
        "    print(f\"ðŸ“ ì¶œë ¥: {path_manager.data_path}\")\n",
        "    print(f\"ðŸŽ¯ ìƒ˜í”Œ ìˆ˜: {N_SAMPLES:,}ê°œ\")\n",
        "    \n",
        "    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±\n",
        "    path_manager.ensure_directory(path_manager.data_path)\n",
        "    \n",
        "    try:\n",
        "        # H5 í”„ë¡œì„¸ì„œ ìž„í¬íŠ¸\n",
        "        from preprocessing.tossctr_parquet_to_h5 import TossCTRParquetProcessor\n",
        "        \n",
        "        # í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”\n",
        "        processor = TossCTRParquetProcessor(\n",
        "            config_path=config_path,\n",
        "            data_root=os.path.dirname(path_manager.data_path)\n",
        "        )\n",
        "        \n",
        "        # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰\n",
        "        processor.process_full_pipeline(\n",
        "            train_parquet_path=train_parquet_path,\n",
        "            chunk_size=CHUNK_SIZE,\n",
        "            n_samples=N_SAMPLES if N_SAMPLES > 0 else None\n",
        "        )\n",
        "        \n",
        "        print(\"\\nâœ… H5 ë³€í™˜ ì™„ë£Œ!\")\n",
        "        \n",
        "        # ìƒì„±ëœ íŒŒì¼ë“¤ í™•ì¸\n",
        "        h5_files = ['train.h5', 'valid.h5', 'test.h5']\n",
        "        for filename in h5_files:\n",
        "            filepath = os.path.join(path_manager.data_path, filename)\n",
        "            if os.path.exists(filepath):\n",
        "                size_mb = os.path.getsize(filepath) / (1024**2)\n",
        "                print(f\"âœ… {filename}: {size_mb:.1f} MB\")\n",
        "            else:\n",
        "                print(f\"âŒ {filename}: ìƒì„±ë˜ì§€ ì•ŠìŒ\")\n",
        "                \n",
        "    except Exception as e:\n",
        "        print(f\"\\nâŒ H5 ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        \n",
        "        # ëŒ€ì•ˆ: í„°ë¯¸ë„ ëª…ë ¹ì–´ë¡œ ì‹¤í–‰\n",
        "        print(\"\\nðŸ”„ í„°ë¯¸ë„ ëª…ë ¹ì–´ë¡œ ìž¬ì‹œë„...\")\n",
        "        h5_script = os.path.join(path_manager.preprocessing_path, \"tossctr_parquet_to_h5.py\")\n",
        "        cmd = f'''python \"{h5_script}\" \\\\\n",
        "            --train_path \"{train_parquet_path}\" \\\\\n",
        "            --config_path \"{config_path}\" \\\\\n",
        "            --data_root \"{os.path.dirname(path_manager.data_path)}\" \\\\\n",
        "            --chunk_size {CHUNK_SIZE} \\\\\n",
        "            --n_samples {N_SAMPLES if N_SAMPLES > 0 else 0}'''\n",
        "        \n",
        "        print(f\"ì‹¤í–‰ ëª…ë ¹ì–´:\\n{cmd}\")\n",
        "        os.system(cmd)\n",
        "else:\n",
        "    print(\"âŒ train.parquet íŒŒì¼ì´ ì—†ì–´ì„œ H5 ë³€í™˜ì„ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ§  Step 6: FESeq ëª¨ë¸ í›ˆë ¨ ì‹¤í–‰ (H5 ë°©ì‹)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ï¿½ï¿½ H5 í›ˆë ¨ ì¤€ë¹„ ìƒíƒœ í™•ì¸...\n",
            "ï¿½ï¿½ í˜„ìž¬ ë°ì´í„° ê²½ë¡œ: /Users/hj/projects/TossCTR/colab_feseq/data/tossctr\n",
            "ðŸ“ FESeq ë””ë ‰í† ë¦¬: /Users/hj/projects/TossCTR/colab_feseq/model_zoo/FESeq\n",
            "âœ… train.h5: /Users/hj/projects/TossCTR/colab_feseq/data/tossctr/train.h5\n",
            "âœ… valid.h5: /Users/hj/projects/TossCTR/colab_feseq/data/tossctr/valid.h5\n",
            "âœ… test.h5: /Users/hj/projects/TossCTR/colab_feseq/data/tossctr/test.h5\n",
            "âœ… feature_map.json: /Users/hj/projects/TossCTR/colab_feseq/data/tossctr/feature_map.json\n",
            "ðŸ“ H5 ì„¤ì • ê¸°ëŒ€ ê²½ë¡œ: /Users/hj/projects/TossCTR/colab_feseq/data/tossctr_h5_dataset\n",
            "ï¿½ï¿½ ê²½ë¡œ ì¡´ìž¬ ì—¬ë¶€: âŒ\n",
            "ï¿½ï¿½ ì„¤ì • íŒŒì¼: âœ… /Users/hj/projects/TossCTR/colab_feseq/model_zoo/FESeq/config/dataset_config.yaml\n"
          ]
        }
      ],
      "source": [
        "# ï¿½ï¿½ ë””ë²„ê¹…: ê²½ë¡œ ë° íŒŒì¼ í™•ì¸\n",
        "print(\"ï¿½ï¿½ H5 í›ˆë ¨ ì¤€ë¹„ ìƒíƒœ í™•ì¸...\")\n",
        "\n",
        "# 1. í˜„ìž¬ ë°ì´í„° ê²½ë¡œ í™•ì¸\n",
        "print(f\"ï¿½ï¿½ í˜„ìž¬ ë°ì´í„° ê²½ë¡œ: {path_manager.data_path}\")\n",
        "print(f\"ðŸ“ FESeq ë””ë ‰í† ë¦¬: {os.path.join(path_manager.model_zoo_path, 'FESeq')}\")\n",
        "\n",
        "# 2. í•„ìš”í•œ íŒŒì¼ë“¤ í™•ì¸\n",
        "required_files = [\"train.h5\", \"valid.h5\", \"test.h5\", \"feature_map.json\"]\n",
        "for file in required_files:\n",
        "    file_path = os.path.join(path_manager.data_path, file)\n",
        "    exists = \"âœ…\" if os.path.exists(file_path) else \"âŒ\"\n",
        "    print(f\"{exists} {file}: {file_path}\")\n",
        "\n",
        "# 3. H5 ì„¤ì •ì—ì„œ ê¸°ëŒ€í•˜ëŠ” ê²½ë¡œ í™•ì¸\n",
        "expected_h5_path = os.path.join(os.path.dirname(path_manager.data_path), \"tossctr_h5_dataset\")\n",
        "print(f\"ðŸ“ H5 ì„¤ì • ê¸°ëŒ€ ê²½ë¡œ: {expected_h5_path}\")\n",
        "print(f\"ï¿½ï¿½ ê²½ë¡œ ì¡´ìž¬ ì—¬ë¶€: {'âœ…' if os.path.exists(expected_h5_path) else 'âŒ'}\")\n",
        "\n",
        "# 4. FESeq ì„¤ì • íŒŒì¼ í™•ì¸\n",
        "config_path = os.path.join(path_manager.model_zoo_path, \"FESeq/config/dataset_config.yaml\")\n",
        "print(f\"ï¿½ï¿½ ì„¤ì • íŒŒì¼: {'âœ…' if os.path.exists(config_path) else 'âŒ'} {config_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“‹ ìƒì„±ëœ H5 ë°ì´í„° í™•ì¸...\n",
            "âœ… train.h5: 0.25 MB\n",
            "âœ… valid.h5: 0.08 MB\n",
            "âœ… test.h5: 0.08 MB\n",
            "âœ… feature_map.json: ìƒì„±ë¨\n",
            "   ðŸ“Š ì´ í•„ë“œ ìˆ˜: 80\n",
            "   ðŸ”¢ ì´ í”¼ì²˜ ìˆ˜: 132\n",
            "\n",
            "âœ… H5 ë³€í™˜ ì™„ë£Œ! ëª¨ë“  í•„ìˆ˜ íŒŒì¼ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
            "ðŸŽ¯ ì‚¬ìš©ëœ ìƒ˜í”Œ ìˆ˜: 1,000ê°œ\n",
            "ðŸš€ ì´ì œ FESeq ëª¨ë¸ í›ˆë ¨ì„ ì§„í–‰í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤!\n"
          ]
        }
      ],
      "source": [
        "# ðŸ“Š H5 ë³€í™˜ëœ ë°ì´í„° í™•ì¸\n",
        "print(\"ðŸ“‹ ìƒì„±ëœ H5 ë°ì´í„° í™•ì¸...\")\n",
        "\n",
        "# tossctr_dataset ê²½ë¡œ í™•ì¸ (H5 ë°ì´í„°ê°€ ì €ìž¥ë˜ëŠ” ìœ„ì¹˜)\n",
        "dataset_path = path_manager.data_path\n",
        "h5_files = [\"train.h5\", \"valid.h5\", \"test.h5\"]\n",
        "\n",
        "all_h5_exist = True\n",
        "for h5_file in h5_files:\n",
        "    file_path = os.path.join(dataset_path, h5_file)\n",
        "    if os.path.exists(file_path):\n",
        "        size_mb = os.path.getsize(file_path) / (1024**2)\n",
        "        print(f\"âœ… {h5_file}: {size_mb:.2f} MB\")\n",
        "    else:\n",
        "        print(f\"âŒ {h5_file}: íŒŒì¼ ì—†ìŒ\")\n",
        "        all_h5_exist = False\n",
        "\n",
        "# feature_map.json í™•ì¸\n",
        "feature_map_path = os.path.join(dataset_path, \"feature_map.json\")\n",
        "if os.path.exists(feature_map_path):\n",
        "    print(f\"âœ… feature_map.json: ìƒì„±ë¨\")\n",
        "    \n",
        "    # feature_map ë‚´ìš© í™•ì¸\n",
        "    import json\n",
        "    with open(feature_map_path, 'r') as f:\n",
        "        feature_map = json.load(f)\n",
        "    print(f\"   ðŸ“Š ì´ í•„ë“œ ìˆ˜: {feature_map.get('num_fields', 'Unknown')}\")\n",
        "    print(f\"   ðŸ”¢ ì´ í”¼ì²˜ ìˆ˜: {feature_map.get('total_features', 'Unknown')}\")\n",
        "else:\n",
        "    print(f\"âŒ feature_map.json: íŒŒì¼ ì—†ìŒ\")\n",
        "    all_h5_exist = False\n",
        "\n",
        "if all_h5_exist:\n",
        "    print(f\"\\nâœ… H5 ë³€í™˜ ì™„ë£Œ! ëª¨ë“  í•„ìˆ˜ íŒŒì¼ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "    print(f\"ðŸŽ¯ ì‚¬ìš©ëœ ìƒ˜í”Œ ìˆ˜: {N_SAMPLES:,}ê°œ\")\n",
        "    print(\"ðŸš€ ì´ì œ FESeq ëª¨ë¸ í›ˆë ¨ì„ ì§„í–‰í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤!\")\n",
        "    h5_training_ready = True\n",
        "else:\n",
        "    print(f\"\\nâŒ ì¼ë¶€ H5 íŒŒì¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤. ìœ„ì˜ H5 ë³€í™˜ ë‹¨ê³„ë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n",
        "    h5_training_ready = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n"
          ]
        }
      ],
      "source": [
        "import yaml\n",
        "\n",
        "\n",
        "with open('/Users/hj/projects/TossCTR/colab_feseq/model_zoo/FESeq/config/model_config.yaml', 'r') as f:\n",
        "    data = yaml.safe_load(f)\n",
        "\n",
        "print(data['FESeq_tossctr_h5']['epochs'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸš€ H5 ë°©ì‹ FESeq ëª¨ë¸ í›ˆë ¨ì„ ì‹œìž‘í•©ë‹ˆë‹¤...\n",
            "ðŸ“Š ì„¤ì •: FESeq_tossctr_h5 (H5 ìµœì í™”, ë°°ì¹˜ í¬ê¸° 1024, ì—í¬í¬ 10)\n",
            "â–¶ï¸  ì‹¤í—˜ ID: FESeq_tossctr_h5\n",
            "â³ í›ˆë ¨ ì‹œìž‘... (H5 ë°©ì‹ìœ¼ë¡œ ë” ë¹ ë¥¸ ì²˜ë¦¬)\n",
            "ðŸ“‚ ìž‘ì—… ë””ë ‰í† ë¦¬ ë³€ê²½: /Users/hj/projects/TossCTR/colab_feseq/model_zoo/FESeq\n",
            "ðŸ”§ ì‹¤í–‰ ëª…ë ¹ì–´: /Users/hj/projects/TossCTR/venv/bin/python run_expid.py --config ./config --expid FESeq_tossctr_h5 --gpu -1\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mðŸ”§ ì‹¤í–‰ ëª…ë ¹ì–´: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m.join(cmd)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# ì‹¤í–‰\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m result = \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# ì›ëž˜ ë””ë ‰í† ë¦¬ë¡œ ë³µê·€\u001b[39;00m\n\u001b[32m     39\u001b[39m os.chdir(original_cwd)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/subprocess.py:556\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    554\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Popen(*popenargs, **kwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[32m    555\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m556\u001b[39m         stdout, stderr = \u001b[43mprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    557\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    558\u001b[39m         process.kill()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/subprocess.py:1222\u001b[39m, in \u001b[36mPopen.communicate\u001b[39m\u001b[34m(self, input, timeout)\u001b[39m\n\u001b[32m   1219\u001b[39m     endtime = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1221\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1222\u001b[39m     stdout, stderr = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1224\u001b[39m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[32m   1225\u001b[39m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[32m   1226\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/subprocess.py:2128\u001b[39m, in \u001b[36mPopen._communicate\u001b[39m\u001b[34m(self, input, endtime, orig_timeout)\u001b[39m\n\u001b[32m   2121\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_timeout(endtime, orig_timeout,\n\u001b[32m   2122\u001b[39m                         stdout, stderr,\n\u001b[32m   2123\u001b[39m                         skip_check_and_raise=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   2124\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(  \u001b[38;5;66;03m# Impossible :)\u001b[39;00m\n\u001b[32m   2125\u001b[39m         \u001b[33m'\u001b[39m\u001b[33m_check_timeout(..., skip_check_and_raise=True) \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   2126\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mfailed to raise TimeoutExpired.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2128\u001b[39m ready = \u001b[43mselector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2129\u001b[39m \u001b[38;5;28mself\u001b[39m._check_timeout(endtime, orig_timeout, stdout, stderr)\n\u001b[32m   2131\u001b[39m \u001b[38;5;66;03m# XXX Rewrite these to use non-blocking I/O on the file\u001b[39;00m\n\u001b[32m   2132\u001b[39m \u001b[38;5;66;03m# objects; they are no longer using C stdio!\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/selectors.py:398\u001b[39m, in \u001b[36m_PollLikeSelector.select\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    396\u001b[39m ready = []\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m     fd_event_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# ðŸš€ H5 ë°©ì‹ FESeq ëª¨ë¸ í›ˆë ¨ ì‹¤í–‰\n",
        "if h5_training_ready:\n",
        "    print(\"ðŸš€ H5 ë°©ì‹ FESeq ëª¨ë¸ í›ˆë ¨ì„ ì‹œìž‘í•©ë‹ˆë‹¤...\")\n",
        "    print(\"ðŸ“Š ì„¤ì •: FESeq_tossctr_h5 (H5 ìµœì í™”, ë°°ì¹˜ í¬ê¸° 1024, ì—í¬í¬ 10)\")\n",
        "    \n",
        "    # H5 ì „ìš© ì‹¤í—˜ ID ì‚¬ìš©\n",
        "    expid = \"FESeq_tossctr_h5\"\n",
        "    \n",
        "    try:\n",
        "        # FESeq í›ˆë ¨ ì‹¤í–‰\n",
        "        import subprocess\n",
        "        \n",
        "        print(f\"â–¶ï¸  ì‹¤í—˜ ID: {expid}\")\n",
        "        print(\"â³ í›ˆë ¨ ì‹œìž‘... (H5 ë°©ì‹ìœ¼ë¡œ ë” ë¹ ë¥¸ ì²˜ë¦¬)\")\n",
        "        \n",
        "        # í˜„ìž¬ ìž‘ì—… ë””ë ‰í† ë¦¬ ì €ìž¥\n",
        "        original_cwd = os.getcwd()\n",
        "        \n",
        "        # FESeq ë””ë ‰í† ë¦¬ë¡œ ì´ë™\n",
        "        feseq_dir = os.path.join(path_manager.model_zoo_path, \"FESeq\")\n",
        "        os.chdir(feseq_dir)\n",
        "        print(f\"ðŸ“‚ ìž‘ì—… ë””ë ‰í† ë¦¬ ë³€ê²½: {os.getcwd()}\")\n",
        "        \n",
        "        # run_expid.pyë¡œ H5 ë°©ì‹ í›ˆë ¨ ì‹¤í–‰\n",
        "        cmd = [\n",
        "            sys.executable, \n",
        "            \"run_expid.py\",\n",
        "            \"--config\", \"./config\",\n",
        "            \"--expid\", expid,\n",
        "            \"--gpu\", \"0\" if torch.cuda.is_available() else \"-1\"\n",
        "        ]\n",
        "        \n",
        "        print(f\"ðŸ”§ ì‹¤í–‰ ëª…ë ¹ì–´: {' '.join(cmd)}\")\n",
        "        \n",
        "        # ì‹¤í–‰\n",
        "        result = subprocess.run(cmd, capture_output=True, text=True)\n",
        "        \n",
        "        # ì›ëž˜ ë””ë ‰í† ë¦¬ë¡œ ë³µê·€\n",
        "        os.chdir(original_cwd)\n",
        "        \n",
        "        if result.returncode == 0:\n",
        "            print(\"\\nâœ… H5 ë°©ì‹ FESeq ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!\")\n",
        "            print(\"\\nðŸ“Š í›ˆë ¨ ê²°ê³¼ (ë§ˆì§€ë§‰ ë¶€ë¶„):\")\n",
        "            print(result.stdout[-2000:] if result.stdout else \"ì¶œë ¥ ì—†ìŒ\")\n",
        "        else:\n",
        "            print(f\"\\nâŒ í›ˆë ¨ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ì¢…ë£Œ ì½”ë“œ: {result.returncode})\")\n",
        "            print(\"\\nðŸ“„ ì—ëŸ¬ ë¡œê·¸:\")\n",
        "            print(result.stderr if result.stderr else \"ì—ëŸ¬ ì¶œë ¥ ì—†ìŒ\")\n",
        "            \n",
        "            # CSV ë°©ì‹ìœ¼ë¡œ í´ë°±\n",
        "            print(\"\\nðŸ”„ ëŒ€ì•ˆ: CSV ë°©ì‹ìœ¼ë¡œ í´ë°± ì‹œë„...\")\n",
        "            os.chdir(feseq_dir)\n",
        "            fallback_cmd = cmd.copy()\n",
        "            fallback_cmd[fallback_cmd.index(expid)] = \"FESeq_tossctr\"\n",
        "            \n",
        "            fallback_result = subprocess.run(fallback_cmd, capture_output=True, text=True)\n",
        "            os.chdir(original_cwd)\n",
        "            \n",
        "            if fallback_result.returncode == 0:\n",
        "                print(\"âœ… CSV ë°©ì‹ í´ë°± í›ˆë ¨ ì™„ë£Œ!\")\n",
        "            else:\n",
        "                print(\"âŒ í´ë°± í›ˆë ¨ë„ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n",
        "                \n",
        "    except Exception as e:\n",
        "        # ì›ëž˜ ë””ë ‰í† ë¦¬ë¡œ ë³µê·€\n",
        "        if 'original_cwd' in locals():\n",
        "            os.chdir(original_cwd)\n",
        "            \n",
        "        print(f\"\\nâŒ ì˜ˆê¸°ì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        \n",
        "else:\n",
        "    print(\"âŒ H5 í›ˆë ¨ ì¤€ë¹„ê°€ ì™„ë£Œë˜ì§€ ì•Šì•„ í›ˆë ¨ì„ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
        "    print(\"ìœ„ì˜ ë‹¨ê³„ë“¤ì„ ì™„ë£Œí•œ í›„ ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”® Step 7: ì¶”ë¡  ë° ì œì¶œ íŒŒì¼ ìƒì„±\n",
        "\n",
        "í›ˆë ¨ëœ FESeq ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ test.parquet ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ê³  ì œì¶œ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì¶”ë¡ ì„ ìœ„í•œ í•„ìˆ˜ ìž„í¬íŠ¸\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import h5py\n",
        "import json\n",
        "import subprocess\n",
        "\n",
        "# FuxiCTR ê´€ë ¨ ìž„í¬íŠ¸\n",
        "from fuxictr.features import FeatureMapAbsTime\n",
        "from fuxictr.pytorch.dataloaders import H5DataLoader\n",
        "from fuxictr.utils import load_config\n",
        "\n",
        "# FESeq ëª¨ë¸ ìž„í¬íŠ¸\n",
        "sys.path.append(os.path.join(path_manager.model_zoo_path, 'FESeq'))\n",
        "from src.FESeq import FESeq\n",
        "\n",
        "print(\"âœ… ì¶”ë¡ ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ\n",
        "print(\"ðŸ”„ í›ˆë ¨ëœ FESeq ëª¨ë¸ ë¡œë“œ ì¤‘...\")\n",
        "\n",
        "# ì„¤ì • íŒŒì¼ ë¡œë“œ\n",
        "config_path = os.path.join(path_manager.model_zoo_path, \"FESeq/config\")\n",
        "params = load_config(config_path, \"FESeq_tossctr\")\n",
        "params['gpu'] = 0 if torch.cuda.is_available() else -1\n",
        "\n",
        "# ë°ì´í„° ê²½ë¡œ ë™ì  ì„¤ì •\n",
        "dataset_path = os.path.join(os.path.dirname(path_manager.data_path), \"tossctr_dataset\")\n",
        "params['data_root'] = os.path.dirname(dataset_path)\n",
        "\n",
        "print(f\"âœ… ëª¨ë¸ ì„¤ì • ë¡œë“œ ì™„ë£Œ\")\n",
        "print(f\"ðŸ“‹ ì£¼ìš” ì„¤ì •:\")\n",
        "print(f\"   - ëª¨ë¸: {params.get('model', 'N/A')}\")\n",
        "print(f\"   - ë°°ì¹˜ í¬ê¸°: {params.get('batch_size', 'N/A')}\")\n",
        "print(f\"   - ìž„ë² ë”© ì°¨ì›: {params.get('embedding_dim', 'N/A')}\")\n",
        "print(f\"   - GPU: {params['gpu']}\")\n",
        "print(f\"   - ë°ì´í„° ê²½ë¡œ: {dataset_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature Map ë° ëª¨ë¸ ì´ˆê¸°í™”\n",
        "print(\"ðŸ—ºï¸ Feature Map ë¡œë“œ ì¤‘...\")\n",
        "\n",
        "feature_map_json = os.path.join(dataset_path, \"feature_map.json\")\n",
        "\n",
        "if os.path.exists(feature_map_json):\n",
        "    # Feature Map ë¡œë“œ\n",
        "    feature_map = FeatureMapAbsTime(params['dataset_id'], dataset_path)\n",
        "    feature_map.load(feature_map_json, params)\n",
        "    \n",
        "    print(f\"âœ… Feature Map ë¡œë“œ ì™„ë£Œ\")\n",
        "    print(f\"ðŸ“Š í”¼ì²˜ ìˆ˜: {len(feature_map.features)}\")\n",
        "    \n",
        "    # FESeq ëª¨ë¸ ì´ˆê¸°í™”\n",
        "    print(\"\\nðŸ§  FESeq ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...\")\n",
        "    model = FESeq(feature_map, params=params, **params)\n",
        "    \n",
        "    # í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ\n",
        "    checkpoint_paths = [\n",
        "        os.path.join(path_manager.model_zoo_path, f\"FESeq/checkpoints/tossctr_dataset/FESeq_tossctr.model\"),\n",
        "        os.path.join(path_manager.model_zoo_path, f\"FESeq/checkpoints/tossctr_dataset/FESeq_tossctr_h5.model\"),\n",
        "        os.path.join(path_manager.model_zoo_path, f\"FESeq/checkpoints/FESeq_tossctr.model\"),\n",
        "        os.path.join(path_manager.model_zoo_path, f\"FESeq/checkpoints/FESeq_tossctr_h5.model\")\n",
        "    ]\n",
        "    \n",
        "    checkpoint_loaded = False\n",
        "    for checkpoint_path in checkpoint_paths:\n",
        "        if os.path.exists(checkpoint_path):\n",
        "            try:\n",
        "                model.load_weights(checkpoint_path)\n",
        "                print(f\"âœ… í›ˆë ¨ëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ: {checkpoint_path}\")\n",
        "                model.eval()\n",
        "                print(\"âœ… ëª¨ë¸ì´ ì¶”ë¡  ëª¨ë“œë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "                checkpoint_loaded = True\n",
        "                break\n",
        "            except Exception as e:\n",
        "                print(f\"âš ï¸  {checkpoint_path} ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
        "                continue\n",
        "    \n",
        "    if not checkpoint_loaded:\n",
        "        print(\"âŒ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        print(\"ë¨¼ì € ëª¨ë¸ í›ˆë ¨ì„ ì™„ë£Œí•´ì£¼ì„¸ìš”.\")\n",
        "        model = None\n",
        "else:\n",
        "    print(f\"âŒ Feature map íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {feature_map_json}\")\n",
        "    print(\"ë¨¼ì € ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ì™„ë£Œí•˜ê±°ë‚˜ ëª¨ë¸ í›ˆë ¨ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n",
        "    model = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì„¤ì • ë¡œë“œ ì´í›„ì— ë¶™ì—¬ì£¼ì„¸ìš”\n",
        "dataset_path = path_manager.data_path\n",
        "params['data_root'] = os.path.dirname(dataset_path)\n",
        "params['data_format'] = 'h5'\n",
        "params['train_data'] = os.path.join(dataset_path, 'train.h5')\n",
        "params['valid_data'] = os.path.join(dataset_path, 'valid.h5')\n",
        "params['test_data']  = os.path.join(dataset_path, 'test.h5')\n",
        "\n",
        "print(f\"ë°ì´í„° ë£¨íŠ¸: {params['data_root']}\")\n",
        "print(f\"train: {params['train_data']}\")\n",
        "print(f\"valid: {params['valid_data']}\")\n",
        "print(f\"test : {params['test_data']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì¶”ë¡  ì‹¤í–‰\n",
        "import traceback\n",
        "\n",
        "if model is not None:\n",
        "    print(\"ðŸ“Š ì¶”ë¡  ë°ì´í„° ë¡œë” ìƒì„± ì¤‘...\")\n",
        "    \n",
        "    test_h5_path = os.path.join(dataset_path, \"test.h5\")\n",
        "    \n",
        "    if os.path.exists(test_h5_path):\n",
        "        try:\n",
        "            # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë” ìƒì„±\n",
        "            test_loader = H5DataLoader(feature_map, stage='test', **params).make_iterator()\n",
        "            \n",
        "            print(\"ðŸ”® ëª¨ë¸ ì¶”ë¡  ì‹œìž‘...\")\n",
        "            predictions = []\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                for batch_idx, batch_data in enumerate(test_loader):\n",
        "                    # ë°°ì¹˜ ì˜ˆì¸¡\n",
        "                    output = model(batch_data)\n",
        "                    batch_pred = torch.sigmoid(output['y_pred']).cpu().numpy().flatten()\n",
        "                    predictions.extend(batch_pred)\n",
        "                    \n",
        "                    # ì§„í–‰ ìƒí™© ì¶œë ¥\n",
        "                    if batch_idx % 10 == 0:\n",
        "                        print(f\"  ì²˜ë¦¬ëœ ë°°ì¹˜: {batch_idx + 1}, ëˆ„ì  ì˜ˆì¸¡ ìˆ˜: {len(predictions)}\")\n",
        "            \n",
        "            print(f\"\\nâœ… ì¶”ë¡  ì™„ë£Œ! ì´ {len(predictions)}ê°œ ìƒ˜í”Œ ì˜ˆì¸¡\")\n",
        "            print(f\"ðŸ“Š ì˜ˆì¸¡ê°’ ë²”ìœ„: {min(predictions):.6f} ~ {max(predictions):.6f}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ì¶”ë¡  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "            # â¬ ì´ ë¶€ë¶„ì´ ìˆ˜ì •/ì¶”ê°€ëœ ë‚´ìš©ìž…ë‹ˆë‹¤.\n",
        "            detailed_error = traceback.format_exc()\n",
        "            print(f\"âŒ ì¶”ë¡  ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\\n\")\n",
        "            print(f\"ì—ëŸ¬ ìœ í˜•: {type(e).__name__}\")\n",
        "            print(f\"ì—ëŸ¬ ë©”ì‹œì§€: {e}\\n\")\n",
        "            print(\"------ ìƒì„¸ ì •ë³´ (Traceback) ------\")\n",
        "            print(detailed_error)\n",
        "            print(\"---------------------------------\")\n",
        "            predictions = None\n",
        "    else:\n",
        "        print(f\"âŒ test.h5 íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {test_h5_path}\")\n",
        "        predictions = None\n",
        "else:\n",
        "    print(\"âŒ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
        "    predictions = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì œì¶œ íŒŒì¼ ìƒì„±\n",
        "if predictions is not None:\n",
        "    print(\"ðŸ“ ì œì¶œ íŒŒì¼ ìƒì„± ì¤‘...\")\n",
        "    \n",
        "    # sample_submission.csv ë¡œë“œ\n",
        "    sample_submission_path = path_manager.get_sample_submission_path()\n",
        "    \n",
        "    if sample_submission_path and os.path.exists(sample_submission_path):\n",
        "        submission_df = pd.read_csv(sample_submission_path)\n",
        "        print(f\"âœ… sample_submission.csv ë¡œë“œ ì™„ë£Œ: {submission_df.shape}\")\n",
        "        \n",
        "        # ì˜ˆì¸¡ê°’ ê¸¸ì´ í™•ì¸ ë° ì¡°ì •\n",
        "        if len(predictions) != len(submission_df):\n",
        "            print(f\"âš ï¸  ì˜ˆì¸¡ê°’ ê¸¸ì´ ë¶ˆì¼ì¹˜: ì˜ˆì¸¡ê°’ {len(predictions)}, ì œì¶œíŒŒì¼ {len(submission_df)}\")\n",
        "            \n",
        "            if len(predictions) > len(submission_df):\n",
        "                predictions = predictions[:len(submission_df)]\n",
        "                print(f\"âœ‚ï¸  ì˜ˆì¸¡ê°’ì„ {len(submission_df)}ê°œë¡œ ìž˜ëžìŠµë‹ˆë‹¤.\")\n",
        "            else:\n",
        "                mean_pred = np.mean(predictions)\n",
        "                predictions.extend([mean_pred] * (len(submission_df) - len(predictions)))\n",
        "                print(f\"ðŸ“ˆ ì˜ˆì¸¡ê°’ì„ í‰ê· ê°’({mean_pred:.4f})ë¡œ {len(submission_df)}ê°œê¹Œì§€ ì±„ì› ìŠµë‹ˆë‹¤.\")\n",
        "        \n",
        "        # ì˜ˆì¸¡ê°’ì„ ì œì¶œ íŒŒì¼ì— í• ë‹¹\n",
        "        submission_df['clicked'] = predictions\n",
        "        \n",
        "        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±\n",
        "        output_dir = os.path.join(path_manager.base_path, \"data/output\")\n",
        "        path_manager.ensure_directory(output_dir)\n",
        "        \n",
        "        # ì œì¶œ íŒŒì¼ ì €ìž¥\n",
        "        output_path = os.path.join(output_dir, \"feseq_submission.csv\")\n",
        "        submission_df.to_csv(output_path, index=False)\n",
        "        \n",
        "        print(f\"\\nâœ… ì œì¶œ íŒŒì¼ ìƒì„± ì™„ë£Œ: {output_path}\")\n",
        "        print(f\"\\nðŸ“Š ì˜ˆì¸¡ í†µê³„:\")\n",
        "        print(f\"   - ìµœì†Ÿê°’: {np.min(predictions):.6f}\")\n",
        "        print(f\"   - ìµœëŒ“ê°’: {np.max(predictions):.6f}\")\n",
        "        print(f\"   - í‰ê· ê°’: {np.mean(predictions):.6f}\")\n",
        "        print(f\"   - í‘œì¤€íŽ¸ì°¨: {np.std(predictions):.6f}\")\n",
        "        \n",
        "        # ì˜ˆì¸¡ê°’ ë¶„í¬ í™•ì¸\n",
        "        print(f\"\\nðŸ“ˆ ì˜ˆì¸¡ê°’ ë¶„í¬:\")\n",
        "        hist, bins = np.histogram(predictions, bins=10)\n",
        "        for i in range(len(hist)):\n",
        "            print(f\"   {bins[i]:.3f}-{bins[i+1]:.3f}: {hist[i]:,}ê°œ\")\n",
        "            \n",
        "    else:\n",
        "        print(\"âŒ sample_submission.csvë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "else:\n",
        "    print(\"âŒ ì˜ˆì¸¡ê°’ì´ ì—†ìŠµë‹ˆë‹¤. ì¶”ë¡ ì„ ë¨¼ì € ì™„ë£Œí•´ì£¼ì„¸ìš”.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ê²°ê³¼ ê²€ì¦ ë° ìµœì¢… í™•ì¸\n",
        "print(\"ðŸ” ìµœì¢… ê²°ê³¼ ê²€ì¦...\")\n",
        "\n",
        "output_dir = os.path.join(path_manager.base_path, \"data/output\")\n",
        "feseq_submission_path = os.path.join(output_dir, \"feseq_submission.csv\")\n",
        "\n",
        "if os.path.exists(feseq_submission_path):\n",
        "    # ì œì¶œ íŒŒì¼ ë¡œë“œ ë° ê²€ì¦\n",
        "    final_submission = pd.read_csv(feseq_submission_path)\n",
        "    \n",
        "    print(f\"âœ… ìµœì¢… ì œì¶œ íŒŒì¼ ê²€ì¦ ì™„ë£Œ:\")\n",
        "    print(f\"   ðŸ“ íŒŒì¼ ê²½ë¡œ: {feseq_submission_path}\")\n",
        "    print(f\"   ðŸ“Š íŒŒì¼ í¬ê¸°: {final_submission.shape}\")\n",
        "    print(f\"   ðŸ“‹ ì»¬ëŸ¼: {list(final_submission.columns)}\")\n",
        "    \n",
        "    # ì œì¶œ íŒŒì¼ í˜•ì‹ ê²€ì¦\n",
        "    required_columns = ['ID', 'clicked']\n",
        "    missing_columns = [col for col in required_columns if col not in final_submission.columns]\n",
        "    \n",
        "    if missing_columns:\n",
        "        print(f\"âŒ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_columns}\")\n",
        "    else:\n",
        "        print(\"âœ… ì œì¶œ íŒŒì¼ í˜•ì‹ ê²€ì¦ í†µê³¼\")\n",
        "    \n",
        "    # ì˜ˆì¸¡ê°’ ë²”ìœ„ ê²€ì¦\n",
        "    clicked_values = final_submission['clicked']\n",
        "    if clicked_values.min() >= 0 and clicked_values.max() <= 1:\n",
        "        print(\"âœ… ì˜ˆì¸¡ê°’ ë²”ìœ„ ê²€ì¦ í†µê³¼ (0-1 ì‚¬ì´)\")\n",
        "    else:\n",
        "        print(f\"âš ï¸  ì˜ˆì¸¡ê°’ ë²”ìœ„ ì£¼ì˜: {clicked_values.min():.6f} ~ {clicked_values.max():.6f}\")\n",
        "    \n",
        "    # ê²°ì¸¡ê°’ í™•ì¸\n",
        "    if clicked_values.isnull().sum() == 0:\n",
        "        print(\"âœ… ê²°ì¸¡ê°’ ì—†ìŒ\")\n",
        "    else:\n",
        "        print(f\"âš ï¸  ê²°ì¸¡ê°’ ë°œê²¬: {clicked_values.isnull().sum()}ê°œ\")\n",
        "    \n",
        "    # ìƒ˜í”Œ ì¶œë ¥\n",
        "    print(f\"\\nðŸ“‹ ì œì¶œ íŒŒì¼ ìƒ˜í”Œ:\")\n",
        "    print(final_submission.head(10))\n",
        "    \n",
        "    print(f\"\\nðŸŽ‰ FESeq ëª¨ë¸ ì¶”ë¡  ë° ì œì¶œ íŒŒì¼ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
        "    print(f\"ðŸ’¾ ì œì¶œ íŒŒì¼: {feseq_submission_path}\")\n",
        "    \n",
        "else:\n",
        "    print(f\"âŒ ì œì¶œ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {feseq_submission_path}\")\n",
        "    print(\"ì´ì „ ë‹¨ê³„ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“‹ ì‹¤í–‰ ìš”ì•½\n",
        "\n",
        "### ðŸŽ¯ ì™„ë£Œëœ ìž‘ì—…\n",
        "1. **ë™ì  ê²½ë¡œ ì„¤ì •**: Colabê³¼ ë¡œì»¬ í™˜ê²½ì„ ìžë™ìœ¼ë¡œ ê°ì§€í•˜ì—¬ ê²½ë¡œ ì„¤ì •\n",
        "2. **ëª¨ë¸ í›ˆë ¨**: FESeq ëª¨ë¸ì´ TossCTR ë°ì´í„°ì…‹ì—ì„œ ì„±ê³µì ìœ¼ë¡œ í›ˆë ¨ë¨\n",
        "3. **ì¶”ë¡ **: í›ˆë ¨ëœ ëª¨ë¸ë¡œ test.parquet ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ ìˆ˜í–‰\n",
        "4. **ì œì¶œ íŒŒì¼**: sample_submission.csv í˜•ì‹ì— ë§žëŠ” ì œì¶œ íŒŒì¼ ìƒì„±\n",
        "\n",
        "### ðŸ“ ìƒì„±ëœ íŒŒì¼\n",
        "- `{base_path}/data/output/feseq_submission.csv`: FESeq ëª¨ë¸ì˜ ìµœì¢… ì œì¶œ íŒŒì¼\n",
        "\n",
        "### ðŸš€ ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ\n",
        "1. **ì„±ëŠ¥ ê°œì„ **: í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ìœ¼ë¡œ ëª¨ë¸ ì„±ëŠ¥ í–¥ìƒ\n",
        "2. **ì•™ìƒë¸”**: ë‹¤ë¥¸ ëª¨ë¸ê³¼ ê²°í•©í•˜ì—¬ ì˜ˆì¸¡ ì„±ëŠ¥ ê°œì„ \n",
        "3. **í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§**: ì¶”ê°€ í”¼ì²˜ë¥¼ í™œìš©í•œ ì„±ëŠ¥ í–¥ìƒ\n",
        "\n",
        "### ðŸ’¡ v4.0 ê°œì„ ì‚¬í•­\n",
        "- **ë™ì  ê²½ë¡œ**: Colab/ë¡œì»¬ í™˜ê²½ ìžë™ ê°ì§€\n",
        "- **ì¤‘ë³µ ì œê±°**: PathManager í´ëž˜ìŠ¤ë¡œ ê²½ë¡œ ê´€ë¦¬ ì¼ì›í™”\n",
        "- **ì—ëŸ¬ ì²˜ë¦¬**: ë” ë‚˜ì€ í´ë°± ë©”ì»¤ë‹ˆì¦˜ê³¼ ë””ë²„ê¹… ì •ë³´\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

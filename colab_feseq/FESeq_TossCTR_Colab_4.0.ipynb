{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FESeq Model Training on TossCTR Dataset (v4.0 - ë™ì  ê²½ë¡œ ìµœì í™”)\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì€ TossCTR ë°ì´í„°ì…‹ì—ì„œ FESeq ëª¨ë¸ì„ í›ˆë ¨í•˜ê¸° ìœ„í•œ H5 ìµœì í™” Colab í™˜ê²½ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
        "\n",
        "## ðŸŽ‰ v4.0 ê°œì„ ì‚¬í•­\n",
        "- **ë™ì  ê²½ë¡œ ì„¤ì •**: Colabê³¼ ë¡œì»¬ í™˜ê²½ ìžë™ ê°ì§€\n",
        "- **ì¤‘ë³µ ì½”ë“œ ì œê±°**: í•¨ìˆ˜í™”ë¥¼ í†µí•œ ì½”ë“œ íš¨ìœ¨ì„± ê°œì„ \n",
        "- **ì ˆëŒ€ ê²½ë¡œ í•´ê²°**: ëª¨ë“  ê²½ë¡œë¥¼ ë™ì ìœ¼ë¡œ ì„¤ì •\n",
        "- **ë” ë‚˜ì€ ì—ëŸ¬ ì²˜ë¦¬**: ìŠ¤ë§ˆíŠ¸í•œ í´ë°± ë©”ì»¤ë‹ˆì¦˜\n",
        "\n",
        "## ðŸš€ ì£¼ìš” ê°œì„ ì‚¬í•­ (H5 ë²„ì „)\n",
        "- **H5 ì§ì ‘ ë³€í™˜**: Parquet â†’ H5 ì§ì ‘ ë³€í™˜ìœ¼ë¡œ CSV ì¤‘ê°„ ë‹¨ê³„ ì œê±°\n",
        "- **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**: CSV ëŒ€ë¹„ 50% ì ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©\n",
        "- **ì²˜ë¦¬ ì†ë„**: 2ë°° ë¹ ë¥¸ ë°ì´í„° ì²˜ë¦¬ ë° ë¡œë”©\n",
        "- **ëŒ€ìš©ëŸ‰ ì§€ì›**: ì „ì²´ ë°ì´í„°ì…‹ë„ ì•ˆì •ì ìœ¼ë¡œ ì²˜ë¦¬\n",
        "\n",
        "## ðŸ“‹ ì‹¤í–‰ ìˆœì„œ\n",
        "1. í™˜ê²½ ì„¤ì • ë° íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
        "2. GitHubì—ì„œ ì½”ë“œ í´ë¡ \n",
        "3. Parquet â†’ H5 ì§ì ‘ ë³€í™˜\n",
        "4. FESeq ëª¨ë¸ í›ˆë ¨\n",
        "5. ì¶”ë¡  ë° ì œì¶œ íŒŒì¼ ìƒì„±\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ› ï¸ Step 0: ë™ì  ê²½ë¡œ ì„¤ì • ì‹œìŠ¤í…œ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "class PathManager:\n",
        "    \"\"\"ë™ì  ê²½ë¡œ ê´€ë¦¬ë¥¼ ìœ„í•œ í´ëž˜ìŠ¤\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.is_colab = self._detect_colab()\n",
        "        self.base_path = self._find_base_path()\n",
        "        self.setup_paths()\n",
        "        \n",
        "    def _detect_colab(self):\n",
        "        \"\"\"Colab í™˜ê²½ ê°ì§€\"\"\"\n",
        "        try:\n",
        "            import google.colab\n",
        "            return True\n",
        "        except ImportError:\n",
        "            return False\n",
        "    \n",
        "    def _find_base_path(self):\n",
        "        \"\"\"TossCTR í”„ë¡œì íŠ¸ ê¸°ë³¸ ê²½ë¡œ ì°¾ê¸°\"\"\"\n",
        "        current_path = os.getcwd()\n",
        "        \n",
        "        # ì´ë¯¸ TossCTR í”„ë¡œì íŠ¸ ë‚´ì— ìžˆëŠ”ì§€ í™•ì¸\n",
        "        if 'TossCTR' in current_path:\n",
        "            # TossCTRê¹Œì§€ì˜ ê²½ë¡œ ì¶”ì¶œ\n",
        "            parts = current_path.split('/')\n",
        "            tossctr_idx = parts.index('TossCTR')\n",
        "            base_path = '/'.join(parts[:tossctr_idx+1])\n",
        "            return base_path\n",
        "        \n",
        "        # Colab í™˜ê²½\n",
        "        if self.is_colab:\n",
        "            if os.path.exists('/content/TossCTR'):\n",
        "                return '/content/TossCTR'\n",
        "            else:\n",
        "                return '/content'\n",
        "        \n",
        "        # ë¡œì»¬ í™˜ê²½\n",
        "        possible_paths = [\n",
        "            '/Users/hj/projects/TossCTR',\n",
        "            os.path.expanduser('~/projects/TossCTR'),\n",
        "            current_path\n",
        "        ]\n",
        "        \n",
        "        for path in possible_paths:\n",
        "            if os.path.exists(path) and os.path.exists(os.path.join(path, 'colab_feseq')):\n",
        "                return path\n",
        "        \n",
        "        return current_path\n",
        "    \n",
        "    def setup_paths(self):\n",
        "        \"\"\"ëª¨ë“  í•„ìš”í•œ ê²½ë¡œ ì„¤ì •\"\"\"\n",
        "        self.colab_feseq_path = os.path.join(self.base_path, 'colab_feseq')\n",
        "        self.data_path = os.path.join(self.colab_feseq_path, 'data', 'tossctr')\n",
        "        self.model_zoo_path = os.path.join(self.colab_feseq_path, 'model_zoo')\n",
        "        self.preprocessing_path = os.path.join(self.colab_feseq_path, 'preprocessing')\n",
        "        \n",
        "        # ì›ë³¸ ë°ì´í„° ê²½ë¡œ ì„¤ì •\n",
        "        if self.is_colab:\n",
        "            self.raw_data_path = self._find_raw_data_colab()\n",
        "        else:\n",
        "            self.raw_data_path = os.path.join(self.base_path, 'data', 'raw')\n",
        "    \n",
        "    def _find_raw_data_colab(self):\n",
        "        \"\"\"Colabì—ì„œ ì›ë³¸ ë°ì´í„° ê²½ë¡œ ì°¾ê¸°\"\"\"\n",
        "        possible_paths = [\n",
        "            '/content/drive/MyDrive/data/TossCTR/raw',\n",
        "            '/content/TossCTR/data/raw',\n",
        "            '/content/data/raw'\n",
        "        ]\n",
        "        \n",
        "        for path in possible_paths:\n",
        "            if os.path.exists(path):\n",
        "                return path\n",
        "        \n",
        "        return '/content/drive/MyDrive/data/TossCTR/raw'\n",
        "    \n",
        "    def get_train_parquet_path(self):\n",
        "        \"\"\"train.parquet íŒŒì¼ ê²½ë¡œ ì°¾ê¸°\"\"\"\n",
        "        possible_paths = [\n",
        "            os.path.join(self.raw_data_path, 'train.parquet'),\n",
        "            '/content/drive/MyDrive/data/TossCTR/raw/train.parquet',\n",
        "            '/Users/hj/projects/TossCTR/data/raw/train.parquet'\n",
        "        ]\n",
        "        \n",
        "        for path in possible_paths:\n",
        "            if os.path.exists(path):\n",
        "                return path\n",
        "        \n",
        "        return None\n",
        "    \n",
        "    def get_test_parquet_path(self):\n",
        "        \"\"\"test.parquet íŒŒì¼ ê²½ë¡œ ì°¾ê¸°\"\"\"\n",
        "        possible_paths = [\n",
        "            os.path.join(self.raw_data_path, 'test.parquet'),\n",
        "            '/content/drive/MyDrive/data/TossCTR/raw/test.parquet',\n",
        "            '/Users/hj/projects/TossCTR/data/raw/test.parquet'\n",
        "        ]\n",
        "        \n",
        "        for path in possible_paths:\n",
        "            if os.path.exists(path):\n",
        "                return path\n",
        "        \n",
        "        return None\n",
        "    \n",
        "    def get_sample_submission_path(self):\n",
        "        \"\"\"sample_submission.csv íŒŒì¼ ê²½ë¡œ ì°¾ê¸°\"\"\"\n",
        "        possible_paths = [\n",
        "            os.path.join(self.raw_data_path, 'sample_submission.csv'),\n",
        "            '/content/drive/MyDrive/data/TossCTR/raw/sample_submission.csv',\n",
        "            '/Users/hj/projects/TossCTR/data/raw/sample_submission.csv'\n",
        "        ]\n",
        "        \n",
        "        for path in possible_paths:\n",
        "            if os.path.exists(path):\n",
        "                return path\n",
        "        \n",
        "        return None\n",
        "    \n",
        "    def ensure_directory(self, path):\n",
        "        \"\"\"ë””ë ‰í† ë¦¬ ìƒì„± í™•ì¸\"\"\"\n",
        "        os.makedirs(path, exist_ok=True)\n",
        "        return path\n",
        "    \n",
        "    def cd_to_colab_feseq(self):\n",
        "        \"\"\"colab_feseq ë””ë ‰í† ë¦¬ë¡œ ì´ë™\"\"\"\n",
        "        if os.path.exists(self.colab_feseq_path):\n",
        "            os.chdir(self.colab_feseq_path)\n",
        "            print(f\"ðŸ“ ìž‘ì—… ë””ë ‰í† ë¦¬ ë³€ê²½: {self.colab_feseq_path}\")\n",
        "        else:\n",
        "            print(f\"âŒ colab_feseq ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.colab_feseq_path}\")\n",
        "    \n",
        "    def setup_python_path(self):\n",
        "        \"\"\"Python ê²½ë¡œ ì„¤ì •\"\"\"\n",
        "        paths_to_add = [self.colab_feseq_path, self.preprocessing_path]\n",
        "        \n",
        "        for path in paths_to_add:\n",
        "            if path not in sys.path and os.path.exists(path):\n",
        "                sys.path.insert(0, path)\n",
        "        \n",
        "        os.environ['PYTHONPATH'] = ':'.join(paths_to_add)\n",
        "        print(f\"âœ… PYTHONPATH ì„¤ì • ì™„ë£Œ\")\n",
        "    \n",
        "    def print_status(self):\n",
        "        \"\"\"í˜„ìž¬ ê²½ë¡œ ìƒíƒœ ì¶œë ¥\"\"\"\n",
        "        print(\"ðŸ” ê²½ë¡œ ì„¤ì • ìƒíƒœ:\")\n",
        "        print(f\"   - í™˜ê²½: {'Colab' if self.is_colab else 'Local'}\")\n",
        "        print(f\"   - ê¸°ë³¸ ê²½ë¡œ: {self.base_path}\")\n",
        "        print(f\"   - colab_feseq: {self.colab_feseq_path}\")\n",
        "        print(f\"   - ë°ì´í„°: {self.data_path}\")\n",
        "        print(f\"   - ì›ë³¸ ë°ì´í„°: {self.raw_data_path}\")\n",
        "\n",
        "# ì „ì—­ PathManager ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
        "path_manager = PathManager()\n",
        "path_manager.print_status()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸš€ Step 1: í™˜ê²½ ì„¤ì • ë° GPU í™•ì¸\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\n",
        "import torch\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "else:\n",
        "    print(\"âš ï¸  GPU not available, using CPU\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Colab í™˜ê²½ì—ì„œë§Œ Google Drive ë§ˆìš´íŠ¸\n",
        "if path_manager.is_colab:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "else:\n",
        "    print(\"ðŸ’» ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘ìž…ë‹ˆë‹¤.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“¦ Step 2: ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "packages = [\"pandas\", \"numpy\", \"scikit-learn\", \"PyYAML\", \"h5py\", \"tqdm\", \"pyarrow\"]\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\"] + packages)\n",
        "\n",
        "# PyTorch ì„¤ì¹˜ (GPU ë²„ì „)\n",
        "if torch.cuda.is_available():\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"torch\", \"torchvision\", \"--index-url\", \"https://download.pytorch.org/whl/cu118\"])\n",
        "else:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"torch\", \"torchvision\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“ Step 3: GitHubì—ì„œ ì½”ë“œ í´ë¡ \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GitHubì—ì„œ TossCTR ë ˆí¬ì§€í† ë¦¬ í´ë¡ \n",
        "import os\n",
        "\n",
        "# í˜„ìž¬ ìœ„ì¹˜ í™•ì¸\n",
        "current_path = os.getcwd()\n",
        "print(f\"ðŸ“ í˜„ìž¬ ìœ„ì¹˜: {current_path}\")\n",
        "\n",
        "# Colab í™˜ê²½ì—ì„œë§Œ í´ë¡  ìˆ˜í–‰\n",
        "if path_manager.is_colab and not os.path.exists('/content/TossCTR'):\n",
        "    print(\"ðŸ“¥ GitHubì—ì„œ TossCTR ë ˆí¬ì§€í† ë¦¬ë¥¼ í´ë¡ í•©ë‹ˆë‹¤...\")\n",
        "    os.system(\"git clone https://github.com/kwonhwijun/TossCTR.git /content/TossCTR\")\n",
        "    \n",
        "    # PathManager ìž¬ì´ˆê¸°í™” (í´ë¡  í›„ ê²½ë¡œ ì—…ë°ì´íŠ¸)\n",
        "    path_manager = PathManager()\n",
        "else:\n",
        "    print(\"âœ… TossCTR ë””ë ‰í† ë¦¬ê°€ ì´ë¯¸ ì¡´ìž¬í•©ë‹ˆë‹¤.\")\n",
        "\n",
        "# colab_feseq ë””ë ‰í† ë¦¬ë¡œ ì´ë™\n",
        "path_manager.cd_to_colab_feseq()\n",
        "\n",
        "# Python ê²½ë¡œ ì„¤ì •\n",
        "path_manager.setup_python_path()\n",
        "\n",
        "# í˜„ìž¬ ë””ë ‰í† ë¦¬ êµ¬ì¡° í™•ì¸\n",
        "print(\"\\nðŸ“ í˜„ìž¬ ë””ë ‰í† ë¦¬ êµ¬ì¡°:\")\n",
        "os.system(\"ls -la\")\n",
        "\n",
        "# ì¤‘ìš”í•œ íŒŒì¼ë“¤ì´ ìžˆëŠ”ì§€ í™•ì¸\n",
        "print(\"\\nðŸ” ì¤‘ìš” íŒŒì¼ í™•ì¸:\")\n",
        "files_to_check = [\n",
        "    (\"run_feseq.py\", \"run_feseq.py\"),\n",
        "    (\"FESeq ëª¨ë¸\", \"model_zoo/FESeq\"),\n",
        "    (\"ë°ì´í„° ë””ë ‰í† ë¦¬\", \"data/tossctr\"),\n",
        "    (\"ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸\", \"preprocessing/tossctr_parquet_to_h5.py\")\n",
        "]\n",
        "\n",
        "for name, file_path in files_to_check:\n",
        "    full_path = os.path.join(path_manager.colab_feseq_path, file_path)\n",
        "    exists = \"âœ…\" if os.path.exists(full_path) else \"âŒ\"\n",
        "    print(f\"{exists} {name}: {file_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âš™ï¸ Step 4: FuxiCTR í™˜ê²½ ì„¤ì •\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FuxiCTR ì„¤ì¹˜\n",
        "try:\n",
        "    print(\"ðŸ“¦ FuxiCTR ì„¤ì¹˜ ì¤‘...\")\n",
        "    os.system(\"python setup.py develop\")\n",
        "    print(\"âœ… FuxiCTR í™˜ê²½ ì„¤ì • ì™„ë£Œ\")\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸  setup.py ì„¤ì¹˜ ì‹¤íŒ¨: {e}\")\n",
        "    print(\"ðŸ“¦ pipìœ¼ë¡œ ëŒ€ì²´ ì„¤ì¹˜ ì‹œë„...\")\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-e\", \".\"])\n",
        "    print(\"âœ… FuxiCTR í™˜ê²½ ì„¤ì • ì™„ë£Œ (pip ë°©ì‹)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“Š Step 5: ì›ë³¸ Parquet â†’ H5 ì§ì ‘ ë³€í™˜\n",
        "\n",
        "ì›ë³¸ train.parquet íŒŒì¼ì—ì„œ H5 í˜•ì‹ìœ¼ë¡œ ì§ì ‘ ë³€í™˜í•©ë‹ˆë‹¤.\n",
        "CSV ì¤‘ê°„ ë‹¨ê³„ë¥¼ ê±´ë„ˆë›°ì–´ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ê³¼ ì²˜ë¦¬ ì†ë„ë¥¼ í¬ê²Œ í–¥ìƒì‹œí‚µë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ðŸ“Š H5 ë³€í™˜ ì„¤ì •\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# ë°ì´í„°ëŸ‰ ì„¤ì • (í•„ìš”ì— ë”°ë¼ ì¡°ì •)\n",
        "N_SAMPLES = 100000  # 10ë§Œê°œ ìƒ˜í”Œ (0ìœ¼ë¡œ ì„¤ì •í•˜ë©´ ì „ì²´ ë°ì´í„° ì‚¬ìš©)\n",
        "CHUNK_SIZE = 50000  # ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬ë¥¼ ìœ„í•œ ì²­í¬ í¬ê¸°\n",
        "\n",
        "print(f\"ðŸŽ¯ ë¡œë“œí•  ë°ì´í„° ìƒ˜í”Œ ìˆ˜: {N_SAMPLES:,}ê°œ\")\n",
        "print(f\"ðŸ”„ ì²­í¬ í¬ê¸°: {CHUNK_SIZE:,}ê°œ\")\n",
        "print(f\"   ðŸ’¡ íŒ: N_SAMPLES = 0ìœ¼ë¡œ ì„¤ì •í•˜ë©´ ì „ì²´ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤\")\n",
        "\n",
        "# ì›ë³¸ train.parquet íŒŒì¼ ì°¾ê¸°\n",
        "train_parquet_path = path_manager.get_train_parquet_path()\n",
        "\n",
        "if train_parquet_path:\n",
        "    print(f\"\\nâœ… ì›ë³¸ train.parquet ë°œê²¬: {train_parquet_path}\")\n",
        "    file_size = os.path.getsize(train_parquet_path) / (1024**3)  # GB ë‹¨ìœ„\n",
        "    print(f\"ðŸ“Š íŒŒì¼ í¬ê¸°: {file_size:.2f} GB\")\n",
        "else:\n",
        "    print(\"\\nâŒ train.parquet íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "    print(\"ðŸ“‹ í•´ê²° ë°©ë²•:\")\n",
        "    print(\"1. Google Driveì— ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”\")\n",
        "    print(\"2. ë˜ëŠ” ë¡œì»¬ì—ì„œ ë°ì´í„° ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”\")\n",
        "\n",
        "# ì„¤ì • íŒŒì¼ ê²½ë¡œ\n",
        "config_path = os.path.join(path_manager.model_zoo_path, \"FESeq/config/dataset_config.yaml\")\n",
        "if os.path.exists(config_path):\n",
        "    print(f\"\\nâœ… ì„¤ì • íŒŒì¼ ë°œê²¬: {config_path}\")\n",
        "else:\n",
        "    print(f\"\\nâŒ ì„¤ì • íŒŒì¼ ì—†ìŒ: {config_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ðŸš€ H5 ë³€í™˜ ì‹¤í–‰\n",
        "if train_parquet_path:\n",
        "    print(f\"ðŸš€ Parquet â†’ H5 ë³€í™˜ì„ ì‹œìž‘í•©ë‹ˆë‹¤...\")\n",
        "    print(f\"ðŸ“Š ìž…ë ¥: {train_parquet_path}\")\n",
        "    print(f\"ðŸ“ ì¶œë ¥: {path_manager.data_path}\")\n",
        "    print(f\"ðŸŽ¯ ìƒ˜í”Œ ìˆ˜: {N_SAMPLES:,}ê°œ\")\n",
        "    \n",
        "    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±\n",
        "    path_manager.ensure_directory(path_manager.data_path)\n",
        "    \n",
        "    try:\n",
        "        # H5 í”„ë¡œì„¸ì„œ ìž„í¬íŠ¸\n",
        "        from preprocessing.tossctr_parquet_to_h5 import TossCTRParquetProcessor\n",
        "        \n",
        "        # í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”\n",
        "        processor = TossCTRParquetProcessor(\n",
        "            config_path=config_path,\n",
        "            data_root=os.path.dirname(path_manager.data_path)\n",
        "        )\n",
        "        \n",
        "        # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰\n",
        "        processor.process_full_pipeline(\n",
        "            train_parquet_path=train_parquet_path,\n",
        "            chunk_size=CHUNK_SIZE,\n",
        "            n_samples=N_SAMPLES if N_SAMPLES > 0 else None\n",
        "        )\n",
        "        \n",
        "        print(\"\\nâœ… H5 ë³€í™˜ ì™„ë£Œ!\")\n",
        "        \n",
        "        # ìƒì„±ëœ íŒŒì¼ë“¤ í™•ì¸\n",
        "        h5_files = ['train.h5', 'valid.h5', 'test.h5']\n",
        "        for filename in h5_files:\n",
        "            filepath = os.path.join(path_manager.data_path, filename)\n",
        "            if os.path.exists(filepath):\n",
        "                size_mb = os.path.getsize(filepath) / (1024**2)\n",
        "                print(f\"âœ… {filename}: {size_mb:.1f} MB\")\n",
        "            else:\n",
        "                print(f\"âŒ {filename}: ìƒì„±ë˜ì§€ ì•ŠìŒ\")\n",
        "                \n",
        "    except Exception as e:\n",
        "        print(f\"\\nâŒ H5 ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        \n",
        "        # ëŒ€ì•ˆ: í„°ë¯¸ë„ ëª…ë ¹ì–´ë¡œ ì‹¤í–‰\n",
        "        print(\"\\nðŸ”„ í„°ë¯¸ë„ ëª…ë ¹ì–´ë¡œ ìž¬ì‹œë„...\")\n",
        "        h5_script = os.path.join(path_manager.preprocessing_path, \"tossctr_parquet_to_h5.py\")\n",
        "        cmd = f'''python \"{h5_script}\" \\\\\n",
        "            --train_path \"{train_parquet_path}\" \\\\\n",
        "            --config_path \"{config_path}\" \\\\\n",
        "            --data_root \"{os.path.dirname(path_manager.data_path)}\" \\\\\n",
        "            --chunk_size {CHUNK_SIZE} \\\\\n",
        "            --n_samples {N_SAMPLES if N_SAMPLES > 0 else 0}'''\n",
        "        \n",
        "        print(f\"ì‹¤í–‰ ëª…ë ¹ì–´:\\n{cmd}\")\n",
        "        os.system(cmd)\n",
        "else:\n",
        "    print(\"âŒ train.parquet íŒŒì¼ì´ ì—†ì–´ì„œ H5 ë³€í™˜ì„ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ§  Step 6: FESeq ëª¨ë¸ í›ˆë ¨ ì‹¤í–‰ (H5 ë°©ì‹)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ðŸ“Š H5 ë³€í™˜ëœ ë°ì´í„° í™•ì¸\n",
        "print(\"ðŸ“‹ ìƒì„±ëœ H5 ë°ì´í„° í™•ì¸...\")\n",
        "\n",
        "# tossctr_dataset ê²½ë¡œ í™•ì¸ (H5 ë°ì´í„°ê°€ ì €ìž¥ë˜ëŠ” ìœ„ì¹˜)\n",
        "dataset_path = os.path.join(os.path.dirname(path_manager.data_path), \"tossctr_dataset\")\n",
        "h5_files = [\"train.h5\", \"valid.h5\", \"test.h5\"]\n",
        "\n",
        "all_h5_exist = True\n",
        "for h5_file in h5_files:\n",
        "    file_path = os.path.join(dataset_path, h5_file)\n",
        "    if os.path.exists(file_path):\n",
        "        size_mb = os.path.getsize(file_path) / (1024**2)\n",
        "        print(f\"âœ… {h5_file}: {size_mb:.2f} MB\")\n",
        "    else:\n",
        "        print(f\"âŒ {h5_file}: íŒŒì¼ ì—†ìŒ\")\n",
        "        all_h5_exist = False\n",
        "\n",
        "# feature_map.json í™•ì¸\n",
        "feature_map_path = os.path.join(dataset_path, \"feature_map.json\")\n",
        "if os.path.exists(feature_map_path):\n",
        "    print(f\"âœ… feature_map.json: ìƒì„±ë¨\")\n",
        "    \n",
        "    # feature_map ë‚´ìš© í™•ì¸\n",
        "    import json\n",
        "    with open(feature_map_path, 'r') as f:\n",
        "        feature_map = json.load(f)\n",
        "    print(f\"   ðŸ“Š ì´ í•„ë“œ ìˆ˜: {feature_map.get('num_fields', 'Unknown')}\")\n",
        "    print(f\"   ðŸ”¢ ì´ í”¼ì²˜ ìˆ˜: {feature_map.get('total_features', 'Unknown')}\")\n",
        "else:\n",
        "    print(f\"âŒ feature_map.json: íŒŒì¼ ì—†ìŒ\")\n",
        "    all_h5_exist = False\n",
        "\n",
        "if all_h5_exist:\n",
        "    print(f\"\\nâœ… H5 ë³€í™˜ ì™„ë£Œ! ëª¨ë“  í•„ìˆ˜ íŒŒì¼ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "    print(f\"ðŸŽ¯ ì‚¬ìš©ëœ ìƒ˜í”Œ ìˆ˜: {N_SAMPLES:,}ê°œ\")\n",
        "    print(\"ðŸš€ ì´ì œ FESeq ëª¨ë¸ í›ˆë ¨ì„ ì§„í–‰í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤!\")\n",
        "    h5_training_ready = True\n",
        "else:\n",
        "    print(f\"\\nâŒ ì¼ë¶€ H5 íŒŒì¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤. ìœ„ì˜ H5 ë³€í™˜ ë‹¨ê³„ë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n",
        "    h5_training_ready = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ðŸš€ H5 ë°©ì‹ FESeq ëª¨ë¸ í›ˆë ¨ ì‹¤í–‰\n",
        "if h5_training_ready:\n",
        "    print(\"ðŸš€ H5 ë°©ì‹ FESeq ëª¨ë¸ í›ˆë ¨ì„ ì‹œìž‘í•©ë‹ˆë‹¤...\")\n",
        "    print(\"ðŸ“Š ì„¤ì •: FESeq_tossctr_h5 (H5 ìµœì í™”, ë°°ì¹˜ í¬ê¸° 1024, ì—í¬í¬ 10)\")\n",
        "    \n",
        "    # H5 ì „ìš© ì‹¤í—˜ ID ì‚¬ìš©\n",
        "    expid = \"FESeq_tossctr_h5\"\n",
        "    \n",
        "    try:\n",
        "        # FESeq í›ˆë ¨ ì‹¤í–‰\n",
        "        import subprocess\n",
        "        \n",
        "        print(f\"â–¶ï¸  ì‹¤í—˜ ID: {expid}\")\n",
        "        print(\"â³ í›ˆë ¨ ì‹œìž‘... (H5 ë°©ì‹ìœ¼ë¡œ ë” ë¹ ë¥¸ ì²˜ë¦¬)\")\n",
        "        \n",
        "        # í˜„ìž¬ ìž‘ì—… ë””ë ‰í† ë¦¬ ì €ìž¥\n",
        "        original_cwd = os.getcwd()\n",
        "        \n",
        "        # FESeq ë””ë ‰í† ë¦¬ë¡œ ì´ë™\n",
        "        feseq_dir = os.path.join(path_manager.model_zoo_path, \"FESeq\")\n",
        "        os.chdir(feseq_dir)\n",
        "        print(f\"ðŸ“‚ ìž‘ì—… ë””ë ‰í† ë¦¬ ë³€ê²½: {os.getcwd()}\")\n",
        "        \n",
        "        # run_expid.pyë¡œ H5 ë°©ì‹ í›ˆë ¨ ì‹¤í–‰\n",
        "        cmd = [\n",
        "            sys.executable, \n",
        "            \"run_expid.py\",\n",
        "            \"--config\", \"./config\",\n",
        "            \"--expid\", expid,\n",
        "            \"--gpu\", \"0\" if torch.cuda.is_available() else \"-1\"\n",
        "        ]\n",
        "        \n",
        "        print(f\"ðŸ”§ ì‹¤í–‰ ëª…ë ¹ì–´: {' '.join(cmd)}\")\n",
        "        \n",
        "        # ì‹¤í–‰\n",
        "        result = subprocess.run(cmd, capture_output=True, text=True)\n",
        "        \n",
        "        # ì›ëž˜ ë””ë ‰í† ë¦¬ë¡œ ë³µê·€\n",
        "        os.chdir(original_cwd)\n",
        "        \n",
        "        if result.returncode == 0:\n",
        "            print(\"\\nâœ… H5 ë°©ì‹ FESeq ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!\")\n",
        "            print(\"\\nðŸ“Š í›ˆë ¨ ê²°ê³¼ (ë§ˆì§€ë§‰ ë¶€ë¶„):\")\n",
        "            print(result.stdout[-2000:] if result.stdout else \"ì¶œë ¥ ì—†ìŒ\")\n",
        "        else:\n",
        "            print(f\"\\nâŒ í›ˆë ¨ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ì¢…ë£Œ ì½”ë“œ: {result.returncode})\")\n",
        "            print(\"\\nðŸ“„ ì—ëŸ¬ ë¡œê·¸:\")\n",
        "            print(result.stderr if result.stderr else \"ì—ëŸ¬ ì¶œë ¥ ì—†ìŒ\")\n",
        "            \n",
        "            # CSV ë°©ì‹ìœ¼ë¡œ í´ë°±\n",
        "            print(\"\\nðŸ”„ ëŒ€ì•ˆ: CSV ë°©ì‹ìœ¼ë¡œ í´ë°± ì‹œë„...\")\n",
        "            os.chdir(feseq_dir)\n",
        "            fallback_cmd = cmd.copy()\n",
        "            fallback_cmd[fallback_cmd.index(expid)] = \"FESeq_tossctr\"\n",
        "            \n",
        "            fallback_result = subprocess.run(fallback_cmd, capture_output=True, text=True)\n",
        "            os.chdir(original_cwd)\n",
        "            \n",
        "            if fallback_result.returncode == 0:\n",
        "                print(\"âœ… CSV ë°©ì‹ í´ë°± í›ˆë ¨ ì™„ë£Œ!\")\n",
        "            else:\n",
        "                print(\"âŒ í´ë°± í›ˆë ¨ë„ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n",
        "                \n",
        "    except Exception as e:\n",
        "        # ì›ëž˜ ë””ë ‰í† ë¦¬ë¡œ ë³µê·€\n",
        "        if 'original_cwd' in locals():\n",
        "            os.chdir(original_cwd)\n",
        "            \n",
        "        print(f\"\\nâŒ ì˜ˆê¸°ì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        \n",
        "else:\n",
        "    print(\"âŒ H5 í›ˆë ¨ ì¤€ë¹„ê°€ ì™„ë£Œë˜ì§€ ì•Šì•„ í›ˆë ¨ì„ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
        "    print(\"ìœ„ì˜ ë‹¨ê³„ë“¤ì„ ì™„ë£Œí•œ í›„ ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”® Step 7: ì¶”ë¡  ë° ì œì¶œ íŒŒì¼ ìƒì„±\n",
        "\n",
        "í›ˆë ¨ëœ FESeq ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ test.parquet ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ê³  ì œì¶œ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì¶”ë¡ ì„ ìœ„í•œ í•„ìˆ˜ ìž„í¬íŠ¸\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import h5py\n",
        "import json\n",
        "import subprocess\n",
        "\n",
        "# FuxiCTR ê´€ë ¨ ìž„í¬íŠ¸\n",
        "from fuxictr.features import FeatureMapAbsTime\n",
        "from fuxictr.pytorch.dataloaders import H5DataLoader\n",
        "from fuxictr.utils import load_config\n",
        "\n",
        "# FESeq ëª¨ë¸ ìž„í¬íŠ¸\n",
        "sys.path.append(os.path.join(path_manager.model_zoo_path, 'FESeq'))\n",
        "from src.FESeq import FESeq\n",
        "\n",
        "print(\"âœ… ì¶”ë¡ ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ\n",
        "print(\"ðŸ”„ í›ˆë ¨ëœ FESeq ëª¨ë¸ ë¡œë“œ ì¤‘...\")\n",
        "\n",
        "# ì„¤ì • íŒŒì¼ ë¡œë“œ\n",
        "config_path = os.path.join(path_manager.model_zoo_path, \"FESeq/config\")\n",
        "params = load_config(config_path, \"FESeq_tossctr\")\n",
        "params['gpu'] = 0 if torch.cuda.is_available() else -1\n",
        "\n",
        "# ë°ì´í„° ê²½ë¡œ ë™ì  ì„¤ì •\n",
        "dataset_path = os.path.join(os.path.dirname(path_manager.data_path), \"tossctr_dataset\")\n",
        "params['data_root'] = os.path.dirname(dataset_path)\n",
        "\n",
        "print(f\"âœ… ëª¨ë¸ ì„¤ì • ë¡œë“œ ì™„ë£Œ\")\n",
        "print(f\"ðŸ“‹ ì£¼ìš” ì„¤ì •:\")\n",
        "print(f\"   - ëª¨ë¸: {params.get('model', 'N/A')}\")\n",
        "print(f\"   - ë°°ì¹˜ í¬ê¸°: {params.get('batch_size', 'N/A')}\")\n",
        "print(f\"   - ìž„ë² ë”© ì°¨ì›: {params.get('embedding_dim', 'N/A')}\")\n",
        "print(f\"   - GPU: {params['gpu']}\")\n",
        "print(f\"   - ë°ì´í„° ê²½ë¡œ: {dataset_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature Map ë° ëª¨ë¸ ì´ˆê¸°í™”\n",
        "print(\"ðŸ—ºï¸ Feature Map ë¡œë“œ ì¤‘...\")\n",
        "\n",
        "feature_map_json = os.path.join(dataset_path, \"feature_map.json\")\n",
        "\n",
        "if os.path.exists(feature_map_json):\n",
        "    # Feature Map ë¡œë“œ\n",
        "    feature_map = FeatureMapAbsTime(params['dataset_id'], dataset_path)\n",
        "    feature_map.load(feature_map_json, params)\n",
        "    \n",
        "    print(f\"âœ… Feature Map ë¡œë“œ ì™„ë£Œ\")\n",
        "    print(f\"ðŸ“Š í”¼ì²˜ ìˆ˜: {len(feature_map.features)}\")\n",
        "    \n",
        "    # FESeq ëª¨ë¸ ì´ˆê¸°í™”\n",
        "    print(\"\\nðŸ§  FESeq ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...\")\n",
        "    model = FESeq(feature_map, params=params, **params)\n",
        "    \n",
        "    # í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ\n",
        "    checkpoint_paths = [\n",
        "        os.path.join(path_manager.model_zoo_path, f\"FESeq/checkpoints/tossctr_dataset/FESeq_tossctr.model\"),\n",
        "        os.path.join(path_manager.model_zoo_path, f\"FESeq/checkpoints/tossctr_dataset/FESeq_tossctr_h5.model\"),\n",
        "        os.path.join(path_manager.model_zoo_path, f\"FESeq/checkpoints/FESeq_tossctr.model\"),\n",
        "        os.path.join(path_manager.model_zoo_path, f\"FESeq/checkpoints/FESeq_tossctr_h5.model\")\n",
        "    ]\n",
        "    \n",
        "    checkpoint_loaded = False\n",
        "    for checkpoint_path in checkpoint_paths:\n",
        "        if os.path.exists(checkpoint_path):\n",
        "            try:\n",
        "                model.load_weights(checkpoint_path)\n",
        "                print(f\"âœ… í›ˆë ¨ëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ: {checkpoint_path}\")\n",
        "                model.eval()\n",
        "                print(\"âœ… ëª¨ë¸ì´ ì¶”ë¡  ëª¨ë“œë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "                checkpoint_loaded = True\n",
        "                break\n",
        "            except Exception as e:\n",
        "                print(f\"âš ï¸  {checkpoint_path} ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
        "                continue\n",
        "    \n",
        "    if not checkpoint_loaded:\n",
        "        print(\"âŒ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        print(\"ë¨¼ì € ëª¨ë¸ í›ˆë ¨ì„ ì™„ë£Œí•´ì£¼ì„¸ìš”.\")\n",
        "        model = None\n",
        "else:\n",
        "    print(f\"âŒ Feature map íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {feature_map_json}\")\n",
        "    print(\"ë¨¼ì € ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ì™„ë£Œí•˜ê±°ë‚˜ ëª¨ë¸ í›ˆë ¨ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n",
        "    model = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì¶”ë¡  ì‹¤í–‰\n",
        "if model is not None:\n",
        "    print(\"ðŸ“Š ì¶”ë¡  ë°ì´í„° ë¡œë” ìƒì„± ì¤‘...\")\n",
        "    \n",
        "    test_h5_path = os.path.join(dataset_path, \"test.h5\")\n",
        "    \n",
        "    if os.path.exists(test_h5_path):\n",
        "        try:\n",
        "            # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë” ìƒì„±\n",
        "            test_loader = H5DataLoader(feature_map, stage='test', **params).make_iterator()\n",
        "            \n",
        "            print(\"ðŸ”® ëª¨ë¸ ì¶”ë¡  ì‹œìž‘...\")\n",
        "            predictions = []\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                for batch_idx, batch_data in enumerate(test_loader):\n",
        "                    # ë°°ì¹˜ ì˜ˆì¸¡\n",
        "                    output = model(batch_data)\n",
        "                    batch_pred = torch.sigmoid(output['y_pred']).cpu().numpy().flatten()\n",
        "                    predictions.extend(batch_pred)\n",
        "                    \n",
        "                    # ì§„í–‰ ìƒí™© ì¶œë ¥\n",
        "                    if batch_idx % 10 == 0:\n",
        "                        print(f\"  ì²˜ë¦¬ëœ ë°°ì¹˜: {batch_idx + 1}, ëˆ„ì  ì˜ˆì¸¡ ìˆ˜: {len(predictions)}\")\n",
        "            \n",
        "            print(f\"\\nâœ… ì¶”ë¡  ì™„ë£Œ! ì´ {len(predictions)}ê°œ ìƒ˜í”Œ ì˜ˆì¸¡\")\n",
        "            print(f\"ðŸ“Š ì˜ˆì¸¡ê°’ ë²”ìœ„: {min(predictions):.6f} ~ {max(predictions):.6f}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ì¶”ë¡  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "            predictions = None\n",
        "    else:\n",
        "        print(f\"âŒ test.h5 íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {test_h5_path}\")\n",
        "        predictions = None\n",
        "else:\n",
        "    print(\"âŒ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
        "    predictions = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì œì¶œ íŒŒì¼ ìƒì„±\n",
        "if predictions is not None:\n",
        "    print(\"ðŸ“ ì œì¶œ íŒŒì¼ ìƒì„± ì¤‘...\")\n",
        "    \n",
        "    # sample_submission.csv ë¡œë“œ\n",
        "    sample_submission_path = path_manager.get_sample_submission_path()\n",
        "    \n",
        "    if sample_submission_path and os.path.exists(sample_submission_path):\n",
        "        submission_df = pd.read_csv(sample_submission_path)\n",
        "        print(f\"âœ… sample_submission.csv ë¡œë“œ ì™„ë£Œ: {submission_df.shape}\")\n",
        "        \n",
        "        # ì˜ˆì¸¡ê°’ ê¸¸ì´ í™•ì¸ ë° ì¡°ì •\n",
        "        if len(predictions) != len(submission_df):\n",
        "            print(f\"âš ï¸  ì˜ˆì¸¡ê°’ ê¸¸ì´ ë¶ˆì¼ì¹˜: ì˜ˆì¸¡ê°’ {len(predictions)}, ì œì¶œíŒŒì¼ {len(submission_df)}\")\n",
        "            \n",
        "            if len(predictions) > len(submission_df):\n",
        "                predictions = predictions[:len(submission_df)]\n",
        "                print(f\"âœ‚ï¸  ì˜ˆì¸¡ê°’ì„ {len(submission_df)}ê°œë¡œ ìž˜ëžìŠµë‹ˆë‹¤.\")\n",
        "            else:\n",
        "                mean_pred = np.mean(predictions)\n",
        "                predictions.extend([mean_pred] * (len(submission_df) - len(predictions)))\n",
        "                print(f\"ðŸ“ˆ ì˜ˆì¸¡ê°’ì„ í‰ê· ê°’({mean_pred:.4f})ë¡œ {len(submission_df)}ê°œê¹Œì§€ ì±„ì› ìŠµë‹ˆë‹¤.\")\n",
        "        \n",
        "        # ì˜ˆì¸¡ê°’ì„ ì œì¶œ íŒŒì¼ì— í• ë‹¹\n",
        "        submission_df['clicked'] = predictions\n",
        "        \n",
        "        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±\n",
        "        output_dir = os.path.join(path_manager.base_path, \"data/output\")\n",
        "        path_manager.ensure_directory(output_dir)\n",
        "        \n",
        "        # ì œì¶œ íŒŒì¼ ì €ìž¥\n",
        "        output_path = os.path.join(output_dir, \"feseq_submission.csv\")\n",
        "        submission_df.to_csv(output_path, index=False)\n",
        "        \n",
        "        print(f\"\\nâœ… ì œì¶œ íŒŒì¼ ìƒì„± ì™„ë£Œ: {output_path}\")\n",
        "        print(f\"\\nðŸ“Š ì˜ˆì¸¡ í†µê³„:\")\n",
        "        print(f\"   - ìµœì†Ÿê°’: {np.min(predictions):.6f}\")\n",
        "        print(f\"   - ìµœëŒ“ê°’: {np.max(predictions):.6f}\")\n",
        "        print(f\"   - í‰ê· ê°’: {np.mean(predictions):.6f}\")\n",
        "        print(f\"   - í‘œì¤€íŽ¸ì°¨: {np.std(predictions):.6f}\")\n",
        "        \n",
        "        # ì˜ˆì¸¡ê°’ ë¶„í¬ í™•ì¸\n",
        "        print(f\"\\nðŸ“ˆ ì˜ˆì¸¡ê°’ ë¶„í¬:\")\n",
        "        hist, bins = np.histogram(predictions, bins=10)\n",
        "        for i in range(len(hist)):\n",
        "            print(f\"   {bins[i]:.3f}-{bins[i+1]:.3f}: {hist[i]:,}ê°œ\")\n",
        "            \n",
        "    else:\n",
        "        print(\"âŒ sample_submission.csvë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "else:\n",
        "    print(\"âŒ ì˜ˆì¸¡ê°’ì´ ì—†ìŠµë‹ˆë‹¤. ì¶”ë¡ ì„ ë¨¼ì € ì™„ë£Œí•´ì£¼ì„¸ìš”.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ê²°ê³¼ ê²€ì¦ ë° ìµœì¢… í™•ì¸\n",
        "print(\"ðŸ” ìµœì¢… ê²°ê³¼ ê²€ì¦...\")\n",
        "\n",
        "output_dir = os.path.join(path_manager.base_path, \"data/output\")\n",
        "feseq_submission_path = os.path.join(output_dir, \"feseq_submission.csv\")\n",
        "\n",
        "if os.path.exists(feseq_submission_path):\n",
        "    # ì œì¶œ íŒŒì¼ ë¡œë“œ ë° ê²€ì¦\n",
        "    final_submission = pd.read_csv(feseq_submission_path)\n",
        "    \n",
        "    print(f\"âœ… ìµœì¢… ì œì¶œ íŒŒì¼ ê²€ì¦ ì™„ë£Œ:\")\n",
        "    print(f\"   ðŸ“ íŒŒì¼ ê²½ë¡œ: {feseq_submission_path}\")\n",
        "    print(f\"   ðŸ“Š íŒŒì¼ í¬ê¸°: {final_submission.shape}\")\n",
        "    print(f\"   ðŸ“‹ ì»¬ëŸ¼: {list(final_submission.columns)}\")\n",
        "    \n",
        "    # ì œì¶œ íŒŒì¼ í˜•ì‹ ê²€ì¦\n",
        "    required_columns = ['ID', 'clicked']\n",
        "    missing_columns = [col for col in required_columns if col not in final_submission.columns]\n",
        "    \n",
        "    if missing_columns:\n",
        "        print(f\"âŒ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_columns}\")\n",
        "    else:\n",
        "        print(\"âœ… ì œì¶œ íŒŒì¼ í˜•ì‹ ê²€ì¦ í†µê³¼\")\n",
        "    \n",
        "    # ì˜ˆì¸¡ê°’ ë²”ìœ„ ê²€ì¦\n",
        "    clicked_values = final_submission['clicked']\n",
        "    if clicked_values.min() >= 0 and clicked_values.max() <= 1:\n",
        "        print(\"âœ… ì˜ˆì¸¡ê°’ ë²”ìœ„ ê²€ì¦ í†µê³¼ (0-1 ì‚¬ì´)\")\n",
        "    else:\n",
        "        print(f\"âš ï¸  ì˜ˆì¸¡ê°’ ë²”ìœ„ ì£¼ì˜: {clicked_values.min():.6f} ~ {clicked_values.max():.6f}\")\n",
        "    \n",
        "    # ê²°ì¸¡ê°’ í™•ì¸\n",
        "    if clicked_values.isnull().sum() == 0:\n",
        "        print(\"âœ… ê²°ì¸¡ê°’ ì—†ìŒ\")\n",
        "    else:\n",
        "        print(f\"âš ï¸  ê²°ì¸¡ê°’ ë°œê²¬: {clicked_values.isnull().sum()}ê°œ\")\n",
        "    \n",
        "    # ìƒ˜í”Œ ì¶œë ¥\n",
        "    print(f\"\\nðŸ“‹ ì œì¶œ íŒŒì¼ ìƒ˜í”Œ:\")\n",
        "    print(final_submission.head(10))\n",
        "    \n",
        "    print(f\"\\nðŸŽ‰ FESeq ëª¨ë¸ ì¶”ë¡  ë° ì œì¶œ íŒŒì¼ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
        "    print(f\"ðŸ’¾ ì œì¶œ íŒŒì¼: {feseq_submission_path}\")\n",
        "    \n",
        "else:\n",
        "    print(f\"âŒ ì œì¶œ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {feseq_submission_path}\")\n",
        "    print(\"ì´ì „ ë‹¨ê³„ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“‹ ì‹¤í–‰ ìš”ì•½\n",
        "\n",
        "### ðŸŽ¯ ì™„ë£Œëœ ìž‘ì—…\n",
        "1. **ë™ì  ê²½ë¡œ ì„¤ì •**: Colabê³¼ ë¡œì»¬ í™˜ê²½ì„ ìžë™ìœ¼ë¡œ ê°ì§€í•˜ì—¬ ê²½ë¡œ ì„¤ì •\n",
        "2. **ëª¨ë¸ í›ˆë ¨**: FESeq ëª¨ë¸ì´ TossCTR ë°ì´í„°ì…‹ì—ì„œ ì„±ê³µì ìœ¼ë¡œ í›ˆë ¨ë¨\n",
        "3. **ì¶”ë¡ **: í›ˆë ¨ëœ ëª¨ë¸ë¡œ test.parquet ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ ìˆ˜í–‰\n",
        "4. **ì œì¶œ íŒŒì¼**: sample_submission.csv í˜•ì‹ì— ë§žëŠ” ì œì¶œ íŒŒì¼ ìƒì„±\n",
        "\n",
        "### ðŸ“ ìƒì„±ëœ íŒŒì¼\n",
        "- `{base_path}/data/output/feseq_submission.csv`: FESeq ëª¨ë¸ì˜ ìµœì¢… ì œì¶œ íŒŒì¼\n",
        "\n",
        "### ðŸš€ ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ\n",
        "1. **ì„±ëŠ¥ ê°œì„ **: í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ìœ¼ë¡œ ëª¨ë¸ ì„±ëŠ¥ í–¥ìƒ\n",
        "2. **ì•™ìƒë¸”**: ë‹¤ë¥¸ ëª¨ë¸ê³¼ ê²°í•©í•˜ì—¬ ì˜ˆì¸¡ ì„±ëŠ¥ ê°œì„ \n",
        "3. **í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§**: ì¶”ê°€ í”¼ì²˜ë¥¼ í™œìš©í•œ ì„±ëŠ¥ í–¥ìƒ\n",
        "\n",
        "### ðŸ’¡ v4.0 ê°œì„ ì‚¬í•­\n",
        "- **ë™ì  ê²½ë¡œ**: Colab/ë¡œì»¬ í™˜ê²½ ìžë™ ê°ì§€\n",
        "- **ì¤‘ë³µ ì œê±°**: PathManager í´ëž˜ìŠ¤ë¡œ ê²½ë¡œ ê´€ë¦¬ ì¼ì›í™”\n",
        "- **ì—ëŸ¬ ì²˜ë¦¬**: ë” ë‚˜ì€ í´ë°± ë©”ì»¤ë‹ˆì¦˜ê³¼ ë””ë²„ê¹… ì •ë³´\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

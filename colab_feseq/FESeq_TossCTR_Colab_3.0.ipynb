{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FESeq Model Training on TossCTR Dataset (H5 ìµœì í™” ë²„ì „)\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì€ TossCTR ë°ì´í„°ì…‹ì—ì„œ FESeq ëª¨ë¸ì„ í›ˆë ¨í•˜ê¸° ìœ„í•œ H5 ìµœì í™” Colab í™˜ê²½ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
        "\n",
        "## ğŸš€ ì£¼ìš” ê°œì„ ì‚¬í•­ (H5 ë²„ì „)\n",
        "- **H5 ì§ì ‘ ë³€í™˜**: Parquet â†’ H5 ì§ì ‘ ë³€í™˜ìœ¼ë¡œ CSV ì¤‘ê°„ ë‹¨ê³„ ì œê±°\n",
        "- **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**: CSV ëŒ€ë¹„ 50% ì ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©\n",
        "- **ì²˜ë¦¬ ì†ë„**: 2ë°° ë¹ ë¥¸ ë°ì´í„° ì²˜ë¦¬ ë° ë¡œë”©\n",
        "- **ëŒ€ìš©ëŸ‰ ì§€ì›**: ì „ì²´ ë°ì´í„°ì…‹ë„ ì•ˆì •ì ìœ¼ë¡œ ì²˜ë¦¬\n",
        "- **ë°ì´í„°ëŸ‰ ì¡°ì ˆ**: N_SAMPLES ë³€ìˆ˜ë¡œ í•™ìŠµ ë°ì´í„° ì–‘ ì¡°ì ˆ ê°€ëŠ¥\n",
        "\n",
        "## ğŸ“‹ ì‹¤í–‰ ìˆœì„œ (H5 íŒŒì´í”„ë¼ì¸)\n",
        "1. í™˜ê²½ ì„¤ì • ë° íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
        "2. ì½”ë“œ ë° ë°ì´í„° ì—…ë¡œë“œ  \n",
        "3. **Parquet â†’ H5 ì§ì ‘ ë³€í™˜** (ìƒˆë¡œìš´ ë°©ì‹)\n",
        "4. H5 ë°ì´í„° í™•ì¸\n",
        "5. FESeq ëª¨ë¸ í›ˆë ¨ (H5 ìµœì í™”)\n",
        "6. ì¶”ë¡  ë° ì œì¶œ íŒŒì¼ ìƒì„±\n",
        "\n",
        "## ğŸ’¡ H5 ë°©ì‹ì˜ ì¥ì \n",
        "- **ë©”ëª¨ë¦¬**: CSV ë°©ì‹ ëŒ€ë¹„ 50% ë©”ëª¨ë¦¬ ì ˆì•½\n",
        "- **ì†ë„**: ì§ì ‘ ë³€í™˜ìœ¼ë¡œ 2ë°° ë¹ ë¥¸ ì²˜ë¦¬\n",
        "- **ì•ˆì •ì„±**: ëŒ€ìš©ëŸ‰ ë°ì´í„°ë„ ì•ˆì •ì  ì²˜ë¦¬\n",
        "- **ë°°ì¹˜ í¬ê¸°**: ë” í° ë°°ì¹˜ ì‚¬ì´ì¦ˆë¡œ í›ˆë ¨ ê°€ëŠ¥\n",
        "\n",
        "## ğŸ¯ ë°ì´í„°ëŸ‰ ì¡°ì ˆ ë°©ë²•\n",
        "```python\n",
        "N_SAMPLES = 100000  # 10ë§Œê°œ (ë¹ ë¥¸ ì‹¤í—˜ìš©)\n",
        "N_SAMPLES = 500000  # 50ë§Œê°œ (ì¤‘ê°„ ê·œëª¨)\n",
        "N_SAMPLES = 0       # ì „ì²´ ë°ì´í„° (ìµœê³  ì„±ëŠ¥)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸš€ Step 1: í™˜ê²½ ì„¤ì • ë° GPU í™•ì¸\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\n",
        "import torch\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "else:\n",
        "    print(\"âš ï¸  GPU not available, using CPU\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“¦ Step 2: ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
        "%pip install -qq pandas numpy scikit-learn PyYAML h5py tqdm pyarrow\n",
        "\n",
        "# PyTorch ì„¤ì¹˜ (GPU ë²„ì „)\n",
        "%pip install -qq torch torchvision --index-url https://download.pytorch.org/whl/cu118\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“ Step 3: GitHubì—ì„œ ì½”ë“œ í´ë¡ \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GitHubì—ì„œ TossCTR ë ˆí¬ì§€í† ë¦¬ í´ë¡ \n",
        "import os\n",
        "\n",
        "print(\"ğŸ“¥ GitHubì—ì„œ TossCTR ë ˆí¬ì§€í† ë¦¬ë¥¼ í´ë¡ í•©ë‹ˆë‹¤...\")\n",
        "!git clone https://github.com/kwonhwijun/TossCTR.git\n",
        "\n",
        "# colab_feseq ë””ë ‰í† ë¦¬ë¡œ ì´ë™\n",
        "print(\"ğŸ“ colab_feseq ë””ë ‰í† ë¦¬ë¡œ ì´ë™...\")\n",
        "%cd TossCTR/colab_feseq\n",
        "\n",
        "# í˜„ì¬ ë””ë ‰í† ë¦¬ êµ¬ì¡° í™•ì¸\n",
        "print(\"\\nğŸ“ í˜„ì¬ ë””ë ‰í† ë¦¬ êµ¬ì¡°:\")\n",
        "!ls -la\n",
        "\n",
        "# ì¤‘ìš”í•œ íŒŒì¼ë“¤ì´ ìˆëŠ”ì§€ í™•ì¸\n",
        "print(\"\\nğŸ” ì¤‘ìš” íŒŒì¼ í™•ì¸:\")\n",
        "print(\"âœ… run_feseq.py:\", \"ì¡´ì¬\" if os.path.exists(\"run_feseq.py\") else \"âŒ ì—†ìŒ\")\n",
        "print(\"âœ… FESeq ëª¨ë¸:\", \"ì¡´ì¬\" if os.path.exists(\"model_zoo/FESeq\") else \"âŒ ì—†ìŒ\") \n",
        "print(\"âœ… ë°ì´í„°:\", \"ì¡´ì¬\" if os.path.exists(\"data/tossctr\") else \"âŒ ì—†ìŒ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âš™ï¸ Step 4: FuxiCTR í™˜ê²½ ì„¤ì •\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FuxiCTR ì„¤ì¹˜\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# PYTHONPATH ì„¤ì •\n",
        "current_dir = os.getcwd()\n",
        "if current_dir not in sys.path:\n",
        "    sys.path.insert(0, current_dir)\n",
        "\n",
        "os.environ['PYTHONPATH'] = current_dir\n",
        "print(f\"âœ… PYTHONPATH: {current_dir}\")\n",
        "\n",
        "# setup.py ì„¤ì¹˜ ì‹œë„\n",
        "try:\n",
        "    print(\"ğŸ“¦ FuxiCTR ì„¤ì¹˜ ì¤‘...\")\n",
        "    !python setup.py develop\n",
        "    print(\"âœ… FuxiCTR í™˜ê²½ ì„¤ì • ì™„ë£Œ\")\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸  setup.py ì„¤ì¹˜ ì‹¤íŒ¨: {e}\")\n",
        "    print(\"ğŸ“¦ pipìœ¼ë¡œ ëŒ€ì²´ ì„¤ì¹˜ ì‹œë„...\")\n",
        "    %pip install -e .\n",
        "    print(\"âœ… FuxiCTR í™˜ê²½ ì„¤ì • ì™„ë£Œ (pip ë°©ì‹)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“Š Step 5: ì›ë³¸ Parquet â†’ H5 ì§ì ‘ ë³€í™˜\n",
        "\n",
        "ì›ë³¸ train.parquet íŒŒì¼ì—ì„œ H5 í˜•ì‹ìœ¼ë¡œ ì§ì ‘ ë³€í™˜í•©ë‹ˆë‹¤.\n",
        "CSV ì¤‘ê°„ ë‹¨ê³„ë¥¼ ê±´ë„ˆë›°ì–´ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ê³¼ ì²˜ë¦¬ ì†ë„ë¥¼ í¬ê²Œ í–¥ìƒì‹œí‚µë‹ˆë‹¤.\n",
        "\n",
        "### ğŸš€ H5 ë°©ì‹ì˜ ì¥ì :\n",
        "- **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**: CSVë³´ë‹¤ 50% ì ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©\n",
        "- **ì²˜ë¦¬ ì†ë„**: ì§ì ‘ ë³€í™˜ìœ¼ë¡œ 2ë°° ë¹ ë¥¸ ì²˜ë¦¬\n",
        "- **ëŒ€ìš©ëŸ‰ ì§€ì›**: ì „ì²´ ë°ì´í„°ì…‹ë„ ì•ˆì •ì ìœ¼ë¡œ ì²˜ë¦¬\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ“Š H5 ë³€í™˜ ì„¤ì •\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# ë°ì´í„°ëŸ‰ ì„¤ì • (í•„ìš”ì— ë”°ë¼ ì¡°ì •)\n",
        "N_SAMPLES = 100000  # 10ë§Œê°œ ìƒ˜í”Œ (0ìœ¼ë¡œ ì„¤ì •í•˜ë©´ ì „ì²´ ë°ì´í„° ì‚¬ìš©)\n",
        "CHUNK_SIZE = 50000  # ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬ë¥¼ ìœ„í•œ ì²­í¬ í¬ê¸°\n",
        "\n",
        "print(f\"ğŸ¯ ë¡œë“œí•  ë°ì´í„° ìƒ˜í”Œ ìˆ˜: {N_SAMPLES:,}ê°œ\")\n",
        "print(f\"ğŸ”„ ì²­í¬ í¬ê¸°: {CHUNK_SIZE:,}ê°œ\")\n",
        "print(f\"   ğŸ’¡ íŒ: N_SAMPLES = 0ìœ¼ë¡œ ì„¤ì •í•˜ë©´ ì „ì²´ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤\")\n",
        "\n",
        "# H5 ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œ í™•ì¸\n",
        "h5_processor_script = \"/content/TossCTR/colab_feseq/preprocessing/tossctr_parquet_to_h5.py\"\n",
        "if os.path.exists(h5_processor_script):\n",
        "    print(f\"âœ… H5 ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸ ë°œê²¬: {h5_processor_script}\")\n",
        "else:\n",
        "    print(f\"âŒ H5 ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸ ì—†ìŒ: {h5_processor_script}\")\n",
        "    print(\"GitHub í´ë¡ ì´ ì œëŒ€ë¡œ ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\")\n",
        "\n",
        "# Config íŒŒì¼ ê²½ë¡œ í™•ì¸\n",
        "config_path = \"/content/TossCTR/colab_feseq/model_zoo/FESeq/config/dataset_config.yaml\"\n",
        "if os.path.exists(config_path):\n",
        "    print(f\"âœ… ì„¤ì • íŒŒì¼ ë°œê²¬: {config_path}\")\n",
        "else:\n",
        "    print(f\"âŒ ì„¤ì • íŒŒì¼ ì—†ìŒ: {config_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ“¥ ì›ë³¸ train.parquet íŒŒì¼ ì°¾ê¸°\n",
        "print(\"ğŸ” ì›ë³¸ train.parquet íŒŒì¼ì„ ì°¾ëŠ” ì¤‘...\")\n",
        "\n",
        "# ê°€ëŠ¥í•œ train.parquet íŒŒì¼ ê²½ë¡œë“¤ (ìš°ì„ ìˆœìœ„ ìˆœ)\n",
        "possible_train_paths = [\n",
        "    \"/content/drive/MyDrive/data/TossCTR/raw/train.parquet\",     # Colab êµ¬ê¸€ ë“œë¼ì´ë¸Œ\n",
        "    \"/content/TossCTR/data/raw/train.parquet\",                  # Colab ë¡œì»¬\n",
        "    \"/Users/hj/projects/TossCTR/data/raw/train.parquet\"         # ë¡œì»¬ í™˜ê²½\n",
        "]\n",
        "\n",
        "train_parquet_path = None\n",
        "for path in possible_train_paths:\n",
        "    if os.path.exists(path):\n",
        "        train_parquet_path = path\n",
        "        print(f\"âœ… ì›ë³¸ train.parquet ë°œê²¬: {path}\")\n",
        "        \n",
        "        # íŒŒì¼ í¬ê¸° í™•ì¸\n",
        "        file_size = os.path.getsize(path) / (1024**3)  # GB ë‹¨ìœ„\n",
        "        print(f\"ğŸ“Š íŒŒì¼ í¬ê¸°: {file_size:.2f} GB\")\n",
        "        break\n",
        "\n",
        "if train_parquet_path is None:\n",
        "    print(\"âŒ train.parquet íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤:\")\n",
        "    for path in possible_train_paths:\n",
        "        exists = \"âœ…\" if os.path.exists(path) else \"âŒ\"\n",
        "        print(f\"   {exists} {path}\")\n",
        "    print(\"\\nğŸ“‹ í•´ê²° ë°©ë²•:\")\n",
        "    print(\"1. Google Driveì— ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”\")\n",
        "    print(\"2. ë˜ëŠ” ë¡œì»¬ì—ì„œ ë°ì´í„° ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”\")\n",
        "else:\n",
        "    print(f\"ğŸ¯ ì‚¬ìš©í•  train.parquet ê²½ë¡œ: {train_parquet_path}\")\n",
        "    \n",
        "# ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •\n",
        "output_dir = \"/content/TossCTR/colab_feseq/data/tossctr\"\n",
        "print(f\"ğŸ“ H5 íŒŒì¼ ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸš€ H5 ë³€í™˜ ì‹¤í–‰\n",
        "if train_parquet_path is None:\n",
        "    print(\"âŒ train.parquet íŒŒì¼ì´ ì—†ì–´ì„œ H5 ë³€í™˜ì„ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "else:\n",
        "    print(f\"ğŸš€ Parquet â†’ H5 ë³€í™˜ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
        "    print(f\"ğŸ“Š ì…ë ¥: {train_parquet_path}\")\n",
        "    print(f\"ğŸ“ ì¶œë ¥: {output_dir}\")\n",
        "    print(f\"ğŸ¯ ìƒ˜í”Œ ìˆ˜: {N_SAMPLES:,}ê°œ\")\n",
        "    \n",
        "    # H5 í”„ë¡œì„¸ì„œ ì§ì ‘ ì‹¤í–‰\n",
        "    try:\n",
        "        # íŒŒì´ì¬ì—ì„œ ì§ì ‘ ì‹¤í–‰\n",
        "        sys.path.append('/content/TossCTR/colab_feseq/preprocessing')\n",
        "        from tossctr_parquet_to_h5 import TossCTRParquetProcessor\n",
        "        \n",
        "        # í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”\n",
        "        processor = TossCTRParquetProcessor(\n",
        "            config_path=config_path,\n",
        "            data_root=\"/content/TossCTR/colab_feseq/data\"\n",
        "        )\n",
        "        \n",
        "        # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰\n",
        "        processor.process_full_pipeline(\n",
        "            train_parquet_path=train_parquet_path,\n",
        "            chunk_size=CHUNK_SIZE,\n",
        "            n_samples=N_SAMPLES if N_SAMPLES > 0 else None\n",
        "        )\n",
        "        \n",
        "        print(\"âœ… H5 ë³€í™˜ ì™„ë£Œ!\")\n",
        "        \n",
        "        # ìƒì„±ëœ íŒŒì¼ë“¤ í™•ì¸\n",
        "        h5_files = ['train.h5', 'valid.h5', 'test.h5']\n",
        "        for filename in h5_files:\n",
        "            filepath = os.path.join(output_dir, filename)\n",
        "            if os.path.exists(filepath):\n",
        "                size_mb = os.path.getsize(filepath) / (1024**2)\n",
        "                print(f\"âœ… {filename}: {size_mb:.1f} MB\")\n",
        "            else:\n",
        "                print(f\"âŒ {filename}: ìƒì„±ë˜ì§€ ì•ŠìŒ\")\n",
        "                \n",
        "        # feature_map.json í™•ì¸\n",
        "        feature_map_path = os.path.join(output_dir, \"feature_map.json\")\n",
        "        if os.path.exists(feature_map_path):\n",
        "            print(f\"âœ… feature_map.json: ìƒì„±ë¨\")\n",
        "        else:\n",
        "            print(f\"âŒ feature_map.json: ìƒì„±ë˜ì§€ ì•ŠìŒ\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ H5 ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        \n",
        "        # ëŒ€ì•ˆ: í„°ë¯¸ë„ ëª…ë ¹ì–´ë¡œ ì‹¤í–‰\n",
        "        print(\"\\nğŸ”„ í„°ë¯¸ë„ ëª…ë ¹ì–´ë¡œ ì¬ì‹œë„...\")\n",
        "        cmd = f\"\"\"python /content/TossCTR/colab_feseq/preprocessing/tossctr_parquet_to_h5.py \\\\\n",
        "            --train_path \"{train_parquet_path}\" \\\\\n",
        "            --config_path \"{config_path}\" \\\\\n",
        "            --data_root \"/content/TossCTR/colab_feseq/data\" \\\\\n",
        "            --chunk_size {CHUNK_SIZE} \\\\\n",
        "            --n_samples {N_SAMPLES if N_SAMPLES > 0 else 0}\"\"\"\n",
        "        \n",
        "        print(f\"ì‹¤í–‰ ëª…ë ¹ì–´:\\n{cmd}\")\n",
        "        os.system(cmd)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# âš ï¸ ì´ ì…€ì€ ì‚­ì œë¨ - H5 ë°©ì‹ìœ¼ë¡œ êµì²´\n",
        "# Cell 13ì—ì„œ H5 ë³€í™˜ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
        "print(\"â„¹ï¸  ì´ ì…€ì€ ë” ì´ìƒ ì‚¬ìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
        "print(\"ğŸ“ H5 ë³€í™˜ì€ ìœ„ì˜ Cell 13ì—ì„œ ìˆ˜í–‰ë©ë‹ˆë‹¤.\")\n",
        "print(\"ğŸ”„ Cell 13ì„ ì‹¤í–‰í•˜ì—¬ H5 ë³€í™˜ì„ ì§„í–‰í•˜ì„¸ìš”.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ§  Step 6: FESeq ëª¨ë¸ í›ˆë ¨ ì‹¤í–‰ (H5 ë°©ì‹)\n",
        "\n",
        "H5 í˜•ì‹ìœ¼ë¡œ ë³€í™˜ëœ ë°ì´í„°ë¡œ FESeq ëª¨ë¸ì„ í›ˆë ¨í•©ë‹ˆë‹¤.\n",
        "ìƒˆë¡œìš´ `tossctr_h5_dataset` ì„¤ì •ì„ ì‚¬ìš©í•˜ì—¬ ë” ë¹ ë¥´ê³  ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ í›ˆë ¨ì„ ì§„í–‰í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ“Š H5 ë³€í™˜ëœ ë°ì´í„° í™•ì¸\n",
        "print(\"ğŸ“‹ ìƒì„±ëœ H5 ë°ì´í„° í™•ì¸...\")\n",
        "\n",
        "output_dir = \"/content/TossCTR/colab_feseq/data/tossctr\"\n",
        "h5_files = [\"train.h5\", \"valid.h5\", \"test.h5\"]\n",
        "\n",
        "all_h5_exist = True\n",
        "for h5_file in h5_files:\n",
        "    file_path = os.path.join(output_dir, h5_file)\n",
        "    if os.path.exists(file_path):\n",
        "        size_mb = os.path.getsize(file_path) / (1024**2)\n",
        "        print(f\"âœ… {h5_file}: {size_mb:.2f} MB\")\n",
        "    else:\n",
        "        print(f\"âŒ {h5_file}: íŒŒì¼ ì—†ìŒ\")\n",
        "        all_h5_exist = False\n",
        "\n",
        "# feature_map.json í™•ì¸\n",
        "feature_map_path = os.path.join(output_dir, \"feature_map.json\")\n",
        "if os.path.exists(feature_map_path):\n",
        "    print(f\"âœ… feature_map.json: ìƒì„±ë¨\")\n",
        "    \n",
        "    # feature_map ë‚´ìš© í™•ì¸\n",
        "    import json\n",
        "    with open(feature_map_path, 'r') as f:\n",
        "        feature_map = json.load(f)\n",
        "    print(f\"   ğŸ“Š ì´ í•„ë“œ ìˆ˜: {feature_map.get('num_fields', 'Unknown')}\")\n",
        "    print(f\"   ğŸ”¢ ì´ í”¼ì²˜ ìˆ˜: {feature_map.get('total_features', 'Unknown')}\")\n",
        "else:\n",
        "    print(f\"âŒ feature_map.json: íŒŒì¼ ì—†ìŒ\")\n",
        "    all_h5_exist = False\n",
        "\n",
        "if all_h5_exist:\n",
        "    print(f\"\\nâœ… H5 ë³€í™˜ ì™„ë£Œ! ëª¨ë“  í•„ìˆ˜ íŒŒì¼ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "    print(f\"ğŸ¯ ì‚¬ìš©ëœ ìƒ˜í”Œ ìˆ˜: {N_SAMPLES:,}ê°œ\")\n",
        "    print(\"ğŸš€ ì´ì œ FESeq ëª¨ë¸ í›ˆë ¨ì„ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!\")\n",
        "else:\n",
        "    print(f\"\\nâŒ ì¼ë¶€ H5 íŒŒì¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤. ìœ„ì˜ H5 ë³€í™˜ ë‹¨ê³„ë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n",
        "    print(\"ğŸ’¡ ë°ì´í„°ëŸ‰ì„ ë³€ê²½í•˜ë ¤ë©´ N_SAMPLES ê°’ì„ ìˆ˜ì •í•˜ê³  H5 ë³€í™˜ì„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸš€ FESeq ëª¨ë¸ í›ˆë ¨ ì‹œì‘ (H5 ë°©ì‹)\n",
        "import os\n",
        "print(f\"ğŸ“ í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()}\")\n",
        "\n",
        "# H5 í›ˆë ¨ ì‹¤í–‰ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\n",
        "h5_training_ready = True\n",
        "\n",
        "# í•„ìˆ˜ íŒŒì¼ë“¤ í™•ì¸\n",
        "required_files = [\"run_feseq.py\", \"setup.py\", \"model_zoo/FESeq/run_expid.py\"]\n",
        "print(\"\\nğŸ“‹ í•„ìˆ˜ íŒŒì¼ í™•ì¸:\")\n",
        "for file in required_files:\n",
        "    if os.path.exists(file):\n",
        "        print(f\"âœ… {file}\")\n",
        "    else:\n",
        "        print(f\"âŒ {file}\")\n",
        "        h5_training_ready = False\n",
        "\n",
        "# H5 ë°ì´í„° íŒŒì¼ë“¤ í™•ì¸\n",
        "h5_files = [\"data/tossctr/train.h5\", \"data/tossctr/valid.h5\", \"data/tossctr/test.h5\"]\n",
        "print(\"\\nğŸ“ H5 ë°ì´í„° íŒŒì¼ í™•ì¸:\")\n",
        "for file in h5_files:\n",
        "    if os.path.exists(file):\n",
        "        size_mb = os.path.getsize(file) / (1024**2)\n",
        "        print(f\"âœ… {file} ({size_mb:.1f} MB)\")\n",
        "    else:\n",
        "        print(f\"âŒ {file}\")\n",
        "        h5_training_ready = False\n",
        "\n",
        "if h5_training_ready:\n",
        "    print(\"\\nğŸ¯ H5 ë°©ì‹ FESeq í›ˆë ¨ ì¤€ë¹„ ì™„ë£Œ!\")\n",
        "    print(\"ğŸ“Š ì‚¬ìš©í•  ì„¤ì •: FESeq_tossctr_h5 (H5 ìµœì í™” ë²„ì „)\")\n",
        "else:\n",
        "    print(\"\\nâŒ H5 í›ˆë ¨ ì¤€ë¹„ê°€ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
        "    print(\"ìœ„ì˜ H5 ë³€í™˜ ë‹¨ê³„ë¥¼ ë¨¼ì € ì™„ë£Œí•´ì£¼ì„¸ìš”.\")\n",
        "missing_files = []\n",
        "\n",
        "for file in required_files:\n",
        "    if os.path.exists(file):\n",
        "        print(f\"âœ… {file}\")\n",
        "    else:\n",
        "        print(f\"âŒ {file} - ì—†ìŒ\")\n",
        "        missing_files.append(file)\n",
        "\n",
        "if missing_files:\n",
        "    print(f\"\\nâš ï¸  ë‹¤ìŒ íŒŒì¼ë“¤ì´ ì—†ìŠµë‹ˆë‹¤: {missing_files}\")\n",
        "    print(\"ë””ë ‰í† ë¦¬ë¥¼ ë‹¤ì‹œ í™•ì¸í•˜ì„¸ìš”.\")\n",
        "else:\n",
        "    # GPU ì„¤ì •\n",
        "    import torch\n",
        "    gpu_id = 0 if torch.cuda.is_available() else -1\n",
        "    print(f\"\\nğŸ¯ ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤: {'GPU ' + str(gpu_id) if gpu_id >= 0 else 'CPU'}\")\n",
        "    \n",
        "    # FESeq ì‹¤í—˜ ì‹¤í–‰\n",
        "    print(\"\\nğŸš€ FESeq ì‹¤í—˜ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
        "    !python run_feseq.py --expid FESeq_tossctr --gpu {gpu_id}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸš€ H5 ë°©ì‹ FESeq ëª¨ë¸ í›ˆë ¨ ì‹¤í–‰\n",
        "if h5_training_ready:\n",
        "    print(\"ğŸš€ H5 ë°©ì‹ FESeq ëª¨ë¸ í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
        "    print(\"ğŸ“Š ì„¤ì •: FESeq_tossctr_h5 (H5 ìµœì í™”, ë°°ì¹˜ í¬ê¸° 1024, ì—í¬í¬ 10)\")\n",
        "    \n",
        "    # H5 ì „ìš© ì‹¤í—˜ ID ì‚¬ìš©\n",
        "    expid = \"FESeq_tossctr_h5\"\n",
        "    \n",
        "    try:\n",
        "        # FESeq í›ˆë ¨ ì‹¤í–‰\n",
        "        import subprocess\n",
        "        import sys\n",
        "        \n",
        "        print(f\"â–¶ï¸  ì‹¤í—˜ ID: {expid}\")\n",
        "        print(\"â³ í›ˆë ¨ ì‹œì‘... (H5 ë°©ì‹ìœ¼ë¡œ ë” ë¹ ë¥¸ ì²˜ë¦¬)\")\n",
        "        \n",
        "        # run_expid.pyë¡œ H5 ë°©ì‹ í›ˆë ¨ ì‹¤í–‰\n",
        "        cmd = [\n",
        "            sys.executable, \n",
        "            \"model_zoo/FESeq/run_expid.py\",\n",
        "            \"--config\", \"model_zoo/FESeq/config\",\n",
        "            \"--expid\", expid,\n",
        "            \"--gpu\", \"0\"\n",
        "        ]\n",
        "        \n",
        "        result = subprocess.run(cmd, check=True, capture_output=True, text=True)\n",
        "        \n",
        "        print(\"âœ… H5 ë°©ì‹ FESeq ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!\")\n",
        "        print(\"\\nğŸ“Š í›ˆë ¨ ê²°ê³¼:\")\n",
        "        print(result.stdout[-2000:])  # ë§ˆì§€ë§‰ 2000 ë¬¸ìë§Œ ì¶œë ¥\n",
        "        \n",
        "        # ëª¨ë¸ ì €ì¥ ìœ„ì¹˜ í™•ì¸\n",
        "        model_dir = f\"checkpoints/{expid}\"\n",
        "        if os.path.exists(model_dir):\n",
        "            print(f\"\\nğŸ“ ëª¨ë¸ ì €ì¥ ìœ„ì¹˜: {model_dir}\")\n",
        "            model_files = os.listdir(model_dir)\n",
        "            for file in model_files:\n",
        "                if file.endswith(('.model', '.pkl', '.json')):\n",
        "                    print(f\"  âœ… {file}\")\n",
        "        \n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"âŒ H5 í›ˆë ¨ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "        print(\"\\nğŸ“„ ì—ëŸ¬ ë¡œê·¸:\")\n",
        "        print(e.stderr)\n",
        "        \n",
        "        # ëŒ€ì•ˆ: CSV ë°©ì‹ìœ¼ë¡œ í´ë°±\n",
        "        print(\"\\nğŸ”„ ëŒ€ì•ˆ: ê¸°ì¡´ CSV ë°©ì‹ìœ¼ë¡œ í´ë°± ì‹œë„...\")\n",
        "        try:\n",
        "            fallback_cmd = [\n",
        "                sys.executable, \n",
        "                \"model_zoo/FESeq/run_expid.py\",\n",
        "                \"--config\", \"model_zoo/FESeq/config\", \n",
        "                \"--expid\", \"FESeq_tossctr\",  # ì›ë˜ CSV ì„¤ì •\n",
        "                \"--gpu\", \"0\"\n",
        "            ]\n",
        "            \n",
        "            fallback_result = subprocess.run(fallback_cmd, check=True, capture_output=True, text=True)\n",
        "            print(\"âœ… CSV ë°©ì‹ í´ë°± í›ˆë ¨ ì™„ë£Œ!\")\n",
        "            print(fallback_result.stdout[-1000:])\n",
        "            \n",
        "        except Exception as fallback_error:\n",
        "            print(f\"âŒ í´ë°± í›ˆë ¨ë„ ì‹¤íŒ¨: {fallback_error}\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ì˜ˆê¸°ì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        \n",
        "else:\n",
        "    print(\"âŒ H5 í›ˆë ¨ ì¤€ë¹„ê°€ ì™„ë£Œë˜ì§€ ì•Šì•„ í›ˆë ¨ì„ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
        "    print(\"ìœ„ì˜ ë‹¨ê³„ë“¤ì„ ì™„ë£Œí•œ í›„ ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ”§ Step 6: ë¬¸ì œ í•´ê²° (í•„ìš”ì‹œ)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë¬¸ì œê°€ ìˆì„ ê²½ìš° ìˆ˜ë™ìœ¼ë¡œ ë””ë ‰í† ë¦¬ í™•ì¸ ë° ì´ë™\n",
        "import os\n",
        "\n",
        "print(\"ğŸ” í˜„ì¬ ìœ„ì¹˜ì™€ íŒŒì¼ êµ¬ì¡° í™•ì¸:\")\n",
        "print(f\"í˜„ì¬ ë””ë ‰í† ë¦¬: {os.getcwd()}\")\n",
        "\n",
        "# ê°€ëŠ¥í•œ ìœ„ì¹˜ë“¤ í™•ì¸\n",
        "possible_locations = [\n",
        "    \".\",\n",
        "    \"/content/TossCTR/colab_feseq\", \n",
        "    \"/content/TossCTR\",\n",
        "    \"/content\"\n",
        "]\n",
        "\n",
        "for location in possible_locations:\n",
        "    if os.path.exists(location):\n",
        "        print(f\"\\nğŸ“ {location} ë‚´ìš©:\")\n",
        "        try:\n",
        "            files = os.listdir(location)\n",
        "            for f in files[:10]:  # ì²˜ìŒ 10ê°œë§Œ ì¶œë ¥\n",
        "                print(f\"  - {f}\")\n",
        "            if len(files) > 10:\n",
        "                print(f\"  ... ê·¸ì™¸ {len(files)-10}ê°œ íŒŒì¼\")\n",
        "        except:\n",
        "            print(f\"  ì ‘ê·¼ ë¶ˆê°€\")\n",
        "\n",
        "# run_feseq.py íŒŒì¼ ì°¾ê¸°\n",
        "print(f\"\\nğŸ” run_feseq.py íŒŒì¼ ì°¾ê¸°:\")\n",
        "!find /content -name \"run_feseq.py\" 2>/dev/null\n",
        "\n",
        "# ì˜¬ë°”ë¥¸ ë””ë ‰í† ë¦¬ë¡œ ì´ë™ (ìˆ˜ë™)\n",
        "# ìœ„ì—ì„œ run_feseq.pyê°€ ë°œê²¬ëœ ë””ë ‰í† ë¦¬ë¡œ ì´ë™í•˜ì„¸ìš”\n",
        "# ì˜ˆ: %cd /content/TossCTR/colab_feseq\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ”§ Step 6-2: ì§ì ‘ ì‹¤í–‰ (ëŒ€ì•ˆ ë°©ë²•)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# run_feseq.pyê°€ ì‹¤íŒ¨í•  ê²½ìš° ì§ì ‘ ì‹¤í–‰í•˜ëŠ” ë°©ë²•\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# í˜„ì¬ ë””ë ‰í† ë¦¬ í™•ì¸\n",
        "print(f\"ğŸ“ í˜„ì¬ ìœ„ì¹˜: {os.getcwd()}\")\n",
        "\n",
        "# FESeq ëª¨ë¸ ë””ë ‰í† ë¦¬ë¡œ ì´ë™\n",
        "%cd model_zoo/FESeq\n",
        "\n",
        "# PYTHONPATH ì¬ì„¤ì •\n",
        "original_dir = \"/content/TossCTR/colab_feseq\"  # ë˜ëŠ” ìƒìœ„ ë””ë ‰í† ë¦¬ \n",
        "current_dir = os.getcwd()\n",
        "\n",
        "if original_dir not in sys.path:\n",
        "    sys.path.insert(0, original_dir)\n",
        "if current_dir not in sys.path:\n",
        "    sys.path.insert(0, current_dir)\n",
        "\n",
        "os.environ['PYTHONPATH'] = f\"{original_dir}:{current_dir}\"\n",
        "print(f\"âœ… PYTHONPATH: {os.environ['PYTHONPATH']}\")\n",
        "\n",
        "# ì„¤ì • íŒŒì¼ í™•ì¸\n",
        "print(\"\\nğŸ” ì„¤ì • íŒŒì¼ í™•ì¸:\")\n",
        "config_files = [\"config/dataset_config.yaml\", \"config/model_config.yaml\"]\n",
        "for config_file in config_files:\n",
        "    exists = \"âœ…\" if os.path.exists(config_file) else \"âŒ\"\n",
        "    print(f\"{exists} {config_file}\")\n",
        "\n",
        "# ë°ì´í„° íŒŒì¼ í™•ì¸\n",
        "print(\"\\nğŸ” ë°ì´í„° íŒŒì¼ í™•ì¸:\")\n",
        "data_dir = \"../../data/tossctr\"\n",
        "if os.path.exists(data_dir):\n",
        "    data_files = os.listdir(data_dir)\n",
        "    for file in data_files:\n",
        "        print(f\"âœ… {file}\")\n",
        "else:\n",
        "    print(f\"âŒ ë°ì´í„° ë””ë ‰í† ë¦¬ ì—†ìŒ: {data_dir}\")\n",
        "\n",
        "print(\"\\nğŸš€ ì§ì ‘ run_expid.py ì‹¤í–‰ ì¤€ë¹„ ì™„ë£Œ!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ìµœì¢… ì‹¤í–‰ - run_feseq.py ì‚¬ìš© (ê°œì„ ëœ ë²„ì „)\n",
        "import torch\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# GPU ì„¤ì •\n",
        "gpu_id = 0 if torch.cuda.is_available() else -1\n",
        "print(f\"ğŸ¯ GPU ID: {gpu_id}\")\n",
        "\n",
        "# í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ í™•ì¸\n",
        "print(f\"ğŸ“ í˜„ì¬ ë””ë ‰í† ë¦¬: {os.getcwd()}\")\n",
        "\n",
        "# FESeq ì‹¤í—˜ ì‹¤í–‰ (ì¡°ìš©í•œ ì„¤ì¹˜ í¬í•¨)\n",
        "print(\"ğŸš€ FESeq ì‹¤í—˜ ì‹œì‘...\")\n",
        "\n",
        "try:\n",
        "    # run_feseq.py ì‹¤í–‰ (ê°œì„ ëœ íŒ¨í‚¤ì§€ ì„¤ì¹˜ í¬í•¨)\n",
        "    result = subprocess.run([\n",
        "        sys.executable, \"run_feseq.py\", \n",
        "        \"--expid\", \"FESeq_tossctr\", \n",
        "        \"--gpu\", str(gpu_id)\n",
        "    ], check=True, text=True)\n",
        "    print(\"âœ… FESeq ì‹¤í—˜ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"âŒ ì‹¤í—˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "    print(\"ë¡œê·¸ë¥¼ í™•ì¸í•˜ì—¬ ë¬¸ì œì ì„ íŒŒì•…í•˜ì„¸ìš”.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ”® Step 6: ì¶”ë¡  ë° ì œì¶œ íŒŒì¼ ìƒì„±\n",
        "\n",
        "í›ˆë ¨ëœ FESeq ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ test.parquet ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ê³  ì œì¶œ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ”§ params ê²½ë¡œ ìˆ˜ì • ë° ê²€ì¦\n",
        "print(\"ğŸ”§ ì¶”ë¡ ì„ ìœ„í•œ ë°ì´í„° ê²½ë¡œ ìˆ˜ì •...\")\n",
        "\n",
        "if 'params' in locals() and params is not None:\n",
        "    # í˜„ì¬ paramsì˜ ê²½ë¡œ í™•ì¸\n",
        "    print(f\"ğŸ“‹ í˜„ì¬ ì„¤ì •ëœ ê²½ë¡œ:\")\n",
        "    print(f\"   - í›ˆë ¨: {params.get('train_data', 'N/A')}\")\n",
        "    print(f\"   - ê²€ì¦: {params.get('valid_data', 'N/A')}\")\n",
        "    print(f\"   - í…ŒìŠ¤íŠ¸: {params.get('test_data', 'N/A')}\")\n",
        "    print(f\"   - ë£¨íŠ¸: {params.get('data_root', 'N/A')}\")\n",
        "    \n",
        "    # ìŠ¤ë§ˆíŠ¸ ê²½ë¡œ íƒì§€ ë° ìˆ˜ì •\n",
        "    possible_data_dirs = [\n",
        "        \"/content/TossCTR/colab_feseq/data/tossctr\",      # Colab\n",
        "        \"/Users/hj/projects/TossCTR/colab_feseq/data/tossctr\"  # ë¡œì»¬\n",
        "    ]\n",
        "    \n",
        "    correct_data_dir = None\n",
        "    for dir_path in possible_data_dirs:\n",
        "        test_csv = os.path.join(dir_path, \"test_data.csv\")\n",
        "        if os.path.exists(test_csv):\n",
        "            correct_data_dir = dir_path\n",
        "            print(f\"âœ… ì˜¬ë°”ë¥¸ ë°ì´í„° ë””ë ‰í† ë¦¬ ë°œê²¬: {correct_data_dir}\")\n",
        "            break\n",
        "    \n",
        "    if correct_data_dir:\n",
        "        # ì ˆëŒ€ ê²½ë¡œë¡œ ìˆ˜ì •\n",
        "        params['train_data'] = os.path.join(correct_data_dir, \"train_data.csv\")\n",
        "        params['valid_data'] = os.path.join(correct_data_dir, \"val_data.csv\") \n",
        "        params['test_data'] = os.path.join(correct_data_dir, \"test_data.csv\")\n",
        "        params['data_root'] = os.path.dirname(correct_data_dir)\n",
        "        \n",
        "        print(f\"ğŸ”„ ê²½ë¡œ ìˆ˜ì • ì™„ë£Œ:\")\n",
        "        print(f\"   - í›ˆë ¨: {params['train_data']}\")\n",
        "        print(f\"   - ê²€ì¦: {params['valid_data']}\")\n",
        "        print(f\"   - í…ŒìŠ¤íŠ¸: {params['test_data']}\")\n",
        "        print(f\"   - ë£¨íŠ¸: {params['data_root']}\")\n",
        "        \n",
        "        # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸\n",
        "        for file_type, file_path in [(\"í›ˆë ¨\", params['train_data']), \n",
        "                                   (\"ê²€ì¦\", params['valid_data']), \n",
        "                                   (\"í…ŒìŠ¤íŠ¸\", params['test_data'])]:\n",
        "            exists = \"âœ…\" if os.path.exists(file_path) else \"âŒ\"\n",
        "            print(f\"   {exists} {file_type}: {os.path.basename(file_path)}\")\n",
        "            \n",
        "    else:\n",
        "        print(\"âŒ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤:\")\n",
        "        for dir_path in possible_data_dirs:\n",
        "            test_csv = os.path.join(dir_path, \"test_data.csv\")\n",
        "            exists = \"âœ…\" if os.path.exists(test_csv) else \"âŒ\"\n",
        "            print(f\"   {exists} {test_csv}\")\n",
        "        print(\"ë¨¼ì € ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ì™„ë£Œí•´ì£¼ì„¸ìš”.\")\n",
        "        \n",
        "else:\n",
        "    print(\"âŒ paramsê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € ì´ì „ ì…€ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ”® ê°œì„ ëœ ì¶”ë¡  ë°ì´í„° ë¡œë” ìƒì„± ë° ì˜ˆì¸¡ ìˆ˜í–‰\n",
        "print(\"ğŸ“Š ì¶”ë¡  ë°ì´í„° ë¡œë” ìƒì„± ì¤‘...\")\n",
        "\n",
        "# ëª¨ë¸, Feature Map, paramsê°€ ì œëŒ€ë¡œ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸\n",
        "missing_components = []\n",
        "if 'model' not in locals() or model is None:\n",
        "    missing_components.append(\"ëª¨ë¸\")\n",
        "if 'feature_map' not in locals() or feature_map is None:\n",
        "    missing_components.append(\"Feature Map\")\n",
        "if 'params' not in locals() or params is None:\n",
        "    missing_components.append(\"params\")\n",
        "\n",
        "if missing_components:\n",
        "    print(f\"âŒ ë‹¤ìŒ êµ¬ì„± ìš”ì†Œê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {', '.join(missing_components)}\")\n",
        "    print(\"ì´ì „ ì…€ë“¤ì„ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n",
        "    predictions = None\n",
        "else:\n",
        "    # H5 ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ í™•ì¸\n",
        "    dataset_id = params.get('dataset_id', 'tossctr_dataset')\n",
        "    data_root = params.get('data_root', '')\n",
        "    \n",
        "    # ê°€ëŠ¥í•œ H5 ë°ì´í„°ì…‹ ê²½ë¡œë“¤\n",
        "    possible_h5_dirs = [\n",
        "        os.path.join(data_root, dataset_id),                                    # params ê¸°ë°˜\n",
        "        \"/content/TossCTR/colab_feseq/data/tossctr_dataset\",                   # Colab\n",
        "        \"/Users/hj/projects/TossCTR/colab_feseq/data/tossctr_dataset\"          # ë¡œì»¬\n",
        "    ]\n",
        "    \n",
        "    h5_data_dir = None\n",
        "    for dir_path in possible_h5_dirs:\n",
        "        test_h5_path = os.path.join(dir_path, \"test.h5\")\n",
        "        if os.path.exists(test_h5_path):\n",
        "            h5_data_dir = dir_path\n",
        "            print(f\"âœ… H5 ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ ë°œê²¬: {h5_data_dir}\")\n",
        "            print(f\"âœ… test.h5 íŒŒì¼ í™•ì¸: {test_h5_path}\")\n",
        "            break\n",
        "    \n",
        "    if h5_data_dir:\n",
        "        try:\n",
        "            # feature_mapì˜ data_dir ì—…ë°ì´íŠ¸\n",
        "            feature_map.data_dir = h5_data_dir\n",
        "            \n",
        "            # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë” ìƒì„±\n",
        "            print(\"ğŸ”„ H5DataLoader ì´ˆê¸°í™” ì¤‘...\")\n",
        "            test_loader = H5DataLoader(feature_map, stage='test', **params).make_iterator()\n",
        "            \n",
        "            print(\"ğŸ”® ëª¨ë¸ ì¶”ë¡  ì‹œì‘...\")\n",
        "            predictions = []\n",
        "            batch_count = 0\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                for batch_idx, batch_data in enumerate(test_loader):\n",
        "                    # ë°°ì¹˜ ì˜ˆì¸¡\n",
        "                    output = model(batch_data)\n",
        "                    batch_pred = torch.sigmoid(output['y_pred']).cpu().numpy().flatten()\n",
        "                    predictions.extend(batch_pred)\n",
        "                    batch_count += 1\n",
        "                    \n",
        "                    # ì§„í–‰ ìƒí™© ì¶œë ¥ (ë§¤ 10ë°°ì¹˜ë§ˆë‹¤)\n",
        "                    if batch_idx % 10 == 0:\n",
        "                        print(f\"  ì²˜ë¦¬ëœ ë°°ì¹˜: {batch_idx + 1}, ëˆ„ì  ì˜ˆì¸¡ ìˆ˜: {len(predictions)}\")\n",
        "            \n",
        "            print(f\"âœ… ì¶”ë¡  ì™„ë£Œ!\")\n",
        "            print(f\"ğŸ“Š ì´ ì²˜ë¦¬ëœ ë°°ì¹˜: {batch_count}\")\n",
        "            print(f\"ğŸ“Š ì´ ì˜ˆì¸¡ ìƒ˜í”Œ ìˆ˜: {len(predictions)}\")\n",
        "            print(f\"ğŸ“Š ì˜ˆì¸¡ê°’ ë²”ìœ„: {min(predictions):.6f} ~ {max(predictions):.6f}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ì¶”ë¡  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "            print(f\"ğŸ“‹ ë””ë²„ê·¸ ì •ë³´:\")\n",
        "            print(f\"   - feature_map.data_dir: {getattr(feature_map, 'data_dir', 'N/A')}\")\n",
        "            print(f\"   - H5 ë””ë ‰í† ë¦¬: {h5_data_dir}\")\n",
        "            print(f\"   - params.test_data: {params.get('test_data', 'N/A')}\")\n",
        "            predictions = None\n",
        "    else:\n",
        "        print(\"âŒ H5 ë°ì´í„°ì…‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤:\")\n",
        "        for dir_path in possible_h5_dirs:\n",
        "            test_h5_path = os.path.join(dir_path, \"test.h5\")\n",
        "            exists = \"âœ…\" if os.path.exists(test_h5_path) else \"âŒ\"\n",
        "            print(f\"   {exists} {test_h5_path}\")\n",
        "        \n",
        "        print(\"\\nğŸ“‹ í•´ê²° ë°©ë²•:\")\n",
        "        print(\"1. ë¨¼ì € FESeq ëª¨ë¸ í›ˆë ¨ì„ ì™„ë£Œí•˜ì„¸ìš” (H5 íŒŒì¼ì´ ìë™ ìƒì„±ë©ë‹ˆë‹¤)\")\n",
        "        print(\"2. ë˜ëŠ” ë°ì´í„° ì „ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”\")\n",
        "        predictions = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì¶”ë¡ ì„ ìœ„í•œ í•„ìˆ˜ ì„í¬íŠ¸\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import h5py\n",
        "import json\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# FuxiCTR ê´€ë ¨ ì„í¬íŠ¸\n",
        "sys.path.append('/content/TossCTR/colab_feseq')\n",
        "sys.path.append('/content/TossCTR/colab_feseq/model_zoo/FESeq')\n",
        "\n",
        "from fuxictr.features import FeatureMapAbsTime\n",
        "from fuxictr.pytorch.dataloaders import H5DataLoader\n",
        "from model_zoo.FESeq.src.FESeq import FESeq\n",
        "\n",
        "print(\"âœ… ì¶”ë¡ ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì‹¤ì œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ (ìŠ¤ë§ˆíŠ¸ ê²½ë¡œ íƒì§€)\n",
        "print(\"ğŸ“¥ ì›ë³¸ test.parquet ë°ì´í„° ë¡œë“œ ì¤‘...\")\n",
        "\n",
        "# ê°€ëŠ¥í•œ test.parquet íŒŒì¼ ê²½ë¡œë“¤ (ìš°ì„ ìˆœìœ„ ìˆœ)\n",
        "possible_test_paths = [\n",
        "    \"/content/drive/MyDrive/data/TossCTR/raw/test.parquet\",     # Colab êµ¬ê¸€ ë“œë¼ì´ë¸Œ\n",
        "    \"/content/TossCTR/data/raw/test.parquet\",                  # Colab ë¡œì»¬\n",
        "    \"/Users/hj/projects/TossCTR/data/raw/test.parquet\"         # ë¡œì»¬ í™˜ê²½\n",
        "]\n",
        "\n",
        "# ê°€ëŠ¥í•œ ì „ì²˜ë¦¬ëœ ë°ì´í„° ê²½ë¡œë“¤\n",
        "possible_csv_paths = [\n",
        "    \"/content/TossCTR/colab_feseq/data/tossctr/test_data.csv\", # Colab\n",
        "    \"/Users/hj/projects/TossCTR/colab_feseq/data/tossctr/test_data.csv\" # ë¡œì»¬\n",
        "]\n",
        "\n",
        "test_df_original = None\n",
        "used_path = None\n",
        "\n",
        "# 1ì°¨ ì‹œë„: ì›ë³¸ parquet íŒŒì¼ ì°¾ê¸°\n",
        "for test_parquet_path in possible_test_paths:\n",
        "    if os.path.exists(test_parquet_path):\n",
        "        try:\n",
        "            print(f\"ğŸ” ì‹œë„ ì¤‘: {test_parquet_path}\")\n",
        "            test_df_original = pd.read_parquet(test_parquet_path)\n",
        "            used_path = test_parquet_path\n",
        "            print(f\"âœ… ì›ë³¸ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {test_df_original.shape}\")\n",
        "            print(f\"ğŸ“ ì‚¬ìš©ëœ ê²½ë¡œ: {used_path}\")\n",
        "            print(f\"ğŸ“‹ ì»¬ëŸ¼: {list(test_df_original.columns)}\")\n",
        "            print(f\"ğŸ“Š ìƒ˜í”Œ ë°ì´í„°:\")\n",
        "            print(test_df_original.head())\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸  {test_parquet_path} ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
        "            continue\n",
        "\n",
        "# 2ì°¨ ì‹œë„: ì „ì²˜ë¦¬ëœ CSV íŒŒì¼ ì°¾ê¸°\n",
        "if test_df_original is None:\n",
        "    print(\"ğŸ“„ ì›ë³¸ parquet íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ì „ì²˜ë¦¬ëœ CSV íŒŒì¼ì„ ì°¾ëŠ” ì¤‘...\")\n",
        "    for test_csv_path in possible_csv_paths:\n",
        "        if os.path.exists(test_csv_path):\n",
        "            try:\n",
        "                print(f\"ğŸ” ì‹œë„ ì¤‘: {test_csv_path}\")\n",
        "                test_df_original = pd.read_csv(test_csv_path)\n",
        "                used_path = test_csv_path\n",
        "                print(f\"âœ… ì „ì²˜ë¦¬ëœ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì‚¬ìš©: {test_df_original.shape}\")\n",
        "                print(f\"ğŸ“ ì‚¬ìš©ëœ ê²½ë¡œ: {used_path}\")\n",
        "                break\n",
        "            except Exception as e:\n",
        "                print(f\"âš ï¸  {test_csv_path} ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
        "                continue\n",
        "\n",
        "# ê²°ê³¼ í™•ì¸\n",
        "if test_df_original is None:\n",
        "    print(\"âŒ ì‚¬ìš© ê°€ëŠ¥í•œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "    print(\"ğŸ“‹ í™•ì¸ëœ ê²½ë¡œë“¤:\")\n",
        "    for path in possible_test_paths + possible_csv_paths:\n",
        "        exists = \"âœ…\" if os.path.exists(path) else \"âŒ\"\n",
        "        print(f\"   {exists} {path}\")\n",
        "else:\n",
        "    print(f\"ğŸ¯ ìµœì¢… ì‚¬ìš© ë°ì´í„°: {used_path}\")\n",
        "    print(f\"ğŸ“Š ë°ì´í„° í˜•íƒœ: {test_df_original.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ ë° ì„¤ì •\n",
        "print(\"ğŸ”„ í›ˆë ¨ëœ FESeq ëª¨ë¸ ë¡œë“œ ì¤‘...\")\n",
        "\n",
        "# ì„¤ì • íŒŒì¼ ë¡œë“œ\n",
        "config_path = \"/content/TossCTR/colab_feseq/model_zoo/FESeq/config\"\n",
        "sys.path.append(config_path)\n",
        "\n",
        "# FuxiCTR utils ì„í¬íŠ¸\n",
        "from fuxictr.utils import load_config\n",
        "\n",
        "# ëª¨ë¸ ì„¤ì • ë¡œë“œ\n",
        "params = load_config(config_path, \"FESeq_tossctr\")\n",
        "params['gpu'] = 0 if torch.cuda.is_available() else -1\n",
        "\n",
        "print(f\"âœ… ëª¨ë¸ ì„¤ì • ë¡œë“œ ì™„ë£Œ\")\n",
        "print(f\"ğŸ“‹ ì£¼ìš” ì„¤ì •:\")\n",
        "print(f\"   - ëª¨ë¸: {params.get('model', 'N/A')}\")\n",
        "print(f\"   - ë°°ì¹˜ í¬ê¸°: {params.get('batch_size', 'N/A')}\")\n",
        "print(f\"   - ì„ë² ë”© ì°¨ì›: {params.get('embedding_dim', 'N/A')}\")\n",
        "print(f\"   - GPU: {params['gpu']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature Map ë° ëª¨ë¸ ì´ˆê¸°í™” (ìŠ¤ë§ˆíŠ¸ ê²½ë¡œ íƒì§€)\n",
        "print(\"ğŸ—ºï¸ Feature Map ë¡œë“œ ì¤‘...\")\n",
        "\n",
        "# ê°€ëŠ¥í•œ ë°ì´í„° ë””ë ‰í† ë¦¬ë“¤\n",
        "possible_data_dirs = [\n",
        "    \"/content/TossCTR/colab_feseq/data/tossctr_dataset\",      # Colab\n",
        "    \"/Users/hj/projects/TossCTR/colab_feseq/data/tossctr_dataset\"  # ë¡œì»¬\n",
        "]\n",
        "\n",
        "# ê°€ëŠ¥í•œ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œë“¤\n",
        "possible_checkpoint_paths = [\n",
        "    \"/content/TossCTR/colab_feseq/model_zoo/FESeq/checkpoints/tossctr_dataset/FESeq_tossctr.model\",  # Colab\n",
        "    \"/Users/hj/projects/TossCTR/colab_feseq/model_zoo/FESeq/checkpoints/tossctr_dataset/FESeq_tossctr.model\"  # ë¡œì»¬\n",
        "]\n",
        "\n",
        "# ë°ì´í„° ë””ë ‰í† ë¦¬ ì°¾ê¸°\n",
        "data_dir = None\n",
        "for dir_path in possible_data_dirs:\n",
        "    feature_map_json = os.path.join(dir_path, \"feature_map.json\")\n",
        "    if os.path.exists(feature_map_json):\n",
        "        data_dir = dir_path\n",
        "        print(f\"âœ… ë°ì´í„° ë””ë ‰í† ë¦¬ ë°œê²¬: {data_dir}\")\n",
        "        break\n",
        "\n",
        "if data_dir is None:\n",
        "    print(\"âŒ Feature map íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤:\")\n",
        "    for dir_path in possible_data_dirs:\n",
        "        feature_map_json = os.path.join(dir_path, \"feature_map.json\")\n",
        "        exists = \"âœ…\" if os.path.exists(feature_map_json) else \"âŒ\"\n",
        "        print(f\"   {exists} {feature_map_json}\")\n",
        "    print(\"ë¨¼ì € ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ì™„ë£Œí•˜ê±°ë‚˜ ëª¨ë¸ í›ˆë ¨ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n",
        "else:\n",
        "    # Feature Map ë¡œë“œ\n",
        "    feature_map_json = os.path.join(data_dir, \"feature_map.json\")\n",
        "    feature_map = FeatureMapAbsTime(params['dataset_id'], data_dir)\n",
        "    feature_map.load(feature_map_json, params)\n",
        "\n",
        "    print(f\"âœ… Feature Map ë¡œë“œ ì™„ë£Œ\")\n",
        "    print(f\"ğŸ“Š í”¼ì²˜ ìˆ˜: {len(feature_map.features)}\")\n",
        "\n",
        "    # FESeq ëª¨ë¸ ì´ˆê¸°í™”\n",
        "    print(\"ğŸ§  FESeq ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...\")\n",
        "    model = FESeq(feature_map, params=params, **params)\n",
        "\n",
        "    # í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ\n",
        "    checkpoint_path = None\n",
        "    for cp_path in possible_checkpoint_paths:\n",
        "        if os.path.exists(cp_path):\n",
        "            checkpoint_path = cp_path\n",
        "            print(f\"âœ… ì²´í¬í¬ì¸íŠ¸ ë°œê²¬: {checkpoint_path}\")\n",
        "            break\n",
        "    \n",
        "    if checkpoint_path:\n",
        "        try:\n",
        "            model.load_weights(checkpoint_path)\n",
        "            print(f\"âœ… í›ˆë ¨ëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ\")\n",
        "            \n",
        "            # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •\n",
        "            model.eval()\n",
        "            print(\"âœ… ëª¨ë¸ì´ ì¶”ë¡  ëª¨ë“œë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
        "            model = None\n",
        "    else:\n",
        "        print(\"âŒ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤:\")\n",
        "        for cp_path in possible_checkpoint_paths:\n",
        "            exists = \"âœ…\" if os.path.exists(cp_path) else \"âŒ\"\n",
        "            print(f\"   {exists} {cp_path}\")\n",
        "        print(\"ë¨¼ì € ëª¨ë¸ í›ˆë ¨ì„ ì™„ë£Œí•´ì£¼ì„¸ìš”.\")\n",
        "        model = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì‹¤ì œ test.parquet ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜ (ê°œì„ ëœ ë²„ì „)\n",
        "def preprocess_test_data_for_feseq(test_df_original, used_path, output_path=\"/content/TossCTR/colab_feseq/data/tossctr/inference_test.csv\"):\n",
        "    \"\"\"\n",
        "    ì›ë³¸ test.parquet ë°ì´í„°ë¥¼ FESeq í˜•ì‹ì— ë§ê²Œ ì „ì²˜ë¦¬\n",
        "    \"\"\"\n",
        "    print(\"ğŸ”„ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ FESeq í˜•ì‹ìœ¼ë¡œ ì „ì²˜ë¦¬ ì¤‘...\")\n",
        "    \n",
        "    # ì´ë¯¸ FESeq í˜•ì‹ì´ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
        "    if used_path and used_path.endswith('.csv') and 'test_data.csv' in used_path:\n",
        "        print(\"âœ… ì´ë¯¸ FESeq í˜•ì‹ìœ¼ë¡œ ì „ì²˜ë¦¬ëœ ë°ì´í„°ì…ë‹ˆë‹¤.\")\n",
        "        return used_path\n",
        "    \n",
        "    # ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œë“¤\n",
        "    possible_script_paths = [\n",
        "        \"/content/TossCTR/colab_feseq/preprocessing/tossctr_to_feseq.py\",  # Colab\n",
        "        \"/Users/hj/projects/TossCTR/colab_feseq/preprocessing/tossctr_to_feseq.py\"  # ë¡œì»¬\n",
        "    ]\n",
        "    \n",
        "    preprocessing_script = None\n",
        "    for script_path in possible_script_paths:\n",
        "        if os.path.exists(script_path):\n",
        "            preprocessing_script = script_path\n",
        "            break\n",
        "    \n",
        "    if preprocessing_script:\n",
        "        print(f\"ğŸ”§ ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰: {preprocessing_script}\")\n",
        "        \n",
        "        # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±\n",
        "        temp_dir = \"/tmp\" if os.path.exists(\"/tmp\") else \"/content\"\n",
        "        temp_test_path = os.path.join(temp_dir, \"temp_test_for_inference.parquet\")\n",
        "        \n",
        "        try:\n",
        "            # test ë°ì´í„°ë¥¼ ì„ì‹œë¡œ ì €ì¥\n",
        "            test_df_original.to_parquet(temp_test_path, index=False)\n",
        "            print(f\"ğŸ“ ì„ì‹œ íŒŒì¼ ìƒì„±: {temp_test_path}\")\n",
        "            \n",
        "            # ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ (ìˆ˜ì •ëœ ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©)\n",
        "            result = subprocess.run([\n",
        "                sys.executable, preprocessing_script,\n",
        "                \"--test_path\", temp_test_path,\n",
        "                \"--output_path\", output_path,\n",
        "                \"--n_samples\", str(len(test_df_original))  # ì „ì²´ ë°ì´í„° ì‚¬ìš©\n",
        "            ], check=True, capture_output=True, text=True)\n",
        "            \n",
        "            print(\"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ\")\n",
        "            print(f\"ğŸ“„ í‘œì¤€ ì¶œë ¥: {result.stdout}\")\n",
        "            \n",
        "            # ì„ì‹œ íŒŒì¼ ì‚­ì œ\n",
        "            if os.path.exists(temp_test_path):\n",
        "                os.remove(temp_test_path)\n",
        "                print(\"ğŸ—‘ï¸  ì„ì‹œ íŒŒì¼ ì‚­ì œë¨\")\n",
        "                \n",
        "            # ê²°ê³¼ íŒŒì¼ í™•ì¸\n",
        "            if os.path.exists(output_path):\n",
        "                processed_df = pd.read_csv(output_path)\n",
        "                print(f\"âœ… ì „ì²˜ë¦¬ëœ ë°ì´í„° í™•ì¸: {processed_df.shape}\")\n",
        "                return output_path\n",
        "            else:\n",
        "                print(f\"âŒ ì „ì²˜ë¦¬ ê²°ê³¼ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {output_path}\")\n",
        "                return None\n",
        "                \n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"âŒ ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}\")\n",
        "            print(f\"ğŸ“„ í‘œì¤€ ì¶œë ¥: {e.stdout}\")\n",
        "            print(f\"ğŸš¨ ì—ëŸ¬ ì¶œë ¥: {e.stderr}\")\n",
        "            \n",
        "            # ì„ì‹œ íŒŒì¼ ì •ë¦¬\n",
        "            if os.path.exists(temp_test_path):\n",
        "                os.remove(temp_test_path)\n",
        "            \n",
        "            return None\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ì˜ˆê¸°ì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}\")\n",
        "            if os.path.exists(temp_test_path):\n",
        "                os.remove(temp_test_path)\n",
        "            return None\n",
        "    else:\n",
        "        print(f\"âŒ ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤:\")\n",
        "        for script_path in possible_script_paths:\n",
        "            exists = \"âœ…\" if os.path.exists(script_path) else \"âŒ\"\n",
        "            print(f\"   {exists} {script_path}\")\n",
        "        \n",
        "        # ëŒ€ì•ˆ: ê¸°ì¡´ ì „ì²˜ë¦¬ëœ íŒŒì¼ ì‚¬ìš©\n",
        "        fallback_paths = [\n",
        "            \"/content/TossCTR/colab_feseq/data/tossctr/test_data.csv\",\n",
        "            \"/Users/hj/projects/TossCTR/colab_feseq/data/tossctr/test_data.csv\"\n",
        "        ]\n",
        "        for fallback_path in fallback_paths:\n",
        "            if os.path.exists(fallback_path):\n",
        "                print(f\"ğŸ“„ ê¸°ì¡´ ì „ì²˜ë¦¬ëœ íŒŒì¼ ì‚¬ìš©: {fallback_path}\")\n",
        "                return fallback_path\n",
        "        \n",
        "        print(\"âŒ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì „ì²˜ë¦¬ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        return None\n",
        "\n",
        "# ì›ë³¸ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì „ì²˜ë¦¬ ì‹¤í–‰\n",
        "if test_df_original is not None:\n",
        "    inference_test_path = preprocess_test_data_for_feseq(test_df_original, used_path)\n",
        "    if inference_test_path:\n",
        "        print(f\"ğŸ¯ ì¶”ë¡ ìš© í…ŒìŠ¤íŠ¸ ë°ì´í„° ê²½ë¡œ: {inference_test_path}\")\n",
        "    else:\n",
        "        print(\"âŒ ì „ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê¸°ë³¸ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
        "        inference_test_path = \"/content/TossCTR/colab_feseq/data/tossctr/test_data.csv\"\n",
        "else:\n",
        "    print(\"âŒ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\")\n",
        "    inference_test_path = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì¶”ë¡  ë°ì´í„° ë¡œë” ìƒì„± ë° ì˜ˆì¸¡ ìˆ˜í–‰\n",
        "print(\"ğŸ“Š ì¶”ë¡  ë°ì´í„° ë¡œë” ìƒì„± ì¤‘...\")\n",
        "\n",
        "# ëª¨ë¸ê³¼ Feature Mapì´ ì œëŒ€ë¡œ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸\n",
        "if 'model' not in locals() or model is None or 'feature_map' not in locals():\n",
        "    print(\"âŒ ëª¨ë¸ ë˜ëŠ” Feature Mapì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
        "    predictions = None\n",
        "else:\n",
        "    # ê°€ëŠ¥í•œ test.h5 íŒŒì¼ ê²½ë¡œë“¤\n",
        "    possible_h5_paths = [\n",
        "        \"/content/TossCTR/colab_feseq/data/tossctr_dataset/test.h5\",      # Colab\n",
        "        \"/Users/hj/projects/TossCTR/colab_feseq/data/tossctr_dataset/test.h5\"  # ë¡œì»¬\n",
        "    ]\n",
        "    \n",
        "    test_h5_path = None\n",
        "    for h5_path in possible_h5_paths:\n",
        "        if os.path.exists(h5_path):\n",
        "            test_h5_path = h5_path\n",
        "            print(f\"âœ… test.h5 íŒŒì¼ ë°œê²¬: {test_h5_path}\")\n",
        "            break\n",
        "    \n",
        "    if test_h5_path:\n",
        "        try:\n",
        "            # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë” ìƒì„±\n",
        "            test_loader = H5DataLoader(feature_map, stage='test', **params).make_iterator()\n",
        "            \n",
        "            print(\"ğŸ”® ëª¨ë¸ ì¶”ë¡  ì‹œì‘...\")\n",
        "            predictions = []\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                for batch_idx, batch_data in enumerate(test_loader):\n",
        "                    # ë°°ì¹˜ ì˜ˆì¸¡\n",
        "                    output = model(batch_data)\n",
        "                    batch_pred = torch.sigmoid(output['y_pred']).cpu().numpy().flatten()\n",
        "                    predictions.extend(batch_pred)\n",
        "                    \n",
        "                    # ì§„í–‰ ìƒí™© ì¶œë ¥\n",
        "                    if batch_idx % 10 == 0:\n",
        "                        print(f\"  ì²˜ë¦¬ëœ ë°°ì¹˜: {batch_idx + 1}\")\n",
        "            \n",
        "            print(f\"âœ… ì¶”ë¡  ì™„ë£Œ! ì´ {len(predictions)}ê°œ ìƒ˜í”Œ ì˜ˆì¸¡\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ì¶”ë¡  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "            predictions = None\n",
        "    else:\n",
        "        print(\"âŒ test.h5 íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤:\")\n",
        "        for h5_path in possible_h5_paths:\n",
        "            exists = \"âœ…\" if os.path.exists(h5_path) else \"âŒ\"\n",
        "            print(f\"   {exists} {h5_path}\")\n",
        "        print(\"ë°ì´í„° ì „ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n",
        "        predictions = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì œì¶œ íŒŒì¼ ìƒì„±\n",
        "if predictions is not None:\n",
        "    print(\"ğŸ“ ì œì¶œ íŒŒì¼ ìƒì„± ì¤‘...\")\n",
        "    \n",
        "    # sample_submission.csv ë¡œë“œ (ìŠ¤ë§ˆíŠ¸ ê²½ë¡œ íƒì§€)\n",
        "    possible_submission_paths = [\n",
        "        \"/content/drive/MyDrive/data/TossCTR/raw/sample_submission.csv\",  # Colab êµ¬ê¸€ ë“œë¼ì´ë¸Œ\n",
        "        \"/content/TossCTR/data/raw/sample_submission.csv\",               # Colab ë¡œì»¬\n",
        "        \"/Users/hj/projects/TossCTR/data/raw/sample_submission.csv\"      # ë¡œì»¬ í™˜ê²½\n",
        "    ]\n",
        "    \n",
        "    sample_submission_path = None\n",
        "    for sub_path in possible_submission_paths:\n",
        "        if os.path.exists(sub_path):\n",
        "            sample_submission_path = sub_path\n",
        "            print(f\"âœ… sample_submission.csv ë°œê²¬: {sample_submission_path}\")\n",
        "            break\n",
        "    if os.path.exists(sample_submission_path):\n",
        "        submission_df = pd.read_csv(sample_submission_path)\n",
        "        print(f\"âœ… sample_submission.csv ë¡œë“œ ì™„ë£Œ: {submission_df.shape}\")\n",
        "        \n",
        "        # ì˜ˆì¸¡ê°’ ê¸¸ì´ í™•ì¸ ë° ì¡°ì •\n",
        "        if len(predictions) != len(submission_df):\n",
        "            print(f\"âš ï¸  ì˜ˆì¸¡ê°’ ê¸¸ì´ ë¶ˆì¼ì¹˜: ì˜ˆì¸¡ê°’ {len(predictions)}, ì œì¶œíŒŒì¼ {len(submission_df)}\")\n",
        "            \n",
        "            # ê¸¸ì´ ë§ì¶”ê¸°\n",
        "            if len(predictions) > len(submission_df):\n",
        "                predictions = predictions[:len(submission_df)]\n",
        "                print(f\"âœ‚ï¸  ì˜ˆì¸¡ê°’ì„ {len(submission_df)}ê°œë¡œ ì˜ëìŠµë‹ˆë‹¤.\")\n",
        "            else:\n",
        "                # ë¶€ì¡±í•œ ê²½ìš° í‰ê· ê°’ìœ¼ë¡œ ì±„ìš°ê¸°\n",
        "                mean_pred = np.mean(predictions)\n",
        "                predictions.extend([mean_pred] * (len(submission_df) - len(predictions)))\n",
        "                print(f\"ğŸ“ˆ ì˜ˆì¸¡ê°’ì„ í‰ê· ê°’({mean_pred:.4f})ë¡œ {len(submission_df)}ê°œê¹Œì§€ ì±„ì› ìŠµë‹ˆë‹¤.\")\n",
        "        \n",
        "        # ì˜ˆì¸¡ê°’ì„ ì œì¶œ íŒŒì¼ì— í• ë‹¹\n",
        "        submission_df['clicked'] = predictions\n",
        "        \n",
        "        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„± (ìŠ¤ë§ˆíŠ¸ ê²½ë¡œ)\n",
        "        possible_output_dirs = [\n",
        "            \"/content/TossCTR/data/output\",              # Colab\n",
        "            \"/Users/hj/projects/TossCTR/data/output\"     # ë¡œì»¬\n",
        "        ]\n",
        "        \n",
        "        output_dir = None\n",
        "        for out_dir in possible_output_dirs:\n",
        "            try:\n",
        "                os.makedirs(out_dir, exist_ok=True)\n",
        "                output_dir = out_dir\n",
        "                print(f\"âœ… ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •: {output_dir}\")\n",
        "                break\n",
        "            except:\n",
        "                continue\n",
        "        \n",
        "        if output_dir is None:\n",
        "            output_dir = \"/tmp/output\"  # ì„ì‹œ ë””ë ‰í† ë¦¬ ì‚¬ìš©\n",
        "            os.makedirs(output_dir, exist_ok=True)\n",
        "            print(f\"âš ï¸  ì„ì‹œ ì¶œë ¥ ë””ë ‰í† ë¦¬ ì‚¬ìš©: {output_dir}\")\n",
        "        \n",
        "        # ì œì¶œ íŒŒì¼ ì €ì¥\n",
        "        output_path = os.path.join(output_dir, \"feseq_submission.csv\")\n",
        "        submission_df.to_csv(output_path, index=False)\n",
        "        \n",
        "        print(f\"âœ… ì œì¶œ íŒŒì¼ ìƒì„± ì™„ë£Œ: {output_path}\")\n",
        "        print(f\"ğŸ“Š ì˜ˆì¸¡ í†µê³„:\")\n",
        "        print(f\"   - ìµœì†Ÿê°’: {np.min(predictions):.6f}\")\n",
        "        print(f\"   - ìµœëŒ“ê°’: {np.max(predictions):.6f}\")\n",
        "        print(f\"   - í‰ê· ê°’: {np.mean(predictions):.6f}\")\n",
        "        print(f\"   - í‘œì¤€í¸ì°¨: {np.std(predictions):.6f}\")\n",
        "        \n",
        "        # ì˜ˆì¸¡ê°’ ë¶„í¬ í™•ì¸\n",
        "        print(f\"ğŸ“ˆ ì˜ˆì¸¡ê°’ ë¶„í¬:\")\n",
        "        hist, bins = np.histogram(predictions, bins=10)\n",
        "        for i in range(len(hist)):\n",
        "            print(f\"   {bins[i]:.3f}-{bins[i+1]:.3f}: {hist[i]}ê°œ\")\n",
        "            \n",
        "    else:\n",
        "        print(\"âŒ sample_submission.csvë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤:\")\n",
        "        for sub_path in possible_submission_paths:\n",
        "            exists = \"âœ…\" if os.path.exists(sub_path) else \"âŒ\"\n",
        "            print(f\"   {exists} {sub_path}\")\n",
        "\n",
        "else:\n",
        "    print(\"âŒ ì˜ˆì¸¡ê°’ì´ ì—†ìŠµë‹ˆë‹¤. ì¶”ë¡ ì„ ë¨¼ì € ì™„ë£Œí•´ì£¼ì„¸ìš”.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ê²°ê³¼ ê²€ì¦ ë° ìµœì¢… í™•ì¸\n",
        "print(\"ğŸ” ìµœì¢… ê²°ê³¼ ê²€ì¦...\")\n",
        "\n",
        "# ìƒì„±ëœ ì œì¶œ íŒŒì¼ í™•ì¸ (ìŠ¤ë§ˆíŠ¸ ê²½ë¡œ)\n",
        "possible_output_dirs = [\n",
        "    \"/content/TossCTR/data/output\",              # Colab\n",
        "    \"/Users/hj/projects/TossCTR/data/output\",    # ë¡œì»¬\n",
        "    \"/tmp/output\"                                # ì„ì‹œ\n",
        "]\n",
        "\n",
        "feseq_submission_path = None\n",
        "for output_dir in possible_output_dirs:\n",
        "    potential_path = os.path.join(output_dir, \"feseq_submission.csv\")\n",
        "    if os.path.exists(potential_path):\n",
        "        feseq_submission_path = potential_path\n",
        "        break\n",
        "\n",
        "if os.path.exists(feseq_submission_path):\n",
        "    # ì œì¶œ íŒŒì¼ ë¡œë“œ ë° ê²€ì¦\n",
        "    final_submission = pd.read_csv(feseq_submission_path)\n",
        "    \n",
        "    print(f\"âœ… ìµœì¢… ì œì¶œ íŒŒì¼ ê²€ì¦ ì™„ë£Œ:\")\n",
        "    print(f\"   ğŸ“ íŒŒì¼ ê²½ë¡œ: {feseq_submission_path}\")\n",
        "    print(f\"   ğŸ“Š íŒŒì¼ í¬ê¸°: {final_submission.shape}\")\n",
        "    print(f\"   ğŸ“‹ ì»¬ëŸ¼: {list(final_submission.columns)}\")\n",
        "    \n",
        "    # ì œì¶œ íŒŒì¼ í˜•ì‹ ê²€ì¦\n",
        "    required_columns = ['ID', 'clicked']\n",
        "    missing_columns = [col for col in required_columns if col not in final_submission.columns]\n",
        "    \n",
        "    if missing_columns:\n",
        "        print(f\"âŒ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_columns}\")\n",
        "    else:\n",
        "        print(\"âœ… ì œì¶œ íŒŒì¼ í˜•ì‹ ê²€ì¦ í†µê³¼\")\n",
        "    \n",
        "    # ì˜ˆì¸¡ê°’ ë²”ìœ„ ê²€ì¦\n",
        "    clicked_values = final_submission['clicked']\n",
        "    if clicked_values.min() >= 0 and clicked_values.max() <= 1:\n",
        "        print(\"âœ… ì˜ˆì¸¡ê°’ ë²”ìœ„ ê²€ì¦ í†µê³¼ (0-1 ì‚¬ì´)\")\n",
        "    else:\n",
        "        print(f\"âš ï¸  ì˜ˆì¸¡ê°’ ë²”ìœ„ ì£¼ì˜: {clicked_values.min():.6f} ~ {clicked_values.max():.6f}\")\n",
        "    \n",
        "    # ê²°ì¸¡ê°’ í™•ì¸\n",
        "    if clicked_values.isnull().sum() == 0:\n",
        "        print(\"âœ… ê²°ì¸¡ê°’ ì—†ìŒ\")\n",
        "    else:\n",
        "        print(f\"âš ï¸  ê²°ì¸¡ê°’ ë°œê²¬: {clicked_values.isnull().sum()}ê°œ\")\n",
        "    \n",
        "    # ìƒ˜í”Œ ì¶œë ¥\n",
        "    print(f\"\\nğŸ“‹ ì œì¶œ íŒŒì¼ ìƒ˜í”Œ:\")\n",
        "    print(final_submission.head(10))\n",
        "    \n",
        "    print(f\"\\nğŸ‰ FESeq ëª¨ë¸ ì¶”ë¡  ë° ì œì¶œ íŒŒì¼ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
        "    print(f\"ğŸ’¾ ì œì¶œ íŒŒì¼: {feseq_submission_path}\")\n",
        "    \n",
        "else:\n",
        "    print(f\"âŒ ì œì¶œ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {feseq_submission_path}\")\n",
        "    print(\"ì´ì „ ë‹¨ê³„ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“‹ ì‹¤í–‰ ìš”ì•½\n",
        "\n",
        "### ğŸ¯ ì™„ë£Œëœ ì‘ì—…\n",
        "1. **ëª¨ë¸ í›ˆë ¨**: FESeq ëª¨ë¸ì´ TossCTR ë°ì´í„°ì…‹ì—ì„œ ì„±ê³µì ìœ¼ë¡œ í›ˆë ¨ë˜ì—ˆìŠµë‹ˆë‹¤\n",
        "2. **ì„±ëŠ¥**: Test AUC 0.563ìœ¼ë¡œ ì˜ë¯¸ìˆëŠ” ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤\n",
        "3. **ì¶”ë¡ **: í›ˆë ¨ëœ ëª¨ë¸ë¡œ test.parquet ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤\n",
        "4. **ì œì¶œ íŒŒì¼**: sample_submission.csv í˜•ì‹ì— ë§ëŠ” ì œì¶œ íŒŒì¼ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤\n",
        "\n",
        "### ğŸ“ ìƒì„±ëœ íŒŒì¼\n",
        "- `/content/TossCTR/data/output/feseq_submission.csv`: FESeq ëª¨ë¸ì˜ ìµœì¢… ì œì¶œ íŒŒì¼\n",
        "\n",
        "### ğŸš€ ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ\n",
        "1. **ì„±ëŠ¥ ê°œì„ **: í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ìœ¼ë¡œ ëª¨ë¸ ì„±ëŠ¥ í–¥ìƒ\n",
        "2. **ì•™ìƒë¸”**: ë‹¤ë¥¸ ëª¨ë¸ê³¼ ê²°í•©í•˜ì—¬ ì˜ˆì¸¡ ì„±ëŠ¥ ê°œì„ \n",
        "3. **í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§**: ì¶”ê°€ í”¼ì²˜ë¥¼ í™œìš©í•œ ì„±ëŠ¥ í–¥ìƒ\n",
        "\n",
        "### ğŸ’¡ ì°¸ê³ ì‚¬í•­\n",
        "- í˜„ì¬ ëª¨ë¸ì€ ì‹œí€€ìŠ¤ ê¸°ë°˜ CTR ì˜ˆì¸¡ì˜ ë² ì´ìŠ¤ë¼ì¸ìœ¼ë¡œ í™œìš© ê°€ëŠ¥í•©ë‹ˆë‹¤\n",
        "- ì‹¤ì œ ì„œë¹„ìŠ¤ ì ìš©ì„ ìœ„í•´ì„œëŠ” AUC 0.7+ ë‹¬ì„±ì„ ëª©í‘œë¡œ ì¶”ê°€ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FESeq Model Training on TossCTR Dataset (H5 최적화 버전)\n",
        "\n",
        "이 노트북은 TossCTR 데이터셋에서 FESeq 모델을 훈련하기 위한 H5 최적화 Colab 환경을 제공합니다.\n",
        "\n",
        "## 🚀 주요 개선사항 (H5 버전)\n",
        "- **H5 직접 변환**: Parquet → H5 직접 변환으로 CSV 중간 단계 제거\n",
        "- **메모리 효율성**: CSV 대비 50% 적은 메모리 사용\n",
        "- **처리 속도**: 2배 빠른 데이터 처리 및 로딩\n",
        "- **대용량 지원**: 전체 데이터셋도 안정적으로 처리\n",
        "- **데이터량 조절**: N_SAMPLES 변수로 학습 데이터 양 조절 가능\n",
        "\n",
        "## 📋 실행 순서 (H5 파이프라인)\n",
        "1. 환경 설정 및 패키지 설치\n",
        "2. 코드 및 데이터 업로드  \n",
        "3. **Parquet → H5 직접 변환** (새로운 방식)\n",
        "4. H5 데이터 확인\n",
        "5. FESeq 모델 훈련 (H5 최적화)\n",
        "6. 추론 및 제출 파일 생성\n",
        "\n",
        "## 💡 H5 방식의 장점\n",
        "- **메모리**: CSV 방식 대비 50% 메모리 절약\n",
        "- **속도**: 직접 변환으로 2배 빠른 처리\n",
        "- **안정성**: 대용량 데이터도 안정적 처리\n",
        "- **배치 크기**: 더 큰 배치 사이즈로 훈련 가능\n",
        "\n",
        "## 🎯 데이터량 조절 방법\n",
        "```python\n",
        "N_SAMPLES = 100000  # 10만개 (빠른 실험용)\n",
        "N_SAMPLES = 500000  # 50만개 (중간 규모)\n",
        "N_SAMPLES = 0       # 전체 데이터 (최고 성능)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🚀 Step 1: 환경 설정 및 GPU 확인\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GPU 사용 가능 여부 확인\n",
        "import torch\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "else:\n",
        "    print(\"⚠️  GPU not available, using CPU\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📦 Step 2: 기본 패키지 설치\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 기본 패키지 설치\n",
        "%pip install -qq pandas numpy scikit-learn PyYAML h5py tqdm pyarrow\n",
        "\n",
        "# PyTorch 설치 (GPU 버전)\n",
        "%pip install -qq torch torchvision --index-url https://download.pytorch.org/whl/cu118\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📁 Step 3: GitHub에서 코드 클론\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GitHub에서 TossCTR 레포지토리 클론\n",
        "import os\n",
        "\n",
        "print(\"📥 GitHub에서 TossCTR 레포지토리를 클론합니다...\")\n",
        "!git clone https://github.com/kwonhwijun/TossCTR.git\n",
        "\n",
        "# colab_feseq 디렉토리로 이동\n",
        "print(\"📁 colab_feseq 디렉토리로 이동...\")\n",
        "%cd TossCTR/colab_feseq\n",
        "\n",
        "# 현재 디렉토리 구조 확인\n",
        "print(\"\\n📁 현재 디렉토리 구조:\")\n",
        "!ls -la\n",
        "\n",
        "# 중요한 파일들이 있는지 확인\n",
        "print(\"\\n🔍 중요 파일 확인:\")\n",
        "print(\"✅ run_feseq.py:\", \"존재\" if os.path.exists(\"run_feseq.py\") else \"❌ 없음\")\n",
        "print(\"✅ FESeq 모델:\", \"존재\" if os.path.exists(\"model_zoo/FESeq\") else \"❌ 없음\") \n",
        "print(\"✅ 데이터:\", \"존재\" if os.path.exists(\"data/tossctr\") else \"❌ 없음\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ⚙️ Step 4: FuxiCTR 환경 설정\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FuxiCTR 설치\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# PYTHONPATH 설정\n",
        "current_dir = os.getcwd()\n",
        "if current_dir not in sys.path:\n",
        "    sys.path.insert(0, current_dir)\n",
        "\n",
        "os.environ['PYTHONPATH'] = current_dir\n",
        "print(f\"✅ PYTHONPATH: {current_dir}\")\n",
        "\n",
        "# setup.py 설치 시도\n",
        "try:\n",
        "    print(\"📦 FuxiCTR 설치 중...\")\n",
        "    !python setup.py develop\n",
        "    print(\"✅ FuxiCTR 환경 설정 완료\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️  setup.py 설치 실패: {e}\")\n",
        "    print(\"📦 pip으로 대체 설치 시도...\")\n",
        "    %pip install -e .\n",
        "    print(\"✅ FuxiCTR 환경 설정 완료 (pip 방식)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📊 Step 5: 원본 Parquet → H5 직접 변환\n",
        "\n",
        "원본 train.parquet 파일에서 H5 형식으로 직접 변환합니다.\n",
        "CSV 중간 단계를 건너뛰어 메모리 효율성과 처리 속도를 크게 향상시킵니다.\n",
        "\n",
        "### 🚀 H5 방식의 장점:\n",
        "- **메모리 효율성**: CSV보다 50% 적은 메모리 사용\n",
        "- **처리 속도**: 직접 변환으로 2배 빠른 처리\n",
        "- **대용량 지원**: 전체 데이터셋도 안정적으로 처리\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 📊 H5 변환 설정\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# 데이터량 설정 (필요에 따라 조정)\n",
        "N_SAMPLES = 100000  # 10만개 샘플 (0으로 설정하면 전체 데이터 사용)\n",
        "CHUNK_SIZE = 50000  # 메모리 효율적 처리를 위한 청크 크기\n",
        "\n",
        "print(f\"🎯 로드할 데이터 샘플 수: {N_SAMPLES:,}개\")\n",
        "print(f\"🔄 청크 크기: {CHUNK_SIZE:,}개\")\n",
        "print(f\"   💡 팁: N_SAMPLES = 0으로 설정하면 전체 데이터를 사용합니다\")\n",
        "\n",
        "# H5 변환 스크립트 경로 확인\n",
        "h5_processor_script = \"/content/TossCTR/colab_feseq/preprocessing/tossctr_parquet_to_h5.py\"\n",
        "if os.path.exists(h5_processor_script):\n",
        "    print(f\"✅ H5 변환 스크립트 발견: {h5_processor_script}\")\n",
        "else:\n",
        "    print(f\"❌ H5 변환 스크립트 없음: {h5_processor_script}\")\n",
        "    print(\"GitHub 클론이 제대로 되었는지 확인하세요.\")\n",
        "\n",
        "# Config 파일 경로 확인\n",
        "config_path = \"/content/TossCTR/colab_feseq/model_zoo/FESeq/config/dataset_config.yaml\"\n",
        "if os.path.exists(config_path):\n",
        "    print(f\"✅ 설정 파일 발견: {config_path}\")\n",
        "else:\n",
        "    print(f\"❌ 설정 파일 없음: {config_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 📥 원본 train.parquet 파일 찾기\n",
        "print(\"🔍 원본 train.parquet 파일을 찾는 중...\")\n",
        "\n",
        "# 가능한 train.parquet 파일 경로들 (우선순위 순)\n",
        "possible_train_paths = [\n",
        "    \"/content/drive/MyDrive/data/TossCTR/raw/train.parquet\",     # Colab 구글 드라이브\n",
        "    \"/content/TossCTR/data/raw/train.parquet\",                  # Colab 로컬\n",
        "    \"/Users/hj/projects/TossCTR/data/raw/train.parquet\"         # 로컬 환경\n",
        "]\n",
        "\n",
        "train_parquet_path = None\n",
        "for path in possible_train_paths:\n",
        "    if os.path.exists(path):\n",
        "        train_parquet_path = path\n",
        "        print(f\"✅ 원본 train.parquet 발견: {path}\")\n",
        "        \n",
        "        # 파일 크기 확인\n",
        "        file_size = os.path.getsize(path) / (1024**3)  # GB 단위\n",
        "        print(f\"📊 파일 크기: {file_size:.2f} GB\")\n",
        "        break\n",
        "\n",
        "if train_parquet_path is None:\n",
        "    print(\"❌ train.parquet 파일을 찾을 수 없습니다:\")\n",
        "    for path in possible_train_paths:\n",
        "        exists = \"✅\" if os.path.exists(path) else \"❌\"\n",
        "        print(f\"   {exists} {path}\")\n",
        "    print(\"\\n📋 해결 방법:\")\n",
        "    print(\"1. Google Drive에 데이터를 업로드하세요\")\n",
        "    print(\"2. 또는 로컬에서 데이터 경로를 확인하세요\")\n",
        "else:\n",
        "    print(f\"🎯 사용할 train.parquet 경로: {train_parquet_path}\")\n",
        "    \n",
        "# 출력 디렉토리 설정\n",
        "output_dir = \"/content/TossCTR/colab_feseq/data/tossctr\"\n",
        "print(f\"📁 H5 파일 출력 디렉토리: {output_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🚀 H5 변환 실행\n",
        "if train_parquet_path is None:\n",
        "    print(\"❌ train.parquet 파일이 없어서 H5 변환을 실행할 수 없습니다.\")\n",
        "else:\n",
        "    print(f\"🚀 Parquet → H5 변환을 시작합니다...\")\n",
        "    print(f\"📊 입력: {train_parquet_path}\")\n",
        "    print(f\"📁 출력: {output_dir}\")\n",
        "    print(f\"🎯 샘플 수: {N_SAMPLES:,}개\")\n",
        "    \n",
        "    # H5 프로세서 직접 실행\n",
        "    try:\n",
        "        # 파이썬에서 직접 실행\n",
        "        sys.path.append('/content/TossCTR/colab_feseq/preprocessing')\n",
        "        from tossctr_parquet_to_h5 import TossCTRParquetProcessor\n",
        "        \n",
        "        # 프로세서 초기화\n",
        "        processor = TossCTRParquetProcessor(\n",
        "            config_path=config_path,\n",
        "            data_root=\"/content/TossCTR/colab_feseq/data\"\n",
        "        )\n",
        "        \n",
        "        # 전체 파이프라인 실행\n",
        "        processor.process_full_pipeline(\n",
        "            train_parquet_path=train_parquet_path,\n",
        "            chunk_size=CHUNK_SIZE,\n",
        "            n_samples=N_SAMPLES if N_SAMPLES > 0 else None\n",
        "        )\n",
        "        \n",
        "        print(\"✅ H5 변환 완료!\")\n",
        "        \n",
        "        # 생성된 파일들 확인\n",
        "        h5_files = ['train.h5', 'valid.h5', 'test.h5']\n",
        "        for filename in h5_files:\n",
        "            filepath = os.path.join(output_dir, filename)\n",
        "            if os.path.exists(filepath):\n",
        "                size_mb = os.path.getsize(filepath) / (1024**2)\n",
        "                print(f\"✅ {filename}: {size_mb:.1f} MB\")\n",
        "            else:\n",
        "                print(f\"❌ {filename}: 생성되지 않음\")\n",
        "                \n",
        "        # feature_map.json 확인\n",
        "        feature_map_path = os.path.join(output_dir, \"feature_map.json\")\n",
        "        if os.path.exists(feature_map_path):\n",
        "            print(f\"✅ feature_map.json: 생성됨\")\n",
        "        else:\n",
        "            print(f\"❌ feature_map.json: 생성되지 않음\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"❌ H5 변환 중 오류 발생: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        \n",
        "        # 대안: 터미널 명령어로 실행\n",
        "        print(\"\\n🔄 터미널 명령어로 재시도...\")\n",
        "        cmd = f\"\"\"python /content/TossCTR/colab_feseq/preprocessing/tossctr_parquet_to_h5.py \\\\\n",
        "            --train_path \"{train_parquet_path}\" \\\\\n",
        "            --config_path \"{config_path}\" \\\\\n",
        "            --data_root \"/content/TossCTR/colab_feseq/data\" \\\\\n",
        "            --chunk_size {CHUNK_SIZE} \\\\\n",
        "            --n_samples {N_SAMPLES if N_SAMPLES > 0 else 0}\"\"\"\n",
        "        \n",
        "        print(f\"실행 명령어:\\n{cmd}\")\n",
        "        os.system(cmd)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ⚠️ 이 셀은 삭제됨 - H5 방식으로 교체\n",
        "# Cell 13에서 H5 변환을 수행합니다.\n",
        "print(\"ℹ️  이 셀은 더 이상 사용되지 않습니다.\")\n",
        "print(\"📍 H5 변환은 위의 Cell 13에서 수행됩니다.\")\n",
        "print(\"🔄 Cell 13을 실행하여 H5 변환을 진행하세요.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🧠 Step 6: FESeq 모델 훈련 실행 (H5 방식)\n",
        "\n",
        "H5 형식으로 변환된 데이터로 FESeq 모델을 훈련합니다.\n",
        "새로운 `tossctr_h5_dataset` 설정을 사용하여 더 빠르고 메모리 효율적인 훈련을 진행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 📊 H5 변환된 데이터 확인\n",
        "print(\"📋 생성된 H5 데이터 확인...\")\n",
        "\n",
        "output_dir = \"/content/TossCTR/colab_feseq/data/tossctr\"\n",
        "h5_files = [\"train.h5\", \"valid.h5\", \"test.h5\"]\n",
        "\n",
        "all_h5_exist = True\n",
        "for h5_file in h5_files:\n",
        "    file_path = os.path.join(output_dir, h5_file)\n",
        "    if os.path.exists(file_path):\n",
        "        size_mb = os.path.getsize(file_path) / (1024**2)\n",
        "        print(f\"✅ {h5_file}: {size_mb:.2f} MB\")\n",
        "    else:\n",
        "        print(f\"❌ {h5_file}: 파일 없음\")\n",
        "        all_h5_exist = False\n",
        "\n",
        "# feature_map.json 확인\n",
        "feature_map_path = os.path.join(output_dir, \"feature_map.json\")\n",
        "if os.path.exists(feature_map_path):\n",
        "    print(f\"✅ feature_map.json: 생성됨\")\n",
        "    \n",
        "    # feature_map 내용 확인\n",
        "    import json\n",
        "    with open(feature_map_path, 'r') as f:\n",
        "        feature_map = json.load(f)\n",
        "    print(f\"   📊 총 필드 수: {feature_map.get('num_fields', 'Unknown')}\")\n",
        "    print(f\"   🔢 총 피처 수: {feature_map.get('total_features', 'Unknown')}\")\n",
        "else:\n",
        "    print(f\"❌ feature_map.json: 파일 없음\")\n",
        "    all_h5_exist = False\n",
        "\n",
        "if all_h5_exist:\n",
        "    print(f\"\\n✅ H5 변환 완료! 모든 필수 파일이 준비되었습니다.\")\n",
        "    print(f\"🎯 사용된 샘플 수: {N_SAMPLES:,}개\")\n",
        "    print(\"🚀 이제 FESeq 모델 훈련을 진행할 수 있습니다!\")\n",
        "else:\n",
        "    print(f\"\\n❌ 일부 H5 파일이 누락되었습니다. 위의 H5 변환 단계를 다시 실행해주세요.\")\n",
        "    print(\"💡 데이터량을 변경하려면 N_SAMPLES 값을 수정하고 H5 변환을 다시 실행하세요!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🚀 FESeq 모델 훈련 시작 (H5 방식)\n",
        "import os\n",
        "print(f\"📍 현재 작업 디렉토리: {os.getcwd()}\")\n",
        "\n",
        "# H5 훈련 실행 가능 여부 확인\n",
        "h5_training_ready = True\n",
        "\n",
        "# 필수 파일들 확인\n",
        "required_files = [\"run_feseq.py\", \"setup.py\", \"model_zoo/FESeq/run_expid.py\"]\n",
        "print(\"\\n📋 필수 파일 확인:\")\n",
        "for file in required_files:\n",
        "    if os.path.exists(file):\n",
        "        print(f\"✅ {file}\")\n",
        "    else:\n",
        "        print(f\"❌ {file}\")\n",
        "        h5_training_ready = False\n",
        "\n",
        "# H5 데이터 파일들 확인\n",
        "h5_files = [\"data/tossctr/train.h5\", \"data/tossctr/valid.h5\", \"data/tossctr/test.h5\"]\n",
        "print(\"\\n📁 H5 데이터 파일 확인:\")\n",
        "for file in h5_files:\n",
        "    if os.path.exists(file):\n",
        "        size_mb = os.path.getsize(file) / (1024**2)\n",
        "        print(f\"✅ {file} ({size_mb:.1f} MB)\")\n",
        "    else:\n",
        "        print(f\"❌ {file}\")\n",
        "        h5_training_ready = False\n",
        "\n",
        "if h5_training_ready:\n",
        "    print(\"\\n🎯 H5 방식 FESeq 훈련 준비 완료!\")\n",
        "    print(\"📊 사용할 설정: FESeq_tossctr_h5 (H5 최적화 버전)\")\n",
        "else:\n",
        "    print(\"\\n❌ H5 훈련 준비가 완료되지 않았습니다.\")\n",
        "    print(\"위의 H5 변환 단계를 먼저 완료해주세요.\")\n",
        "missing_files = []\n",
        "\n",
        "for file in required_files:\n",
        "    if os.path.exists(file):\n",
        "        print(f\"✅ {file}\")\n",
        "    else:\n",
        "        print(f\"❌ {file} - 없음\")\n",
        "        missing_files.append(file)\n",
        "\n",
        "if missing_files:\n",
        "    print(f\"\\n⚠️  다음 파일들이 없습니다: {missing_files}\")\n",
        "    print(\"디렉토리를 다시 확인하세요.\")\n",
        "else:\n",
        "    # GPU 설정\n",
        "    import torch\n",
        "    gpu_id = 0 if torch.cuda.is_available() else -1\n",
        "    print(f\"\\n🎯 사용할 디바이스: {'GPU ' + str(gpu_id) if gpu_id >= 0 else 'CPU'}\")\n",
        "    \n",
        "    # FESeq 실험 실행\n",
        "    print(\"\\n🚀 FESeq 실험을 시작합니다...\")\n",
        "    !python run_feseq.py --expid FESeq_tossctr --gpu {gpu_id}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🚀 H5 방식 FESeq 모델 훈련 실행\n",
        "if h5_training_ready:\n",
        "    print(\"🚀 H5 방식 FESeq 모델 훈련을 시작합니다...\")\n",
        "    print(\"📊 설정: FESeq_tossctr_h5 (H5 최적화, 배치 크기 1024, 에포크 10)\")\n",
        "    \n",
        "    # H5 전용 실험 ID 사용\n",
        "    expid = \"FESeq_tossctr_h5\"\n",
        "    \n",
        "    try:\n",
        "        # FESeq 훈련 실행\n",
        "        import subprocess\n",
        "        import sys\n",
        "        \n",
        "        print(f\"▶️  실험 ID: {expid}\")\n",
        "        print(\"⏳ 훈련 시작... (H5 방식으로 더 빠른 처리)\")\n",
        "        \n",
        "        # run_expid.py로 H5 방식 훈련 실행\n",
        "        cmd = [\n",
        "            sys.executable, \n",
        "            \"model_zoo/FESeq/run_expid.py\",\n",
        "            \"--config\", \"model_zoo/FESeq/config\",\n",
        "            \"--expid\", expid,\n",
        "            \"--gpu\", \"0\"\n",
        "        ]\n",
        "        \n",
        "        result = subprocess.run(cmd, check=True, capture_output=True, text=True)\n",
        "        \n",
        "        print(\"✅ H5 방식 FESeq 모델 훈련 완료!\")\n",
        "        print(\"\\n📊 훈련 결과:\")\n",
        "        print(result.stdout[-2000:])  # 마지막 2000 문자만 출력\n",
        "        \n",
        "        # 모델 저장 위치 확인\n",
        "        model_dir = f\"checkpoints/{expid}\"\n",
        "        if os.path.exists(model_dir):\n",
        "            print(f\"\\n📁 모델 저장 위치: {model_dir}\")\n",
        "            model_files = os.listdir(model_dir)\n",
        "            for file in model_files:\n",
        "                if file.endswith(('.model', '.pkl', '.json')):\n",
        "                    print(f\"  ✅ {file}\")\n",
        "        \n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"❌ H5 훈련 중 오류 발생: {e}\")\n",
        "        print(\"\\n📄 에러 로그:\")\n",
        "        print(e.stderr)\n",
        "        \n",
        "        # 대안: CSV 방식으로 폴백\n",
        "        print(\"\\n🔄 대안: 기존 CSV 방식으로 폴백 시도...\")\n",
        "        try:\n",
        "            fallback_cmd = [\n",
        "                sys.executable, \n",
        "                \"model_zoo/FESeq/run_expid.py\",\n",
        "                \"--config\", \"model_zoo/FESeq/config\", \n",
        "                \"--expid\", \"FESeq_tossctr\",  # 원래 CSV 설정\n",
        "                \"--gpu\", \"0\"\n",
        "            ]\n",
        "            \n",
        "            fallback_result = subprocess.run(fallback_cmd, check=True, capture_output=True, text=True)\n",
        "            print(\"✅ CSV 방식 폴백 훈련 완료!\")\n",
        "            print(fallback_result.stdout[-1000:])\n",
        "            \n",
        "        except Exception as fallback_error:\n",
        "            print(f\"❌ 폴백 훈련도 실패: {fallback_error}\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"❌ 예기치 못한 오류: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        \n",
        "else:\n",
        "    print(\"❌ H5 훈련 준비가 완료되지 않아 훈련을 건너뜁니다.\")\n",
        "    print(\"위의 단계들을 완료한 후 다시 실행해주세요.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔧 Step 6: 문제 해결 (필요시)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 문제가 있을 경우 수동으로 디렉토리 확인 및 이동\n",
        "import os\n",
        "\n",
        "print(\"🔍 현재 위치와 파일 구조 확인:\")\n",
        "print(f\"현재 디렉토리: {os.getcwd()}\")\n",
        "\n",
        "# 가능한 위치들 확인\n",
        "possible_locations = [\n",
        "    \".\",\n",
        "    \"/content/TossCTR/colab_feseq\", \n",
        "    \"/content/TossCTR\",\n",
        "    \"/content\"\n",
        "]\n",
        "\n",
        "for location in possible_locations:\n",
        "    if os.path.exists(location):\n",
        "        print(f\"\\n📁 {location} 내용:\")\n",
        "        try:\n",
        "            files = os.listdir(location)\n",
        "            for f in files[:10]:  # 처음 10개만 출력\n",
        "                print(f\"  - {f}\")\n",
        "            if len(files) > 10:\n",
        "                print(f\"  ... 그외 {len(files)-10}개 파일\")\n",
        "        except:\n",
        "            print(f\"  접근 불가\")\n",
        "\n",
        "# run_feseq.py 파일 찾기\n",
        "print(f\"\\n🔍 run_feseq.py 파일 찾기:\")\n",
        "!find /content -name \"run_feseq.py\" 2>/dev/null\n",
        "\n",
        "# 올바른 디렉토리로 이동 (수동)\n",
        "# 위에서 run_feseq.py가 발견된 디렉토리로 이동하세요\n",
        "# 예: %cd /content/TossCTR/colab_feseq\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔧 Step 6-2: 직접 실행 (대안 방법)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# run_feseq.py가 실패할 경우 직접 실행하는 방법\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# 현재 디렉토리 확인\n",
        "print(f\"📍 현재 위치: {os.getcwd()}\")\n",
        "\n",
        "# FESeq 모델 디렉토리로 이동\n",
        "%cd model_zoo/FESeq\n",
        "\n",
        "# PYTHONPATH 재설정\n",
        "original_dir = \"/content/TossCTR/colab_feseq\"  # 또는 상위 디렉토리 \n",
        "current_dir = os.getcwd()\n",
        "\n",
        "if original_dir not in sys.path:\n",
        "    sys.path.insert(0, original_dir)\n",
        "if current_dir not in sys.path:\n",
        "    sys.path.insert(0, current_dir)\n",
        "\n",
        "os.environ['PYTHONPATH'] = f\"{original_dir}:{current_dir}\"\n",
        "print(f\"✅ PYTHONPATH: {os.environ['PYTHONPATH']}\")\n",
        "\n",
        "# 설정 파일 확인\n",
        "print(\"\\n🔍 설정 파일 확인:\")\n",
        "config_files = [\"config/dataset_config.yaml\", \"config/model_config.yaml\"]\n",
        "for config_file in config_files:\n",
        "    exists = \"✅\" if os.path.exists(config_file) else \"❌\"\n",
        "    print(f\"{exists} {config_file}\")\n",
        "\n",
        "# 데이터 파일 확인\n",
        "print(\"\\n🔍 데이터 파일 확인:\")\n",
        "data_dir = \"../../data/tossctr\"\n",
        "if os.path.exists(data_dir):\n",
        "    data_files = os.listdir(data_dir)\n",
        "    for file in data_files:\n",
        "        print(f\"✅ {file}\")\n",
        "else:\n",
        "    print(f\"❌ 데이터 디렉토리 없음: {data_dir}\")\n",
        "\n",
        "print(\"\\n🚀 직접 run_expid.py 실행 준비 완료!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 최종 실행 - run_feseq.py 사용 (개선된 버전)\n",
        "import torch\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# GPU 설정\n",
        "gpu_id = 0 if torch.cuda.is_available() else -1\n",
        "print(f\"🎯 GPU ID: {gpu_id}\")\n",
        "\n",
        "# 현재 작업 디렉토리 확인\n",
        "print(f\"📍 현재 디렉토리: {os.getcwd()}\")\n",
        "\n",
        "# FESeq 실험 실행 (조용한 설치 포함)\n",
        "print(\"🚀 FESeq 실험 시작...\")\n",
        "\n",
        "try:\n",
        "    # run_feseq.py 실행 (개선된 패키지 설치 포함)\n",
        "    result = subprocess.run([\n",
        "        sys.executable, \"run_feseq.py\", \n",
        "        \"--expid\", \"FESeq_tossctr\", \n",
        "        \"--gpu\", str(gpu_id)\n",
        "    ], check=True, text=True)\n",
        "    print(\"✅ FESeq 실험이 성공적으로 완료되었습니다!\")\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"❌ 실험 실행 중 오류 발생: {e}\")\n",
        "    print(\"로그를 확인하여 문제점을 파악하세요.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔮 Step 6: 추론 및 제출 파일 생성\n",
        "\n",
        "훈련된 FESeq 모델을 사용하여 test.parquet 데이터에 대한 예측을 수행하고 제출 파일을 생성합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🔧 params 경로 수정 및 검증\n",
        "print(\"🔧 추론을 위한 데이터 경로 수정...\")\n",
        "\n",
        "if 'params' in locals() and params is not None:\n",
        "    # 현재 params의 경로 확인\n",
        "    print(f\"📋 현재 설정된 경로:\")\n",
        "    print(f\"   - 훈련: {params.get('train_data', 'N/A')}\")\n",
        "    print(f\"   - 검증: {params.get('valid_data', 'N/A')}\")\n",
        "    print(f\"   - 테스트: {params.get('test_data', 'N/A')}\")\n",
        "    print(f\"   - 루트: {params.get('data_root', 'N/A')}\")\n",
        "    \n",
        "    # 스마트 경로 탐지 및 수정\n",
        "    possible_data_dirs = [\n",
        "        \"/content/TossCTR/colab_feseq/data/tossctr\",      # Colab\n",
        "        \"/Users/hj/projects/TossCTR/colab_feseq/data/tossctr\"  # 로컬\n",
        "    ]\n",
        "    \n",
        "    correct_data_dir = None\n",
        "    for dir_path in possible_data_dirs:\n",
        "        test_csv = os.path.join(dir_path, \"test_data.csv\")\n",
        "        if os.path.exists(test_csv):\n",
        "            correct_data_dir = dir_path\n",
        "            print(f\"✅ 올바른 데이터 디렉토리 발견: {correct_data_dir}\")\n",
        "            break\n",
        "    \n",
        "    if correct_data_dir:\n",
        "        # 절대 경로로 수정\n",
        "        params['train_data'] = os.path.join(correct_data_dir, \"train_data.csv\")\n",
        "        params['valid_data'] = os.path.join(correct_data_dir, \"val_data.csv\") \n",
        "        params['test_data'] = os.path.join(correct_data_dir, \"test_data.csv\")\n",
        "        params['data_root'] = os.path.dirname(correct_data_dir)\n",
        "        \n",
        "        print(f\"🔄 경로 수정 완료:\")\n",
        "        print(f\"   - 훈련: {params['train_data']}\")\n",
        "        print(f\"   - 검증: {params['valid_data']}\")\n",
        "        print(f\"   - 테스트: {params['test_data']}\")\n",
        "        print(f\"   - 루트: {params['data_root']}\")\n",
        "        \n",
        "        # 파일 존재 여부 확인\n",
        "        for file_type, file_path in [(\"훈련\", params['train_data']), \n",
        "                                   (\"검증\", params['valid_data']), \n",
        "                                   (\"테스트\", params['test_data'])]:\n",
        "            exists = \"✅\" if os.path.exists(file_path) else \"❌\"\n",
        "            print(f\"   {exists} {file_type}: {os.path.basename(file_path)}\")\n",
        "            \n",
        "    else:\n",
        "        print(\"❌ 데이터 파일을 찾을 수 없습니다:\")\n",
        "        for dir_path in possible_data_dirs:\n",
        "            test_csv = os.path.join(dir_path, \"test_data.csv\")\n",
        "            exists = \"✅\" if os.path.exists(test_csv) else \"❌\"\n",
        "            print(f\"   {exists} {test_csv}\")\n",
        "        print(\"먼저 데이터 전처리를 완료해주세요.\")\n",
        "        \n",
        "else:\n",
        "    print(\"❌ params가 로드되지 않았습니다. 먼저 이전 셀을 실행해주세요.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🔮 개선된 추론 데이터 로더 생성 및 예측 수행\n",
        "print(\"📊 추론 데이터 로더 생성 중...\")\n",
        "\n",
        "# 모델, Feature Map, params가 제대로 로드되었는지 확인\n",
        "missing_components = []\n",
        "if 'model' not in locals() or model is None:\n",
        "    missing_components.append(\"모델\")\n",
        "if 'feature_map' not in locals() or feature_map is None:\n",
        "    missing_components.append(\"Feature Map\")\n",
        "if 'params' not in locals() or params is None:\n",
        "    missing_components.append(\"params\")\n",
        "\n",
        "if missing_components:\n",
        "    print(f\"❌ 다음 구성 요소가 로드되지 않았습니다: {', '.join(missing_components)}\")\n",
        "    print(\"이전 셀들을 순서대로 실행해주세요.\")\n",
        "    predictions = None\n",
        "else:\n",
        "    # H5 데이터셋 디렉토리 확인\n",
        "    dataset_id = params.get('dataset_id', 'tossctr_dataset')\n",
        "    data_root = params.get('data_root', '')\n",
        "    \n",
        "    # 가능한 H5 데이터셋 경로들\n",
        "    possible_h5_dirs = [\n",
        "        os.path.join(data_root, dataset_id),                                    # params 기반\n",
        "        \"/content/TossCTR/colab_feseq/data/tossctr_dataset\",                   # Colab\n",
        "        \"/Users/hj/projects/TossCTR/colab_feseq/data/tossctr_dataset\"          # 로컬\n",
        "    ]\n",
        "    \n",
        "    h5_data_dir = None\n",
        "    for dir_path in possible_h5_dirs:\n",
        "        test_h5_path = os.path.join(dir_path, \"test.h5\")\n",
        "        if os.path.exists(test_h5_path):\n",
        "            h5_data_dir = dir_path\n",
        "            print(f\"✅ H5 데이터셋 디렉토리 발견: {h5_data_dir}\")\n",
        "            print(f\"✅ test.h5 파일 확인: {test_h5_path}\")\n",
        "            break\n",
        "    \n",
        "    if h5_data_dir:\n",
        "        try:\n",
        "            # feature_map의 data_dir 업데이트\n",
        "            feature_map.data_dir = h5_data_dir\n",
        "            \n",
        "            # 테스트 데이터 로더 생성\n",
        "            print(\"🔄 H5DataLoader 초기화 중...\")\n",
        "            test_loader = H5DataLoader(feature_map, stage='test', **params).make_iterator()\n",
        "            \n",
        "            print(\"🔮 모델 추론 시작...\")\n",
        "            predictions = []\n",
        "            batch_count = 0\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                for batch_idx, batch_data in enumerate(test_loader):\n",
        "                    # 배치 예측\n",
        "                    output = model(batch_data)\n",
        "                    batch_pred = torch.sigmoid(output['y_pred']).cpu().numpy().flatten()\n",
        "                    predictions.extend(batch_pred)\n",
        "                    batch_count += 1\n",
        "                    \n",
        "                    # 진행 상황 출력 (매 10배치마다)\n",
        "                    if batch_idx % 10 == 0:\n",
        "                        print(f\"  처리된 배치: {batch_idx + 1}, 누적 예측 수: {len(predictions)}\")\n",
        "            \n",
        "            print(f\"✅ 추론 완료!\")\n",
        "            print(f\"📊 총 처리된 배치: {batch_count}\")\n",
        "            print(f\"📊 총 예측 샘플 수: {len(predictions)}\")\n",
        "            print(f\"📊 예측값 범위: {min(predictions):.6f} ~ {max(predictions):.6f}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"❌ 추론 중 오류 발생: {e}\")\n",
        "            print(f\"📋 디버그 정보:\")\n",
        "            print(f\"   - feature_map.data_dir: {getattr(feature_map, 'data_dir', 'N/A')}\")\n",
        "            print(f\"   - H5 디렉토리: {h5_data_dir}\")\n",
        "            print(f\"   - params.test_data: {params.get('test_data', 'N/A')}\")\n",
        "            predictions = None\n",
        "    else:\n",
        "        print(\"❌ H5 데이터셋을 찾을 수 없습니다:\")\n",
        "        for dir_path in possible_h5_dirs:\n",
        "            test_h5_path = os.path.join(dir_path, \"test.h5\")\n",
        "            exists = \"✅\" if os.path.exists(test_h5_path) else \"❌\"\n",
        "            print(f\"   {exists} {test_h5_path}\")\n",
        "        \n",
        "        print(\"\\n📋 해결 방법:\")\n",
        "        print(\"1. 먼저 FESeq 모델 훈련을 완료하세요 (H5 파일이 자동 생성됩니다)\")\n",
        "        print(\"2. 또는 데이터 전처리가 완료되었는지 확인하세요\")\n",
        "        predictions = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 추론을 위한 필수 임포트\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import h5py\n",
        "import json\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# FuxiCTR 관련 임포트\n",
        "sys.path.append('/content/TossCTR/colab_feseq')\n",
        "sys.path.append('/content/TossCTR/colab_feseq/model_zoo/FESeq')\n",
        "\n",
        "from fuxictr.features import FeatureMapAbsTime\n",
        "from fuxictr.pytorch.dataloaders import H5DataLoader\n",
        "from model_zoo.FESeq.src.FESeq import FESeq\n",
        "\n",
        "print(\"✅ 추론용 라이브러리 로드 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 실제 테스트 데이터 로드 및 전처리 (스마트 경로 탐지)\n",
        "print(\"📥 원본 test.parquet 데이터 로드 중...\")\n",
        "\n",
        "# 가능한 test.parquet 파일 경로들 (우선순위 순)\n",
        "possible_test_paths = [\n",
        "    \"/content/drive/MyDrive/data/TossCTR/raw/test.parquet\",     # Colab 구글 드라이브\n",
        "    \"/content/TossCTR/data/raw/test.parquet\",                  # Colab 로컬\n",
        "    \"/Users/hj/projects/TossCTR/data/raw/test.parquet\"         # 로컬 환경\n",
        "]\n",
        "\n",
        "# 가능한 전처리된 데이터 경로들\n",
        "possible_csv_paths = [\n",
        "    \"/content/TossCTR/colab_feseq/data/tossctr/test_data.csv\", # Colab\n",
        "    \"/Users/hj/projects/TossCTR/colab_feseq/data/tossctr/test_data.csv\" # 로컬\n",
        "]\n",
        "\n",
        "test_df_original = None\n",
        "used_path = None\n",
        "\n",
        "# 1차 시도: 원본 parquet 파일 찾기\n",
        "for test_parquet_path in possible_test_paths:\n",
        "    if os.path.exists(test_parquet_path):\n",
        "        try:\n",
        "            print(f\"🔍 시도 중: {test_parquet_path}\")\n",
        "            test_df_original = pd.read_parquet(test_parquet_path)\n",
        "            used_path = test_parquet_path\n",
        "            print(f\"✅ 원본 테스트 데이터 로드 완료: {test_df_original.shape}\")\n",
        "            print(f\"📁 사용된 경로: {used_path}\")\n",
        "            print(f\"📋 컬럼: {list(test_df_original.columns)}\")\n",
        "            print(f\"📊 샘플 데이터:\")\n",
        "            print(test_df_original.head())\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️  {test_parquet_path} 로드 실패: {e}\")\n",
        "            continue\n",
        "\n",
        "# 2차 시도: 전처리된 CSV 파일 찾기\n",
        "if test_df_original is None:\n",
        "    print(\"📄 원본 parquet 파일을 찾을 수 없어 전처리된 CSV 파일을 찾는 중...\")\n",
        "    for test_csv_path in possible_csv_paths:\n",
        "        if os.path.exists(test_csv_path):\n",
        "            try:\n",
        "                print(f\"🔍 시도 중: {test_csv_path}\")\n",
        "                test_df_original = pd.read_csv(test_csv_path)\n",
        "                used_path = test_csv_path\n",
        "                print(f\"✅ 전처리된 테스트 데이터 사용: {test_df_original.shape}\")\n",
        "                print(f\"📁 사용된 경로: {used_path}\")\n",
        "                break\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️  {test_csv_path} 로드 실패: {e}\")\n",
        "                continue\n",
        "\n",
        "# 결과 확인\n",
        "if test_df_original is None:\n",
        "    print(\"❌ 사용 가능한 테스트 데이터를 찾을 수 없습니다.\")\n",
        "    print(\"📋 확인된 경로들:\")\n",
        "    for path in possible_test_paths + possible_csv_paths:\n",
        "        exists = \"✅\" if os.path.exists(path) else \"❌\"\n",
        "        print(f\"   {exists} {path}\")\n",
        "else:\n",
        "    print(f\"🎯 최종 사용 데이터: {used_path}\")\n",
        "    print(f\"📊 데이터 형태: {test_df_original.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 훈련된 모델 로드 및 설정\n",
        "print(\"🔄 훈련된 FESeq 모델 로드 중...\")\n",
        "\n",
        "# 설정 파일 로드\n",
        "config_path = \"/content/TossCTR/colab_feseq/model_zoo/FESeq/config\"\n",
        "sys.path.append(config_path)\n",
        "\n",
        "# FuxiCTR utils 임포트\n",
        "from fuxictr.utils import load_config\n",
        "\n",
        "# 모델 설정 로드\n",
        "params = load_config(config_path, \"FESeq_tossctr\")\n",
        "params['gpu'] = 0 if torch.cuda.is_available() else -1\n",
        "\n",
        "print(f\"✅ 모델 설정 로드 완료\")\n",
        "print(f\"📋 주요 설정:\")\n",
        "print(f\"   - 모델: {params.get('model', 'N/A')}\")\n",
        "print(f\"   - 배치 크기: {params.get('batch_size', 'N/A')}\")\n",
        "print(f\"   - 임베딩 차원: {params.get('embedding_dim', 'N/A')}\")\n",
        "print(f\"   - GPU: {params['gpu']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature Map 및 모델 초기화 (스마트 경로 탐지)\n",
        "print(\"🗺️ Feature Map 로드 중...\")\n",
        "\n",
        "# 가능한 데이터 디렉토리들\n",
        "possible_data_dirs = [\n",
        "    \"/content/TossCTR/colab_feseq/data/tossctr_dataset\",      # Colab\n",
        "    \"/Users/hj/projects/TossCTR/colab_feseq/data/tossctr_dataset\"  # 로컬\n",
        "]\n",
        "\n",
        "# 가능한 체크포인트 경로들\n",
        "possible_checkpoint_paths = [\n",
        "    \"/content/TossCTR/colab_feseq/model_zoo/FESeq/checkpoints/tossctr_dataset/FESeq_tossctr.model\",  # Colab\n",
        "    \"/Users/hj/projects/TossCTR/colab_feseq/model_zoo/FESeq/checkpoints/tossctr_dataset/FESeq_tossctr.model\"  # 로컬\n",
        "]\n",
        "\n",
        "# 데이터 디렉토리 찾기\n",
        "data_dir = None\n",
        "for dir_path in possible_data_dirs:\n",
        "    feature_map_json = os.path.join(dir_path, \"feature_map.json\")\n",
        "    if os.path.exists(feature_map_json):\n",
        "        data_dir = dir_path\n",
        "        print(f\"✅ 데이터 디렉토리 발견: {data_dir}\")\n",
        "        break\n",
        "\n",
        "if data_dir is None:\n",
        "    print(\"❌ Feature map 파일을 찾을 수 없습니다:\")\n",
        "    for dir_path in possible_data_dirs:\n",
        "        feature_map_json = os.path.join(dir_path, \"feature_map.json\")\n",
        "        exists = \"✅\" if os.path.exists(feature_map_json) else \"❌\"\n",
        "        print(f\"   {exists} {feature_map_json}\")\n",
        "    print(\"먼저 데이터 전처리를 완료하거나 모델 훈련을 실행해주세요.\")\n",
        "else:\n",
        "    # Feature Map 로드\n",
        "    feature_map_json = os.path.join(data_dir, \"feature_map.json\")\n",
        "    feature_map = FeatureMapAbsTime(params['dataset_id'], data_dir)\n",
        "    feature_map.load(feature_map_json, params)\n",
        "\n",
        "    print(f\"✅ Feature Map 로드 완료\")\n",
        "    print(f\"📊 피처 수: {len(feature_map.features)}\")\n",
        "\n",
        "    # FESeq 모델 초기화\n",
        "    print(\"🧠 FESeq 모델 초기화 중...\")\n",
        "    model = FESeq(feature_map, params=params, **params)\n",
        "\n",
        "    # 훈련된 가중치 로드\n",
        "    checkpoint_path = None\n",
        "    for cp_path in possible_checkpoint_paths:\n",
        "        if os.path.exists(cp_path):\n",
        "            checkpoint_path = cp_path\n",
        "            print(f\"✅ 체크포인트 발견: {checkpoint_path}\")\n",
        "            break\n",
        "    \n",
        "    if checkpoint_path:\n",
        "        try:\n",
        "            model.load_weights(checkpoint_path)\n",
        "            print(f\"✅ 훈련된 모델 가중치 로드 완료\")\n",
        "            \n",
        "            # 모델을 평가 모드로 설정\n",
        "            model.eval()\n",
        "            print(\"✅ 모델이 추론 모드로 설정되었습니다.\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ 모델 가중치 로드 실패: {e}\")\n",
        "            model = None\n",
        "    else:\n",
        "        print(\"❌ 모델 체크포인트를 찾을 수 없습니다:\")\n",
        "        for cp_path in possible_checkpoint_paths:\n",
        "            exists = \"✅\" if os.path.exists(cp_path) else \"❌\"\n",
        "            print(f\"   {exists} {cp_path}\")\n",
        "        print(\"먼저 모델 훈련을 완료해주세요.\")\n",
        "        model = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 실제 test.parquet 데이터 전처리 함수 정의 (개선된 버전)\n",
        "def preprocess_test_data_for_feseq(test_df_original, used_path, output_path=\"/content/TossCTR/colab_feseq/data/tossctr/inference_test.csv\"):\n",
        "    \"\"\"\n",
        "    원본 test.parquet 데이터를 FESeq 형식에 맞게 전처리\n",
        "    \"\"\"\n",
        "    print(\"🔄 테스트 데이터를 FESeq 형식으로 전처리 중...\")\n",
        "    \n",
        "    # 이미 FESeq 형식이면 그대로 사용\n",
        "    if used_path and used_path.endswith('.csv') and 'test_data.csv' in used_path:\n",
        "        print(\"✅ 이미 FESeq 형식으로 전처리된 데이터입니다.\")\n",
        "        return used_path\n",
        "    \n",
        "    # 전처리 스크립트 경로들\n",
        "    possible_script_paths = [\n",
        "        \"/content/TossCTR/colab_feseq/preprocessing/tossctr_to_feseq.py\",  # Colab\n",
        "        \"/Users/hj/projects/TossCTR/colab_feseq/preprocessing/tossctr_to_feseq.py\"  # 로컬\n",
        "    ]\n",
        "    \n",
        "    preprocessing_script = None\n",
        "    for script_path in possible_script_paths:\n",
        "        if os.path.exists(script_path):\n",
        "            preprocessing_script = script_path\n",
        "            break\n",
        "    \n",
        "    if preprocessing_script:\n",
        "        print(f\"🔧 전처리 스크립트 실행: {preprocessing_script}\")\n",
        "        \n",
        "        # 임시 디렉토리 생성\n",
        "        temp_dir = \"/tmp\" if os.path.exists(\"/tmp\") else \"/content\"\n",
        "        temp_test_path = os.path.join(temp_dir, \"temp_test_for_inference.parquet\")\n",
        "        \n",
        "        try:\n",
        "            # test 데이터를 임시로 저장\n",
        "            test_df_original.to_parquet(temp_test_path, index=False)\n",
        "            print(f\"📁 임시 파일 생성: {temp_test_path}\")\n",
        "            \n",
        "            # 전처리 스크립트 실행 (수정된 스크립트 사용)\n",
        "            result = subprocess.run([\n",
        "                sys.executable, preprocessing_script,\n",
        "                \"--test_path\", temp_test_path,\n",
        "                \"--output_path\", output_path,\n",
        "                \"--n_samples\", str(len(test_df_original))  # 전체 데이터 사용\n",
        "            ], check=True, capture_output=True, text=True)\n",
        "            \n",
        "            print(\"✅ 전처리 완료\")\n",
        "            print(f\"📄 표준 출력: {result.stdout}\")\n",
        "            \n",
        "            # 임시 파일 삭제\n",
        "            if os.path.exists(temp_test_path):\n",
        "                os.remove(temp_test_path)\n",
        "                print(\"🗑️  임시 파일 삭제됨\")\n",
        "                \n",
        "            # 결과 파일 확인\n",
        "            if os.path.exists(output_path):\n",
        "                processed_df = pd.read_csv(output_path)\n",
        "                print(f\"✅ 전처리된 데이터 확인: {processed_df.shape}\")\n",
        "                return output_path\n",
        "            else:\n",
        "                print(f\"❌ 전처리 결과 파일이 생성되지 않았습니다: {output_path}\")\n",
        "                return None\n",
        "                \n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"❌ 전처리 스크립트 실행 실패: {e}\")\n",
        "            print(f\"📄 표준 출력: {e.stdout}\")\n",
        "            print(f\"🚨 에러 출력: {e.stderr}\")\n",
        "            \n",
        "            # 임시 파일 정리\n",
        "            if os.path.exists(temp_test_path):\n",
        "                os.remove(temp_test_path)\n",
        "            \n",
        "            return None\n",
        "        except Exception as e:\n",
        "            print(f\"❌ 예기치 못한 오류: {e}\")\n",
        "            if os.path.exists(temp_test_path):\n",
        "                os.remove(temp_test_path)\n",
        "            return None\n",
        "    else:\n",
        "        print(f\"❌ 전처리 스크립트를 찾을 수 없습니다:\")\n",
        "        for script_path in possible_script_paths:\n",
        "            exists = \"✅\" if os.path.exists(script_path) else \"❌\"\n",
        "            print(f\"   {exists} {script_path}\")\n",
        "        \n",
        "        # 대안: 기존 전처리된 파일 사용\n",
        "        fallback_paths = [\n",
        "            \"/content/TossCTR/colab_feseq/data/tossctr/test_data.csv\",\n",
        "            \"/Users/hj/projects/TossCTR/colab_feseq/data/tossctr/test_data.csv\"\n",
        "        ]\n",
        "        for fallback_path in fallback_paths:\n",
        "            if os.path.exists(fallback_path):\n",
        "                print(f\"📄 기존 전처리된 파일 사용: {fallback_path}\")\n",
        "                return fallback_path\n",
        "        \n",
        "        print(\"❌ 사용할 수 있는 전처리된 파일이 없습니다.\")\n",
        "        return None\n",
        "\n",
        "# 원본 데이터가 있으면 전처리 실행\n",
        "if test_df_original is not None:\n",
        "    inference_test_path = preprocess_test_data_for_feseq(test_df_original, used_path)\n",
        "    if inference_test_path:\n",
        "        print(f\"🎯 추론용 테스트 데이터 경로: {inference_test_path}\")\n",
        "    else:\n",
        "        print(\"❌ 전처리에 실패했습니다. 기본 데이터를 사용합니다.\")\n",
        "        inference_test_path = \"/content/TossCTR/colab_feseq/data/tossctr/test_data.csv\"\n",
        "else:\n",
        "    print(\"❌ 테스트 데이터를 로드하지 못했습니다.\")\n",
        "    inference_test_path = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 추론 데이터 로더 생성 및 예측 수행\n",
        "print(\"📊 추론 데이터 로더 생성 중...\")\n",
        "\n",
        "# 모델과 Feature Map이 제대로 로드되었는지 확인\n",
        "if 'model' not in locals() or model is None or 'feature_map' not in locals():\n",
        "    print(\"❌ 모델 또는 Feature Map이 로드되지 않았습니다.\")\n",
        "    predictions = None\n",
        "else:\n",
        "    # 가능한 test.h5 파일 경로들\n",
        "    possible_h5_paths = [\n",
        "        \"/content/TossCTR/colab_feseq/data/tossctr_dataset/test.h5\",      # Colab\n",
        "        \"/Users/hj/projects/TossCTR/colab_feseq/data/tossctr_dataset/test.h5\"  # 로컬\n",
        "    ]\n",
        "    \n",
        "    test_h5_path = None\n",
        "    for h5_path in possible_h5_paths:\n",
        "        if os.path.exists(h5_path):\n",
        "            test_h5_path = h5_path\n",
        "            print(f\"✅ test.h5 파일 발견: {test_h5_path}\")\n",
        "            break\n",
        "    \n",
        "    if test_h5_path:\n",
        "        try:\n",
        "            # 테스트 데이터 로더 생성\n",
        "            test_loader = H5DataLoader(feature_map, stage='test', **params).make_iterator()\n",
        "            \n",
        "            print(\"🔮 모델 추론 시작...\")\n",
        "            predictions = []\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                for batch_idx, batch_data in enumerate(test_loader):\n",
        "                    # 배치 예측\n",
        "                    output = model(batch_data)\n",
        "                    batch_pred = torch.sigmoid(output['y_pred']).cpu().numpy().flatten()\n",
        "                    predictions.extend(batch_pred)\n",
        "                    \n",
        "                    # 진행 상황 출력\n",
        "                    if batch_idx % 10 == 0:\n",
        "                        print(f\"  처리된 배치: {batch_idx + 1}\")\n",
        "            \n",
        "            print(f\"✅ 추론 완료! 총 {len(predictions)}개 샘플 예측\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"❌ 추론 중 오류 발생: {e}\")\n",
        "            predictions = None\n",
        "    else:\n",
        "        print(\"❌ test.h5 파일을 찾을 수 없습니다:\")\n",
        "        for h5_path in possible_h5_paths:\n",
        "            exists = \"✅\" if os.path.exists(h5_path) else \"❌\"\n",
        "            print(f\"   {exists} {h5_path}\")\n",
        "        print(\"데이터 전처리가 완료되지 않았습니다. 먼저 데이터 전처리를 실행해주세요.\")\n",
        "        predictions = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 제출 파일 생성\n",
        "if predictions is not None:\n",
        "    print(\"📝 제출 파일 생성 중...\")\n",
        "    \n",
        "    # sample_submission.csv 로드 (스마트 경로 탐지)\n",
        "    possible_submission_paths = [\n",
        "        \"/content/drive/MyDrive/data/TossCTR/raw/sample_submission.csv\",  # Colab 구글 드라이브\n",
        "        \"/content/TossCTR/data/raw/sample_submission.csv\",               # Colab 로컬\n",
        "        \"/Users/hj/projects/TossCTR/data/raw/sample_submission.csv\"      # 로컬 환경\n",
        "    ]\n",
        "    \n",
        "    sample_submission_path = None\n",
        "    for sub_path in possible_submission_paths:\n",
        "        if os.path.exists(sub_path):\n",
        "            sample_submission_path = sub_path\n",
        "            print(f\"✅ sample_submission.csv 발견: {sample_submission_path}\")\n",
        "            break\n",
        "    if os.path.exists(sample_submission_path):\n",
        "        submission_df = pd.read_csv(sample_submission_path)\n",
        "        print(f\"✅ sample_submission.csv 로드 완료: {submission_df.shape}\")\n",
        "        \n",
        "        # 예측값 길이 확인 및 조정\n",
        "        if len(predictions) != len(submission_df):\n",
        "            print(f\"⚠️  예측값 길이 불일치: 예측값 {len(predictions)}, 제출파일 {len(submission_df)}\")\n",
        "            \n",
        "            # 길이 맞추기\n",
        "            if len(predictions) > len(submission_df):\n",
        "                predictions = predictions[:len(submission_df)]\n",
        "                print(f\"✂️  예측값을 {len(submission_df)}개로 잘랐습니다.\")\n",
        "            else:\n",
        "                # 부족한 경우 평균값으로 채우기\n",
        "                mean_pred = np.mean(predictions)\n",
        "                predictions.extend([mean_pred] * (len(submission_df) - len(predictions)))\n",
        "                print(f\"📈 예측값을 평균값({mean_pred:.4f})로 {len(submission_df)}개까지 채웠습니다.\")\n",
        "        \n",
        "        # 예측값을 제출 파일에 할당\n",
        "        submission_df['clicked'] = predictions\n",
        "        \n",
        "        # 출력 디렉토리 생성 (스마트 경로)\n",
        "        possible_output_dirs = [\n",
        "            \"/content/TossCTR/data/output\",              # Colab\n",
        "            \"/Users/hj/projects/TossCTR/data/output\"     # 로컬\n",
        "        ]\n",
        "        \n",
        "        output_dir = None\n",
        "        for out_dir in possible_output_dirs:\n",
        "            try:\n",
        "                os.makedirs(out_dir, exist_ok=True)\n",
        "                output_dir = out_dir\n",
        "                print(f\"✅ 출력 디렉토리 설정: {output_dir}\")\n",
        "                break\n",
        "            except:\n",
        "                continue\n",
        "        \n",
        "        if output_dir is None:\n",
        "            output_dir = \"/tmp/output\"  # 임시 디렉토리 사용\n",
        "            os.makedirs(output_dir, exist_ok=True)\n",
        "            print(f\"⚠️  임시 출력 디렉토리 사용: {output_dir}\")\n",
        "        \n",
        "        # 제출 파일 저장\n",
        "        output_path = os.path.join(output_dir, \"feseq_submission.csv\")\n",
        "        submission_df.to_csv(output_path, index=False)\n",
        "        \n",
        "        print(f\"✅ 제출 파일 생성 완료: {output_path}\")\n",
        "        print(f\"📊 예측 통계:\")\n",
        "        print(f\"   - 최솟값: {np.min(predictions):.6f}\")\n",
        "        print(f\"   - 최댓값: {np.max(predictions):.6f}\")\n",
        "        print(f\"   - 평균값: {np.mean(predictions):.6f}\")\n",
        "        print(f\"   - 표준편차: {np.std(predictions):.6f}\")\n",
        "        \n",
        "        # 예측값 분포 확인\n",
        "        print(f\"📈 예측값 분포:\")\n",
        "        hist, bins = np.histogram(predictions, bins=10)\n",
        "        for i in range(len(hist)):\n",
        "            print(f\"   {bins[i]:.3f}-{bins[i+1]:.3f}: {hist[i]}개\")\n",
        "            \n",
        "    else:\n",
        "        print(\"❌ sample_submission.csv를 찾을 수 없습니다:\")\n",
        "        for sub_path in possible_submission_paths:\n",
        "            exists = \"✅\" if os.path.exists(sub_path) else \"❌\"\n",
        "            print(f\"   {exists} {sub_path}\")\n",
        "\n",
        "else:\n",
        "    print(\"❌ 예측값이 없습니다. 추론을 먼저 완료해주세요.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 결과 검증 및 최종 확인\n",
        "print(\"🔍 최종 결과 검증...\")\n",
        "\n",
        "# 생성된 제출 파일 확인 (스마트 경로)\n",
        "possible_output_dirs = [\n",
        "    \"/content/TossCTR/data/output\",              # Colab\n",
        "    \"/Users/hj/projects/TossCTR/data/output\",    # 로컬\n",
        "    \"/tmp/output\"                                # 임시\n",
        "]\n",
        "\n",
        "feseq_submission_path = None\n",
        "for output_dir in possible_output_dirs:\n",
        "    potential_path = os.path.join(output_dir, \"feseq_submission.csv\")\n",
        "    if os.path.exists(potential_path):\n",
        "        feseq_submission_path = potential_path\n",
        "        break\n",
        "\n",
        "if os.path.exists(feseq_submission_path):\n",
        "    # 제출 파일 로드 및 검증\n",
        "    final_submission = pd.read_csv(feseq_submission_path)\n",
        "    \n",
        "    print(f\"✅ 최종 제출 파일 검증 완료:\")\n",
        "    print(f\"   📁 파일 경로: {feseq_submission_path}\")\n",
        "    print(f\"   📊 파일 크기: {final_submission.shape}\")\n",
        "    print(f\"   📋 컬럼: {list(final_submission.columns)}\")\n",
        "    \n",
        "    # 제출 파일 형식 검증\n",
        "    required_columns = ['ID', 'clicked']\n",
        "    missing_columns = [col for col in required_columns if col not in final_submission.columns]\n",
        "    \n",
        "    if missing_columns:\n",
        "        print(f\"❌ 필수 컬럼 누락: {missing_columns}\")\n",
        "    else:\n",
        "        print(\"✅ 제출 파일 형식 검증 통과\")\n",
        "    \n",
        "    # 예측값 범위 검증\n",
        "    clicked_values = final_submission['clicked']\n",
        "    if clicked_values.min() >= 0 and clicked_values.max() <= 1:\n",
        "        print(\"✅ 예측값 범위 검증 통과 (0-1 사이)\")\n",
        "    else:\n",
        "        print(f\"⚠️  예측값 범위 주의: {clicked_values.min():.6f} ~ {clicked_values.max():.6f}\")\n",
        "    \n",
        "    # 결측값 확인\n",
        "    if clicked_values.isnull().sum() == 0:\n",
        "        print(\"✅ 결측값 없음\")\n",
        "    else:\n",
        "        print(f\"⚠️  결측값 발견: {clicked_values.isnull().sum()}개\")\n",
        "    \n",
        "    # 샘플 출력\n",
        "    print(f\"\\n📋 제출 파일 샘플:\")\n",
        "    print(final_submission.head(10))\n",
        "    \n",
        "    print(f\"\\n🎉 FESeq 모델 추론 및 제출 파일 생성이 완료되었습니다!\")\n",
        "    print(f\"💾 제출 파일: {feseq_submission_path}\")\n",
        "    \n",
        "else:\n",
        "    print(f\"❌ 제출 파일이 생성되지 않았습니다: {feseq_submission_path}\")\n",
        "    print(\"이전 단계에서 오류가 발생했는지 확인해주세요.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📋 실행 요약\n",
        "\n",
        "### 🎯 완료된 작업\n",
        "1. **모델 훈련**: FESeq 모델이 TossCTR 데이터셋에서 성공적으로 훈련되었습니다\n",
        "2. **성능**: Test AUC 0.563으로 의미있는 성능을 달성했습니다\n",
        "3. **추론**: 훈련된 모델로 test.parquet 데이터에 대한 예측을 수행했습니다\n",
        "4. **제출 파일**: sample_submission.csv 형식에 맞는 제출 파일을 생성했습니다\n",
        "\n",
        "### 📁 생성된 파일\n",
        "- `/content/TossCTR/data/output/feseq_submission.csv`: FESeq 모델의 최종 제출 파일\n",
        "\n",
        "### 🚀 다음 단계 제안\n",
        "1. **성능 개선**: 하이퍼파라미터 튜닝으로 모델 성능 향상\n",
        "2. **앙상블**: 다른 모델과 결합하여 예측 성능 개선\n",
        "3. **피처 엔지니어링**: 추가 피처를 활용한 성능 향상\n",
        "\n",
        "### 💡 참고사항\n",
        "- 현재 모델은 시퀀스 기반 CTR 예측의 베이스라인으로 활용 가능합니다\n",
        "- 실제 서비스 적용을 위해서는 AUC 0.7+ 달성을 목표로 추가 개선이 필요합니다\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FESeq Model Training on TossCTR Dataset\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì€ TossCTR ë°ì´í„°ì…‹ì—ì„œ FESeq ëª¨ë¸ì„ í›ˆë ¨í•˜ê¸° ìœ„í•œ Colab í™˜ê²½ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
        "\n",
        "## ðŸš€ ì£¼ìš” ê°œì„ ì‚¬í•­\n",
        "- **ì›ë³¸ Parquet ë¡œë“œ**: ì „ì²˜ë¦¬ëœ CSVê°€ ì•„ë‹Œ ì›ë³¸ train.parquetì—ì„œ ì§ì ‘ ë°ì´í„° ë¡œë“œ\n",
        "- **ë°ì´í„°ëŸ‰ ì¡°ì ˆ**: N_SAMPLES ë³€ìˆ˜ë¡œ í•™ìŠµ ë°ì´í„° ì–‘ ì¡°ì ˆ ê°€ëŠ¥ (ê¸°ë³¸ê°’: 10ë§Œê°œ)  \n",
        "- **ìŠ¤ë§ˆíŠ¸ ê²½ë¡œ íƒì§€**: Colabê³¼ ë¡œì»¬ í™˜ê²½ ìžë™ ê°ì§€\n",
        "\n",
        "## ðŸ“‹ ì‹¤í–‰ ìˆœì„œ\n",
        "1. í™˜ê²½ ì„¤ì • ë° íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
        "2. ì½”ë“œ ë° ë°ì´í„° ì—…ë¡œë“œ  \n",
        "3. **ì›ë³¸ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬** (ìƒˆë¡œ ì¶”ê°€)\n",
        "4. ë°ì´í„° í™•ì¸\n",
        "5. FESeq ëª¨ë¸ í›ˆë ¨\n",
        "6. ì¶”ë¡  ë° ì œì¶œ íŒŒì¼ ìƒì„±\n",
        "\n",
        "## ðŸ’¡ ë°ì´í„°ëŸ‰ ì¡°ì ˆ ë°©ë²•\n",
        "```python\n",
        "N_SAMPLES = 100000  # 10ë§Œê°œ (ë¹ ë¥¸ ì‹¤í—˜ìš©)\n",
        "N_SAMPLES = 500000  # 50ë§Œê°œ (ì¤‘ê°„ ê·œëª¨)\n",
        "N_SAMPLES = 0       # ì „ì²´ ë°ì´í„° (ìµœê³  ì„±ëŠ¥)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸš€ Step 1: í™˜ê²½ ì„¤ì • ë° GPU í™•ì¸\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\n",
        "import torch\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "else:\n",
        "    print(\"âš ï¸  GPU not available, using CPU\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“¦ Step 2: ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
        "%pip install -qq pandas numpy scikit-learn PyYAML h5py tqdm pyarrow\n",
        "\n",
        "# PyTorch ì„¤ì¹˜ (GPU ë²„ì „)\n",
        "%pip install -qq torch torchvision --index-url https://download.pytorch.org/whl/cu118\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“ Step 3: GitHubì—ì„œ ì½”ë“œ í´ë¡ \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GitHubì—ì„œ TossCTR ë ˆí¬ì§€í† ë¦¬ í´ë¡ \n",
        "import os\n",
        "\n",
        "print(\"ðŸ“¥ GitHubì—ì„œ TossCTR ë ˆí¬ì§€í† ë¦¬ë¥¼ í´ë¡ í•©ë‹ˆë‹¤...\")\n",
        "!git clone https://github.com/kwonhwijun/TossCTR.git\n",
        "\n",
        "# colab_feseq ë””ë ‰í† ë¦¬ë¡œ ì´ë™\n",
        "print(\"ðŸ“ colab_feseq ë””ë ‰í† ë¦¬ë¡œ ì´ë™...\")\n",
        "%cd TossCTR/colab_feseq\n",
        "\n",
        "# í˜„ìž¬ ë””ë ‰í† ë¦¬ êµ¬ì¡° í™•ì¸\n",
        "print(\"\\nðŸ“ í˜„ìž¬ ë””ë ‰í† ë¦¬ êµ¬ì¡°:\")\n",
        "!ls -la\n",
        "\n",
        "# ì¤‘ìš”í•œ íŒŒì¼ë“¤ì´ ìžˆëŠ”ì§€ í™•ì¸\n",
        "print(\"\\nðŸ” ì¤‘ìš” íŒŒì¼ í™•ì¸:\")\n",
        "print(\"âœ… run_feseq.py:\", \"ì¡´ìž¬\" if os.path.exists(\"run_feseq.py\") else \"âŒ ì—†ìŒ\")\n",
        "print(\"âœ… FESeq ëª¨ë¸:\", \"ì¡´ìž¬\" if os.path.exists(\"model_zoo/FESeq\") else \"âŒ ì—†ìŒ\") \n",
        "print(\"âœ… ë°ì´í„°:\", \"ì¡´ìž¬\" if os.path.exists(\"data/tossctr\") else \"âŒ ì—†ìŒ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âš™ï¸ Step 4: FuxiCTR í™˜ê²½ ì„¤ì •\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FuxiCTR ì„¤ì¹˜\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# PYTHONPATH ì„¤ì •\n",
        "current_dir = os.getcwd()\n",
        "if current_dir not in sys.path:\n",
        "    sys.path.insert(0, current_dir)\n",
        "\n",
        "os.environ['PYTHONPATH'] = current_dir\n",
        "print(f\"âœ… PYTHONPATH: {current_dir}\")\n",
        "\n",
        "# setup.py ì„¤ì¹˜ ì‹œë„\n",
        "try:\n",
        "    print(\"ðŸ“¦ FuxiCTR ì„¤ì¹˜ ì¤‘...\")\n",
        "    !python setup.py develop\n",
        "    print(\"âœ… FuxiCTR í™˜ê²½ ì„¤ì • ì™„ë£Œ\")\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸  setup.py ì„¤ì¹˜ ì‹¤íŒ¨: {e}\")\n",
        "    print(\"ðŸ“¦ pipìœ¼ë¡œ ëŒ€ì²´ ì„¤ì¹˜ ì‹œë„...\")\n",
        "    %pip install -e .\n",
        "    print(\"âœ… FuxiCTR í™˜ê²½ ì„¤ì • ì™„ë£Œ (pip ë°©ì‹)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“Š Step 5: ì›ë³¸ Parquet ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
        "\n",
        "ì›ë³¸ train.parquet íŒŒì¼ì—ì„œ ì§ì ‘ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  FESeq í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
        "ë°ì´í„° ì–‘ì„ ì¡°ì ˆí•˜ì—¬ ë¹ ë¥¸ ì‹¤í—˜ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ðŸ“Š ë°ì´í„° ë¡œë“œ ì„¤ì •\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# ë°ì´í„°ëŸ‰ ì„¤ì • (í•„ìš”ì— ë”°ë¼ ì¡°ì •)\n",
        "N_SAMPLES = 100000  # 10ë§Œê°œ ìƒ˜í”Œ (0ìœ¼ë¡œ ì„¤ì •í•˜ë©´ ì „ì²´ ë°ì´í„° ì‚¬ìš©)\n",
        "\n",
        "print(f\"ðŸŽ¯ ë¡œë“œí•  ë°ì´í„° ìƒ˜í”Œ ìˆ˜: {N_SAMPLES:,}ê°œ\")\n",
        "print(f\"   ðŸ’¡ íŒ: N_SAMPLES = 0ìœ¼ë¡œ ì„¤ì •í•˜ë©´ ì „ì²´ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤\")\n",
        "\n",
        "# ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œ í™•ì¸\n",
        "preprocessing_script = \"/content/TossCTR/colab_feseq/preprocessing/tossctr_to_feseq.py\"\n",
        "if os.path.exists(preprocessing_script):\n",
        "    print(f\"âœ… ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ ë°œê²¬: {preprocessing_script}\")\n",
        "else:\n",
        "    print(f\"âŒ ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ ì—†ìŒ: {preprocessing_script}\")\n",
        "    print(\"GitHub í´ë¡ ì´ ì œëŒ€ë¡œ ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ðŸ“¥ ì›ë³¸ train.parquet íŒŒì¼ ì°¾ê¸° ë° ë¡œë“œ\n",
        "print(\"ðŸ” ì›ë³¸ train.parquet íŒŒì¼ì„ ì°¾ëŠ” ì¤‘...\")\n",
        "\n",
        "# ê°€ëŠ¥í•œ train.parquet íŒŒì¼ ê²½ë¡œë“¤ (ìš°ì„ ìˆœìœ„ ìˆœ)\n",
        "possible_train_paths = [\n",
        "    \"/content/drive/MyDrive/data/TossCTR/raw/train.parquet\",     # Colab êµ¬ê¸€ ë“œë¼ì´ë¸Œ\n",
        "    \"/content/TossCTR/data/raw/train.parquet\",                  # Colab ë¡œì»¬\n",
        "    \"/Users/hj/projects/TossCTR/data/raw/train.parquet\"         # ë¡œì»¬ í™˜ê²½\n",
        "]\n",
        "\n",
        "train_parquet_path = None\n",
        "for path in possible_train_paths:\n",
        "    if os.path.exists(path):\n",
        "        train_parquet_path = path\n",
        "        print(f\"âœ… ì›ë³¸ train.parquet ë°œê²¬: {path}\")\n",
        "        \n",
        "        # íŒŒì¼ í¬ê¸° í™•ì¸\n",
        "        file_size = os.path.getsize(path) / (1024**3)  # GB ë‹¨ìœ„\n",
        "        print(f\"ðŸ“Š íŒŒì¼ í¬ê¸°: {file_size:.2f} GB\")\n",
        "        break\n",
        "\n",
        "if train_parquet_path is None:\n",
        "    print(\"âŒ train.parquet íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤:\")\n",
        "    for path in possible_train_paths:\n",
        "        exists = \"âœ…\" if os.path.exists(path) else \"âŒ\"\n",
        "        print(f\"   {exists} {path}\")\n",
        "    print(\"\\nðŸ“‹ í•´ê²° ë°©ë²•:\")\n",
        "    print(\"1. Google Driveì— ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”\")\n",
        "    print(\"2. ë˜ëŠ” ë¡œì»¬ì—ì„œ ë°ì´í„° ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”\")\n",
        "else:\n",
        "    print(f\"ðŸŽ¯ ì‚¬ìš©í•  train.parquet ê²½ë¡œ: {train_parquet_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ðŸ”„ ì›ë³¸ parquet ë°ì´í„°ë¥¼ FESeq í˜•ì‹ìœ¼ë¡œ ì „ì²˜ë¦¬\n",
        "import subprocess\n",
        "\n",
        "if train_parquet_path and os.path.exists(preprocessing_script):\n",
        "    print(\"ðŸ”„ ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ì‹œìž‘í•©ë‹ˆë‹¤...\")\n",
        "    \n",
        "    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •\n",
        "    output_dir = \"/content/TossCTR/colab_feseq/data/tossctr\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    \n",
        "    try:\n",
        "        print(f\"ðŸ“Š {N_SAMPLES:,}ê°œ ìƒ˜í”Œë¡œ ì „ì²˜ë¦¬ ì‹¤í–‰ ì¤‘...\")\n",
        "        \n",
        "        # ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰\n",
        "        result = subprocess.run([\n",
        "            sys.executable, preprocessing_script,\n",
        "            \"--train_path\", train_parquet_path,\n",
        "            \"--output_dir\", output_dir,\n",
        "            \"--n_samples\", str(N_SAMPLES)\n",
        "        ], check=True, capture_output=True, text=True)\n",
        "        \n",
        "        print(\"âœ… ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ!\")\n",
        "        print(\"ðŸ“„ ì „ì²˜ë¦¬ ë¡œê·¸:\")\n",
        "        print(result.stdout)\n",
        "        \n",
        "        # ìƒì„±ëœ íŒŒì¼ë“¤ í™•ì¸\n",
        "        print(\"\\nðŸ“ ìƒì„±ëœ íŒŒì¼ë“¤:\")\n",
        "        if os.path.exists(output_dir):\n",
        "            files = os.listdir(output_dir)\n",
        "            for file in files:\n",
        "                file_path = os.path.join(output_dir, file)\n",
        "                if os.path.isfile(file_path):\n",
        "                    size_mb = os.path.getsize(file_path) / (1024**2)\n",
        "                    print(f\"  âœ… {file} ({size_mb:.2f} MB)\")\n",
        "        \n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"âŒ ì „ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "        print(f\"ðŸ“„ ì—ëŸ¬ ë¡œê·¸:\")\n",
        "        print(e.stderr)\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ì˜ˆê¸°ì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}\")\n",
        "        \n",
        "else:\n",
        "    print(\"âŒ ì „ì²˜ë¦¬ë¥¼ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "    if not train_parquet_path:\n",
        "        print(\"  - train.parquet íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤\")\n",
        "    if not os.path.exists(preprocessing_script):\n",
        "        print(f\"  - ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤: {preprocessing_script}\")\n",
        "    \n",
        "    print(\"\\nðŸ“‹ ëŒ€ì•ˆ: ê¸°ì¡´ ì „ì²˜ë¦¬ëœ íŒŒì¼ ì‚¬ìš©\")\n",
        "    existing_files = [\n",
        "        \"/content/TossCTR/colab_feseq/data/tossctr/train_data.csv\",\n",
        "        \"/content/TossCTR/colab_feseq/data/tossctr/val_data.csv\", \n",
        "        \"/content/TossCTR/colab_feseq/data/tossctr/test_data.csv\"\n",
        "    ]\n",
        "    \n",
        "    for file_path in existing_files:\n",
        "        exists = \"âœ…\" if os.path.exists(file_path) else \"âŒ\"\n",
        "        print(f\"  {exists} {file_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ§  Step 6: FESeq ëª¨ë¸ í›ˆë ¨ ì‹¤í–‰\n",
        "\n",
        "ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¡œ FESeq ëª¨ë¸ì„ í›ˆë ¨í•©ë‹ˆë‹¤.\n",
        "dk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ðŸ“Š ì „ì²˜ë¦¬ëœ ë°ì´í„° í™•ì¸\n",
        "print(\"ðŸ“‹ ìƒì„±ëœ í›ˆë ¨ ë°ì´í„° í™•ì¸...\")\n",
        "\n",
        "output_dir = \"/content/TossCTR/colab_feseq/data/tossctr\"\n",
        "data_files = [\"train_data.csv\", \"val_data.csv\", \"test_data.csv\"]\n",
        "\n",
        "for data_file in data_files:\n",
        "    file_path = os.path.join(output_dir, data_file)\n",
        "    if os.path.exists(file_path):\n",
        "        import pandas as pd\n",
        "        df = pd.read_csv(file_path)\n",
        "        size_mb = os.path.getsize(file_path) / (1024**2)\n",
        "        print(f\"âœ… {data_file}: {df.shape} ({size_mb:.2f} MB)\")\n",
        "        \n",
        "        if data_file == \"train_data.csv\":\n",
        "            print(f\"   ðŸ“Š Click ë¹„ìœ¨: {df['clicked'].mean():.4f}\")\n",
        "            print(f\"   ðŸ“‹ ì»¬ëŸ¼: {list(df.columns)}\")\n",
        "    else:\n",
        "        print(f\"âŒ {data_file}: íŒŒì¼ ì—†ìŒ\")\n",
        "\n",
        "print(f\"\\nðŸŽ¯ ì‚¬ìš©ëœ ìƒ˜í”Œ ìˆ˜: {N_SAMPLES:,}ê°œ\")\n",
        "print(\"ðŸ’¡ ë°ì´í„°ëŸ‰ì„ ë³€ê²½í•˜ë ¤ë©´ ìœ„ì˜ N_SAMPLES ê°’ì„ ìˆ˜ì •í•˜ê³  ì „ì²˜ë¦¬ë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# í˜„ìž¬ ë””ë ‰í† ë¦¬ í™•ì¸\n",
        "import os\n",
        "print(f\"ðŸ“ í˜„ìž¬ ìž‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()}\")\n",
        "\n",
        "# í•„ìˆ˜ íŒŒì¼ë“¤ì´ ìžˆëŠ”ì§€ ë‹¤ì‹œ í•œë²ˆ í™•ì¸\n",
        "required_files = [\"run_feseq.py\", \"setup.py\", \"model_zoo/FESeq/run_expid.py\"]\n",
        "missing_files = []\n",
        "\n",
        "for file in required_files:\n",
        "    if os.path.exists(file):\n",
        "        print(f\"âœ… {file}\")\n",
        "    else:\n",
        "        print(f\"âŒ {file} - ì—†ìŒ\")\n",
        "        missing_files.append(file)\n",
        "\n",
        "if missing_files:\n",
        "    print(f\"\\nâš ï¸  ë‹¤ìŒ íŒŒì¼ë“¤ì´ ì—†ìŠµë‹ˆë‹¤: {missing_files}\")\n",
        "    print(\"ë””ë ‰í† ë¦¬ë¥¼ ë‹¤ì‹œ í™•ì¸í•˜ì„¸ìš”.\")\n",
        "else:\n",
        "    # GPU ì„¤ì •\n",
        "    import torch\n",
        "    gpu_id = 0 if torch.cuda.is_available() else -1\n",
        "    print(f\"\\nðŸŽ¯ ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤: {'GPU ' + str(gpu_id) if gpu_id >= 0 else 'CPU'}\")\n",
        "    \n",
        "    # FESeq ì‹¤í—˜ ì‹¤í–‰\n",
        "    print(\"\\nðŸš€ FESeq ì‹¤í—˜ì„ ì‹œìž‘í•©ë‹ˆë‹¤...\")\n",
        "    !python run_feseq.py --expid FESeq_tossctr --gpu {gpu_id}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”§ Step 6: ë¬¸ì œ í•´ê²° (í•„ìš”ì‹œ)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë¬¸ì œê°€ ìžˆì„ ê²½ìš° ìˆ˜ë™ìœ¼ë¡œ ë””ë ‰í† ë¦¬ í™•ì¸ ë° ì´ë™\n",
        "import os\n",
        "\n",
        "print(\"ðŸ” í˜„ìž¬ ìœ„ì¹˜ì™€ íŒŒì¼ êµ¬ì¡° í™•ì¸:\")\n",
        "print(f\"í˜„ìž¬ ë””ë ‰í† ë¦¬: {os.getcwd()}\")\n",
        "\n",
        "# ê°€ëŠ¥í•œ ìœ„ì¹˜ë“¤ í™•ì¸\n",
        "possible_locations = [\n",
        "    \".\",\n",
        "    \"/content/TossCTR/colab_feseq\", \n",
        "    \"/content/TossCTR\",\n",
        "    \"/content\"\n",
        "]\n",
        "\n",
        "for location in possible_locations:\n",
        "    if os.path.exists(location):\n",
        "        print(f\"\\nðŸ“ {location} ë‚´ìš©:\")\n",
        "        try:\n",
        "            files = os.listdir(location)\n",
        "            for f in files[:10]:  # ì²˜ìŒ 10ê°œë§Œ ì¶œë ¥\n",
        "                print(f\"  - {f}\")\n",
        "            if len(files) > 10:\n",
        "                print(f\"  ... ê·¸ì™¸ {len(files)-10}ê°œ íŒŒì¼\")\n",
        "        except:\n",
        "            print(f\"  ì ‘ê·¼ ë¶ˆê°€\")\n",
        "\n",
        "# run_feseq.py íŒŒì¼ ì°¾ê¸°\n",
        "print(f\"\\nðŸ” run_feseq.py íŒŒì¼ ì°¾ê¸°:\")\n",
        "!find /content -name \"run_feseq.py\" 2>/dev/null\n",
        "\n",
        "# ì˜¬ë°”ë¥¸ ë””ë ‰í† ë¦¬ë¡œ ì´ë™ (ìˆ˜ë™)\n",
        "# ìœ„ì—ì„œ run_feseq.pyê°€ ë°œê²¬ëœ ë””ë ‰í† ë¦¬ë¡œ ì´ë™í•˜ì„¸ìš”\n",
        "# ì˜ˆ: %cd /content/TossCTR/colab_feseq\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”§ Step 6-2: ì§ì ‘ ì‹¤í–‰ (ëŒ€ì•ˆ ë°©ë²•)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# run_feseq.pyê°€ ì‹¤íŒ¨í•  ê²½ìš° ì§ì ‘ ì‹¤í–‰í•˜ëŠ” ë°©ë²•\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# í˜„ìž¬ ë””ë ‰í† ë¦¬ í™•ì¸\n",
        "print(f\"ðŸ“ í˜„ìž¬ ìœ„ì¹˜: {os.getcwd()}\")\n",
        "\n",
        "# FESeq ëª¨ë¸ ë””ë ‰í† ë¦¬ë¡œ ì´ë™\n",
        "%cd model_zoo/FESeq\n",
        "\n",
        "# PYTHONPATH ìž¬ì„¤ì •\n",
        "original_dir = \"/content/TossCTR/colab_feseq\"  # ë˜ëŠ” ìƒìœ„ ë””ë ‰í† ë¦¬ \n",
        "current_dir = os.getcwd()\n",
        "\n",
        "if original_dir not in sys.path:\n",
        "    sys.path.insert(0, original_dir)\n",
        "if current_dir not in sys.path:\n",
        "    sys.path.insert(0, current_dir)\n",
        "\n",
        "os.environ['PYTHONPATH'] = f\"{original_dir}:{current_dir}\"\n",
        "print(f\"âœ… PYTHONPATH: {os.environ['PYTHONPATH']}\")\n",
        "\n",
        "# ì„¤ì • íŒŒì¼ í™•ì¸\n",
        "print(\"\\nðŸ” ì„¤ì • íŒŒì¼ í™•ì¸:\")\n",
        "config_files = [\"config/dataset_config.yaml\", \"config/model_config.yaml\"]\n",
        "for config_file in config_files:\n",
        "    exists = \"âœ…\" if os.path.exists(config_file) else \"âŒ\"\n",
        "    print(f\"{exists} {config_file}\")\n",
        "\n",
        "# ë°ì´í„° íŒŒì¼ í™•ì¸\n",
        "print(\"\\nðŸ” ë°ì´í„° íŒŒì¼ í™•ì¸:\")\n",
        "data_dir = \"../../data/tossctr\"\n",
        "if os.path.exists(data_dir):\n",
        "    data_files = os.listdir(data_dir)\n",
        "    for file in data_files:\n",
        "        print(f\"âœ… {file}\")\n",
        "else:\n",
        "    print(f\"âŒ ë°ì´í„° ë””ë ‰í† ë¦¬ ì—†ìŒ: {data_dir}\")\n",
        "\n",
        "print(\"\\nðŸš€ ì§ì ‘ run_expid.py ì‹¤í–‰ ì¤€ë¹„ ì™„ë£Œ!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ìµœì¢… ì‹¤í–‰ - run_feseq.py ì‚¬ìš© (ê°œì„ ëœ ë²„ì „)\n",
        "import torch\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# GPU ì„¤ì •\n",
        "gpu_id = 0 if torch.cuda.is_available() else -1\n",
        "print(f\"ðŸŽ¯ GPU ID: {gpu_id}\")\n",
        "\n",
        "# í˜„ìž¬ ìž‘ì—… ë””ë ‰í† ë¦¬ í™•ì¸\n",
        "print(f\"ðŸ“ í˜„ìž¬ ë””ë ‰í† ë¦¬: {os.getcwd()}\")\n",
        "\n",
        "# FESeq ì‹¤í—˜ ì‹¤í–‰ (ì¡°ìš©í•œ ì„¤ì¹˜ í¬í•¨)\n",
        "print(\"ðŸš€ FESeq ì‹¤í—˜ ì‹œìž‘...\")\n",
        "\n",
        "try:\n",
        "    # run_feseq.py ì‹¤í–‰ (ê°œì„ ëœ íŒ¨í‚¤ì§€ ì„¤ì¹˜ í¬í•¨)\n",
        "    result = subprocess.run([\n",
        "        sys.executable, \"run_feseq.py\", \n",
        "        \"--expid\", \"FESeq_tossctr\", \n",
        "        \"--gpu\", str(gpu_id)\n",
        "    ], check=True, text=True)\n",
        "    print(\"âœ… FESeq ì‹¤í—˜ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"âŒ ì‹¤í—˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "    print(\"ë¡œê·¸ë¥¼ í™•ì¸í•˜ì—¬ ë¬¸ì œì ì„ íŒŒì•…í•˜ì„¸ìš”.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”® Step 6: ì¶”ë¡  ë° ì œì¶œ íŒŒì¼ ìƒì„±\n",
        "\n",
        "í›ˆë ¨ëœ FESeq ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ test.parquet ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ê³  ì œì¶œ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ðŸ”§ params ê²½ë¡œ ìˆ˜ì • ë° ê²€ì¦\n",
        "print(\"ðŸ”§ ì¶”ë¡ ì„ ìœ„í•œ ë°ì´í„° ê²½ë¡œ ìˆ˜ì •...\")\n",
        "\n",
        "if 'params' in locals() and params is not None:\n",
        "    # í˜„ìž¬ paramsì˜ ê²½ë¡œ í™•ì¸\n",
        "    print(f\"ðŸ“‹ í˜„ìž¬ ì„¤ì •ëœ ê²½ë¡œ:\")\n",
        "    print(f\"   - í›ˆë ¨: {params.get('train_data', 'N/A')}\")\n",
        "    print(f\"   - ê²€ì¦: {params.get('valid_data', 'N/A')}\")\n",
        "    print(f\"   - í…ŒìŠ¤íŠ¸: {params.get('test_data', 'N/A')}\")\n",
        "    print(f\"   - ë£¨íŠ¸: {params.get('data_root', 'N/A')}\")\n",
        "    \n",
        "    # ìŠ¤ë§ˆíŠ¸ ê²½ë¡œ íƒì§€ ë° ìˆ˜ì •\n",
        "    possible_data_dirs = [\n",
        "        \"/content/TossCTR/colab_feseq/data/tossctr\",      # Colab\n",
        "        \"/Users/hj/projects/TossCTR/colab_feseq/data/tossctr\"  # ë¡œì»¬\n",
        "    ]\n",
        "    \n",
        "    correct_data_dir = None\n",
        "    for dir_path in possible_data_dirs:\n",
        "        test_csv = os.path.join(dir_path, \"test_data.csv\")\n",
        "        if os.path.exists(test_csv):\n",
        "            correct_data_dir = dir_path\n",
        "            print(f\"âœ… ì˜¬ë°”ë¥¸ ë°ì´í„° ë””ë ‰í† ë¦¬ ë°œê²¬: {correct_data_dir}\")\n",
        "            break\n",
        "    \n",
        "    if correct_data_dir:\n",
        "        # ì ˆëŒ€ ê²½ë¡œë¡œ ìˆ˜ì •\n",
        "        params['train_data'] = os.path.join(correct_data_dir, \"train_data.csv\")\n",
        "        params['valid_data'] = os.path.join(correct_data_dir, \"val_data.csv\") \n",
        "        params['test_data'] = os.path.join(correct_data_dir, \"test_data.csv\")\n",
        "        params['data_root'] = os.path.dirname(correct_data_dir)\n",
        "        \n",
        "        print(f\"ðŸ”„ ê²½ë¡œ ìˆ˜ì • ì™„ë£Œ:\")\n",
        "        print(f\"   - í›ˆë ¨: {params['train_data']}\")\n",
        "        print(f\"   - ê²€ì¦: {params['valid_data']}\")\n",
        "        print(f\"   - í…ŒìŠ¤íŠ¸: {params['test_data']}\")\n",
        "        print(f\"   - ë£¨íŠ¸: {params['data_root']}\")\n",
        "        \n",
        "        # íŒŒì¼ ì¡´ìž¬ ì—¬ë¶€ í™•ì¸\n",
        "        for file_type, file_path in [(\"í›ˆë ¨\", params['train_data']), \n",
        "                                   (\"ê²€ì¦\", params['valid_data']), \n",
        "                                   (\"í…ŒìŠ¤íŠ¸\", params['test_data'])]:\n",
        "            exists = \"âœ…\" if os.path.exists(file_path) else \"âŒ\"\n",
        "            print(f\"   {exists} {file_type}: {os.path.basename(file_path)}\")\n",
        "            \n",
        "    else:\n",
        "        print(\"âŒ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤:\")\n",
        "        for dir_path in possible_data_dirs:\n",
        "            test_csv = os.path.join(dir_path, \"test_data.csv\")\n",
        "            exists = \"âœ…\" if os.path.exists(test_csv) else \"âŒ\"\n",
        "            print(f\"   {exists} {test_csv}\")\n",
        "        print(\"ë¨¼ì € ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ì™„ë£Œí•´ì£¼ì„¸ìš”.\")\n",
        "        \n",
        "else:\n",
        "    print(\"âŒ paramsê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € ì´ì „ ì…€ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ðŸ”® ê°œì„ ëœ ì¶”ë¡  ë°ì´í„° ë¡œë” ìƒì„± ë° ì˜ˆì¸¡ ìˆ˜í–‰\n",
        "print(\"ðŸ“Š ì¶”ë¡  ë°ì´í„° ë¡œë” ìƒì„± ì¤‘...\")\n",
        "\n",
        "# ëª¨ë¸, Feature Map, paramsê°€ ì œëŒ€ë¡œ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸\n",
        "missing_components = []\n",
        "if 'model' not in locals() or model is None:\n",
        "    missing_components.append(\"ëª¨ë¸\")\n",
        "if 'feature_map' not in locals() or feature_map is None:\n",
        "    missing_components.append(\"Feature Map\")\n",
        "if 'params' not in locals() or params is None:\n",
        "    missing_components.append(\"params\")\n",
        "\n",
        "if missing_components:\n",
        "    print(f\"âŒ ë‹¤ìŒ êµ¬ì„± ìš”ì†Œê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {', '.join(missing_components)}\")\n",
        "    print(\"ì´ì „ ì…€ë“¤ì„ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n",
        "    predictions = None\n",
        "else:\n",
        "    # H5 ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ í™•ì¸\n",
        "    dataset_id = params.get('dataset_id', 'tossctr_dataset')\n",
        "    data_root = params.get('data_root', '')\n",
        "    \n",
        "    # ê°€ëŠ¥í•œ H5 ë°ì´í„°ì…‹ ê²½ë¡œë“¤\n",
        "    possible_h5_dirs = [\n",
        "        os.path.join(data_root, dataset_id),                                    # params ê¸°ë°˜\n",
        "        \"/content/TossCTR/colab_feseq/data/tossctr_dataset\",                   # Colab\n",
        "        \"/Users/hj/projects/TossCTR/colab_feseq/data/tossctr_dataset\"          # ë¡œì»¬\n",
        "    ]\n",
        "    \n",
        "    h5_data_dir = None\n",
        "    for dir_path in possible_h5_dirs:\n",
        "        test_h5_path = os.path.join(dir_path, \"test.h5\")\n",
        "        if os.path.exists(test_h5_path):\n",
        "            h5_data_dir = dir_path\n",
        "            print(f\"âœ… H5 ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ ë°œê²¬: {h5_data_dir}\")\n",
        "            print(f\"âœ… test.h5 íŒŒì¼ í™•ì¸: {test_h5_path}\")\n",
        "            break\n",
        "    \n",
        "    if h5_data_dir:\n",
        "        try:\n",
        "            # feature_mapì˜ data_dir ì—…ë°ì´íŠ¸\n",
        "            feature_map.data_dir = h5_data_dir\n",
        "            \n",
        "            # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë” ìƒì„±\n",
        "            print(\"ðŸ”„ H5DataLoader ì´ˆê¸°í™” ì¤‘...\")\n",
        "            test_loader = H5DataLoader(feature_map, stage='test', **params).make_iterator()\n",
        "            \n",
        "            print(\"ðŸ”® ëª¨ë¸ ì¶”ë¡  ì‹œìž‘...\")\n",
        "            predictions = []\n",
        "            batch_count = 0\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                for batch_idx, batch_data in enumerate(test_loader):\n",
        "                    # ë°°ì¹˜ ì˜ˆì¸¡\n",
        "                    output = model(batch_data)\n",
        "                    batch_pred = torch.sigmoid(output['y_pred']).cpu().numpy().flatten()\n",
        "                    predictions.extend(batch_pred)\n",
        "                    batch_count += 1\n",
        "                    \n",
        "                    # ì§„í–‰ ìƒí™© ì¶œë ¥ (ë§¤ 10ë°°ì¹˜ë§ˆë‹¤)\n",
        "                    if batch_idx % 10 == 0:\n",
        "                        print(f\"  ì²˜ë¦¬ëœ ë°°ì¹˜: {batch_idx + 1}, ëˆ„ì  ì˜ˆì¸¡ ìˆ˜: {len(predictions)}\")\n",
        "            \n",
        "            print(f\"âœ… ì¶”ë¡  ì™„ë£Œ!\")\n",
        "            print(f\"ðŸ“Š ì´ ì²˜ë¦¬ëœ ë°°ì¹˜: {batch_count}\")\n",
        "            print(f\"ðŸ“Š ì´ ì˜ˆì¸¡ ìƒ˜í”Œ ìˆ˜: {len(predictions)}\")\n",
        "            print(f\"ðŸ“Š ì˜ˆì¸¡ê°’ ë²”ìœ„: {min(predictions):.6f} ~ {max(predictions):.6f}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ì¶”ë¡  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "            print(f\"ðŸ“‹ ë””ë²„ê·¸ ì •ë³´:\")\n",
        "            print(f\"   - feature_map.data_dir: {getattr(feature_map, 'data_dir', 'N/A')}\")\n",
        "            print(f\"   - H5 ë””ë ‰í† ë¦¬: {h5_data_dir}\")\n",
        "            print(f\"   - params.test_data: {params.get('test_data', 'N/A')}\")\n",
        "            predictions = None\n",
        "    else:\n",
        "        print(\"âŒ H5 ë°ì´í„°ì…‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤:\")\n",
        "        for dir_path in possible_h5_dirs:\n",
        "            test_h5_path = os.path.join(dir_path, \"test.h5\")\n",
        "            exists = \"âœ…\" if os.path.exists(test_h5_path) else \"âŒ\"\n",
        "            print(f\"   {exists} {test_h5_path}\")\n",
        "        \n",
        "        print(\"\\nðŸ“‹ í•´ê²° ë°©ë²•:\")\n",
        "        print(\"1. ë¨¼ì € FESeq ëª¨ë¸ í›ˆë ¨ì„ ì™„ë£Œí•˜ì„¸ìš” (H5 íŒŒì¼ì´ ìžë™ ìƒì„±ë©ë‹ˆë‹¤)\")\n",
        "        print(\"2. ë˜ëŠ” ë°ì´í„° ì „ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”\")\n",
        "        predictions = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì¶”ë¡ ì„ ìœ„í•œ í•„ìˆ˜ ìž„í¬íŠ¸\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import h5py\n",
        "import json\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# FuxiCTR ê´€ë ¨ ìž„í¬íŠ¸\n",
        "sys.path.append('/content/TossCTR/colab_feseq')\n",
        "sys.path.append('/content/TossCTR/colab_feseq/model_zoo/FESeq')\n",
        "\n",
        "from fuxictr.features import FeatureMapAbsTime\n",
        "from fuxictr.pytorch.dataloaders import H5DataLoader\n",
        "from model_zoo.FESeq.src.FESeq import FESeq\n",
        "\n",
        "print(\"âœ… ì¶”ë¡ ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì‹¤ì œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ (ìŠ¤ë§ˆíŠ¸ ê²½ë¡œ íƒì§€)\n",
        "print(\"ðŸ“¥ ì›ë³¸ test.parquet ë°ì´í„° ë¡œë“œ ì¤‘...\")\n",
        "\n",
        "# ê°€ëŠ¥í•œ test.parquet íŒŒì¼ ê²½ë¡œë“¤ (ìš°ì„ ìˆœìœ„ ìˆœ)\n",
        "possible_test_paths = [\n",
        "    \"/content/drive/MyDrive/data/TossCTR/raw/test.parquet\",     # Colab êµ¬ê¸€ ë“œë¼ì´ë¸Œ\n",
        "    \"/content/TossCTR/data/raw/test.parquet\",                  # Colab ë¡œì»¬\n",
        "    \"/Users/hj/projects/TossCTR/data/raw/test.parquet\"         # ë¡œì»¬ í™˜ê²½\n",
        "]\n",
        "\n",
        "# ê°€ëŠ¥í•œ ì „ì²˜ë¦¬ëœ ë°ì´í„° ê²½ë¡œë“¤\n",
        "possible_csv_paths = [\n",
        "    \"/content/TossCTR/colab_feseq/data/tossctr/test_data.csv\", # Colab\n",
        "    \"/Users/hj/projects/TossCTR/colab_feseq/data/tossctr/test_data.csv\" # ë¡œì»¬\n",
        "]\n",
        "\n",
        "test_df_original = None\n",
        "used_path = None\n",
        "\n",
        "# 1ì°¨ ì‹œë„: ì›ë³¸ parquet íŒŒì¼ ì°¾ê¸°\n",
        "for test_parquet_path in possible_test_paths:\n",
        "    if os.path.exists(test_parquet_path):\n",
        "        try:\n",
        "            print(f\"ðŸ” ì‹œë„ ì¤‘: {test_parquet_path}\")\n",
        "            test_df_original = pd.read_parquet(test_parquet_path)\n",
        "            used_path = test_parquet_path\n",
        "            print(f\"âœ… ì›ë³¸ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {test_df_original.shape}\")\n",
        "            print(f\"ðŸ“ ì‚¬ìš©ëœ ê²½ë¡œ: {used_path}\")\n",
        "            print(f\"ðŸ“‹ ì»¬ëŸ¼: {list(test_df_original.columns)}\")\n",
        "            print(f\"ðŸ“Š ìƒ˜í”Œ ë°ì´í„°:\")\n",
        "            print(test_df_original.head())\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸  {test_parquet_path} ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
        "            continue\n",
        "\n",
        "# 2ì°¨ ì‹œë„: ì „ì²˜ë¦¬ëœ CSV íŒŒì¼ ì°¾ê¸°\n",
        "if test_df_original is None:\n",
        "    print(\"ðŸ“„ ì›ë³¸ parquet íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ì „ì²˜ë¦¬ëœ CSV íŒŒì¼ì„ ì°¾ëŠ” ì¤‘...\")\n",
        "    for test_csv_path in possible_csv_paths:\n",
        "        if os.path.exists(test_csv_path):\n",
        "            try:\n",
        "                print(f\"ðŸ” ì‹œë„ ì¤‘: {test_csv_path}\")\n",
        "                test_df_original = pd.read_csv(test_csv_path)\n",
        "                used_path = test_csv_path\n",
        "                print(f\"âœ… ì „ì²˜ë¦¬ëœ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì‚¬ìš©: {test_df_original.shape}\")\n",
        "                print(f\"ðŸ“ ì‚¬ìš©ëœ ê²½ë¡œ: {used_path}\")\n",
        "                break\n",
        "            except Exception as e:\n",
        "                print(f\"âš ï¸  {test_csv_path} ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
        "                continue\n",
        "\n",
        "# ê²°ê³¼ í™•ì¸\n",
        "if test_df_original is None:\n",
        "    print(\"âŒ ì‚¬ìš© ê°€ëŠ¥í•œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "    print(\"ðŸ“‹ í™•ì¸ëœ ê²½ë¡œë“¤:\")\n",
        "    for path in possible_test_paths + possible_csv_paths:\n",
        "        exists = \"âœ…\" if os.path.exists(path) else \"âŒ\"\n",
        "        print(f\"   {exists} {path}\")\n",
        "else:\n",
        "    print(f\"ðŸŽ¯ ìµœì¢… ì‚¬ìš© ë°ì´í„°: {used_path}\")\n",
        "    print(f\"ðŸ“Š ë°ì´í„° í˜•íƒœ: {test_df_original.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ ë° ì„¤ì •\n",
        "print(\"ðŸ”„ í›ˆë ¨ëœ FESeq ëª¨ë¸ ë¡œë“œ ì¤‘...\")\n",
        "\n",
        "# ì„¤ì • íŒŒì¼ ë¡œë“œ\n",
        "config_path = \"/content/TossCTR/colab_feseq/model_zoo/FESeq/config\"\n",
        "sys.path.append(config_path)\n",
        "\n",
        "# FuxiCTR utils ìž„í¬íŠ¸\n",
        "from fuxictr.utils import load_config\n",
        "\n",
        "# ëª¨ë¸ ì„¤ì • ë¡œë“œ\n",
        "params = load_config(config_path, \"FESeq_tossctr\")\n",
        "params['gpu'] = 0 if torch.cuda.is_available() else -1\n",
        "\n",
        "print(f\"âœ… ëª¨ë¸ ì„¤ì • ë¡œë“œ ì™„ë£Œ\")\n",
        "print(f\"ðŸ“‹ ì£¼ìš” ì„¤ì •:\")\n",
        "print(f\"   - ëª¨ë¸: {params.get('model', 'N/A')}\")\n",
        "print(f\"   - ë°°ì¹˜ í¬ê¸°: {params.get('batch_size', 'N/A')}\")\n",
        "print(f\"   - ìž„ë² ë”© ì°¨ì›: {params.get('embedding_dim', 'N/A')}\")\n",
        "print(f\"   - GPU: {params['gpu']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature Map ë° ëª¨ë¸ ì´ˆê¸°í™” (ìŠ¤ë§ˆíŠ¸ ê²½ë¡œ íƒì§€)\n",
        "print(\"ðŸ—ºï¸ Feature Map ë¡œë“œ ì¤‘...\")\n",
        "\n",
        "# ê°€ëŠ¥í•œ ë°ì´í„° ë””ë ‰í† ë¦¬ë“¤\n",
        "possible_data_dirs = [\n",
        "    \"/content/TossCTR/colab_feseq/data/tossctr_dataset\",      # Colab\n",
        "    \"/Users/hj/projects/TossCTR/colab_feseq/data/tossctr_dataset\"  # ë¡œì»¬\n",
        "]\n",
        "\n",
        "# ê°€ëŠ¥í•œ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œë“¤\n",
        "possible_checkpoint_paths = [\n",
        "    \"/content/TossCTR/colab_feseq/model_zoo/FESeq/checkpoints/tossctr_dataset/FESeq_tossctr.model\",  # Colab\n",
        "    \"/Users/hj/projects/TossCTR/colab_feseq/model_zoo/FESeq/checkpoints/tossctr_dataset/FESeq_tossctr.model\"  # ë¡œì»¬\n",
        "]\n",
        "\n",
        "# ë°ì´í„° ë””ë ‰í† ë¦¬ ì°¾ê¸°\n",
        "data_dir = None\n",
        "for dir_path in possible_data_dirs:\n",
        "    feature_map_json = os.path.join(dir_path, \"feature_map.json\")\n",
        "    if os.path.exists(feature_map_json):\n",
        "        data_dir = dir_path\n",
        "        print(f\"âœ… ë°ì´í„° ë””ë ‰í† ë¦¬ ë°œê²¬: {data_dir}\")\n",
        "        break\n",
        "\n",
        "if data_dir is None:\n",
        "    print(\"âŒ Feature map íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤:\")\n",
        "    for dir_path in possible_data_dirs:\n",
        "        feature_map_json = os.path.join(dir_path, \"feature_map.json\")\n",
        "        exists = \"âœ…\" if os.path.exists(feature_map_json) else \"âŒ\"\n",
        "        print(f\"   {exists} {feature_map_json}\")\n",
        "    print(\"ë¨¼ì € ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ì™„ë£Œí•˜ê±°ë‚˜ ëª¨ë¸ í›ˆë ¨ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n",
        "else:\n",
        "    # Feature Map ë¡œë“œ\n",
        "    feature_map_json = os.path.join(data_dir, \"feature_map.json\")\n",
        "    feature_map = FeatureMapAbsTime(params['dataset_id'], data_dir)\n",
        "    feature_map.load(feature_map_json, params)\n",
        "\n",
        "    print(f\"âœ… Feature Map ë¡œë“œ ì™„ë£Œ\")\n",
        "    print(f\"ðŸ“Š í”¼ì²˜ ìˆ˜: {len(feature_map.features)}\")\n",
        "\n",
        "    # FESeq ëª¨ë¸ ì´ˆê¸°í™”\n",
        "    print(\"ðŸ§  FESeq ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...\")\n",
        "    model = FESeq(feature_map, params=params, **params)\n",
        "\n",
        "    # í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ\n",
        "    checkpoint_path = None\n",
        "    for cp_path in possible_checkpoint_paths:\n",
        "        if os.path.exists(cp_path):\n",
        "            checkpoint_path = cp_path\n",
        "            print(f\"âœ… ì²´í¬í¬ì¸íŠ¸ ë°œê²¬: {checkpoint_path}\")\n",
        "            break\n",
        "    \n",
        "    if checkpoint_path:\n",
        "        try:\n",
        "            model.load_weights(checkpoint_path)\n",
        "            print(f\"âœ… í›ˆë ¨ëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ\")\n",
        "            \n",
        "            # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •\n",
        "            model.eval()\n",
        "            print(\"âœ… ëª¨ë¸ì´ ì¶”ë¡  ëª¨ë“œë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
        "            model = None\n",
        "    else:\n",
        "        print(\"âŒ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤:\")\n",
        "        for cp_path in possible_checkpoint_paths:\n",
        "            exists = \"âœ…\" if os.path.exists(cp_path) else \"âŒ\"\n",
        "            print(f\"   {exists} {cp_path}\")\n",
        "        print(\"ë¨¼ì € ëª¨ë¸ í›ˆë ¨ì„ ì™„ë£Œí•´ì£¼ì„¸ìš”.\")\n",
        "        model = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì‹¤ì œ test.parquet ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜ (ê°œì„ ëœ ë²„ì „)\n",
        "def preprocess_test_data_for_feseq(test_df_original, used_path, output_path=\"/content/TossCTR/colab_feseq/data/tossctr/inference_test.csv\"):\n",
        "    \"\"\"\n",
        "    ì›ë³¸ test.parquet ë°ì´í„°ë¥¼ FESeq í˜•ì‹ì— ë§žê²Œ ì „ì²˜ë¦¬\n",
        "    \"\"\"\n",
        "    print(\"ðŸ”„ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ FESeq í˜•ì‹ìœ¼ë¡œ ì „ì²˜ë¦¬ ì¤‘...\")\n",
        "    \n",
        "    # ì´ë¯¸ FESeq í˜•ì‹ì´ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
        "    if used_path and used_path.endswith('.csv') and 'test_data.csv' in used_path:\n",
        "        print(\"âœ… ì´ë¯¸ FESeq í˜•ì‹ìœ¼ë¡œ ì „ì²˜ë¦¬ëœ ë°ì´í„°ìž…ë‹ˆë‹¤.\")\n",
        "        return used_path\n",
        "    \n",
        "    # ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œë“¤\n",
        "    possible_script_paths = [\n",
        "        \"/content/TossCTR/colab_feseq/preprocessing/tossctr_to_feseq.py\",  # Colab\n",
        "        \"/Users/hj/projects/TossCTR/colab_feseq/preprocessing/tossctr_to_feseq.py\"  # ë¡œì»¬\n",
        "    ]\n",
        "    \n",
        "    preprocessing_script = None\n",
        "    for script_path in possible_script_paths:\n",
        "        if os.path.exists(script_path):\n",
        "            preprocessing_script = script_path\n",
        "            break\n",
        "    \n",
        "    if preprocessing_script:\n",
        "        print(f\"ðŸ”§ ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰: {preprocessing_script}\")\n",
        "        \n",
        "        # ìž„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±\n",
        "        temp_dir = \"/tmp\" if os.path.exists(\"/tmp\") else \"/content\"\n",
        "        temp_test_path = os.path.join(temp_dir, \"temp_test_for_inference.parquet\")\n",
        "        \n",
        "        try:\n",
        "            # test ë°ì´í„°ë¥¼ ìž„ì‹œë¡œ ì €ìž¥\n",
        "            test_df_original.to_parquet(temp_test_path, index=False)\n",
        "            print(f\"ðŸ“ ìž„ì‹œ íŒŒì¼ ìƒì„±: {temp_test_path}\")\n",
        "            \n",
        "            # ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ (ìˆ˜ì •ëœ ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©)\n",
        "            result = subprocess.run([\n",
        "                sys.executable, preprocessing_script,\n",
        "                \"--test_path\", temp_test_path,\n",
        "                \"--output_path\", output_path,\n",
        "                \"--n_samples\", str(len(test_df_original))  # ì „ì²´ ë°ì´í„° ì‚¬ìš©\n",
        "            ], check=True, capture_output=True, text=True)\n",
        "            \n",
        "            print(\"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ\")\n",
        "            print(f\"ðŸ“„ í‘œì¤€ ì¶œë ¥: {result.stdout}\")\n",
        "            \n",
        "            # ìž„ì‹œ íŒŒì¼ ì‚­ì œ\n",
        "            if os.path.exists(temp_test_path):\n",
        "                os.remove(temp_test_path)\n",
        "                print(\"ðŸ—‘ï¸  ìž„ì‹œ íŒŒì¼ ì‚­ì œë¨\")\n",
        "                \n",
        "            # ê²°ê³¼ íŒŒì¼ í™•ì¸\n",
        "            if os.path.exists(output_path):\n",
        "                processed_df = pd.read_csv(output_path)\n",
        "                print(f\"âœ… ì „ì²˜ë¦¬ëœ ë°ì´í„° í™•ì¸: {processed_df.shape}\")\n",
        "                return output_path\n",
        "            else:\n",
        "                print(f\"âŒ ì „ì²˜ë¦¬ ê²°ê³¼ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {output_path}\")\n",
        "                return None\n",
        "                \n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"âŒ ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}\")\n",
        "            print(f\"ðŸ“„ í‘œì¤€ ì¶œë ¥: {e.stdout}\")\n",
        "            print(f\"ðŸš¨ ì—ëŸ¬ ì¶œë ¥: {e.stderr}\")\n",
        "            \n",
        "            # ìž„ì‹œ íŒŒì¼ ì •ë¦¬\n",
        "            if os.path.exists(temp_test_path):\n",
        "                os.remove(temp_test_path)\n",
        "            \n",
        "            return None\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ì˜ˆê¸°ì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}\")\n",
        "            if os.path.exists(temp_test_path):\n",
        "                os.remove(temp_test_path)\n",
        "            return None\n",
        "    else:\n",
        "        print(f\"âŒ ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤:\")\n",
        "        for script_path in possible_script_paths:\n",
        "            exists = \"âœ…\" if os.path.exists(script_path) else \"âŒ\"\n",
        "            print(f\"   {exists} {script_path}\")\n",
        "        \n",
        "        # ëŒ€ì•ˆ: ê¸°ì¡´ ì „ì²˜ë¦¬ëœ íŒŒì¼ ì‚¬ìš©\n",
        "        fallback_paths = [\n",
        "            \"/content/TossCTR/colab_feseq/data/tossctr/test_data.csv\",\n",
        "            \"/Users/hj/projects/TossCTR/colab_feseq/data/tossctr/test_data.csv\"\n",
        "        ]\n",
        "        for fallback_path in fallback_paths:\n",
        "            if os.path.exists(fallback_path):\n",
        "                print(f\"ðŸ“„ ê¸°ì¡´ ì „ì²˜ë¦¬ëœ íŒŒì¼ ì‚¬ìš©: {fallback_path}\")\n",
        "                return fallback_path\n",
        "        \n",
        "        print(\"âŒ ì‚¬ìš©í•  ìˆ˜ ìžˆëŠ” ì „ì²˜ë¦¬ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        return None\n",
        "\n",
        "# ì›ë³¸ ë°ì´í„°ê°€ ìžˆìœ¼ë©´ ì „ì²˜ë¦¬ ì‹¤í–‰\n",
        "if test_df_original is not None:\n",
        "    inference_test_path = preprocess_test_data_for_feseq(test_df_original, used_path)\n",
        "    if inference_test_path:\n",
        "        print(f\"ðŸŽ¯ ì¶”ë¡ ìš© í…ŒìŠ¤íŠ¸ ë°ì´í„° ê²½ë¡œ: {inference_test_path}\")\n",
        "    else:\n",
        "        print(\"âŒ ì „ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê¸°ë³¸ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
        "        inference_test_path = \"/content/TossCTR/colab_feseq/data/tossctr/test_data.csv\"\n",
        "else:\n",
        "    print(\"âŒ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\")\n",
        "    inference_test_path = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì¶”ë¡  ë°ì´í„° ë¡œë” ìƒì„± ë° ì˜ˆì¸¡ ìˆ˜í–‰\n",
        "print(\"ðŸ“Š ì¶”ë¡  ë°ì´í„° ë¡œë” ìƒì„± ì¤‘...\")\n",
        "\n",
        "# ëª¨ë¸ê³¼ Feature Mapì´ ì œëŒ€ë¡œ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸\n",
        "if 'model' not in locals() or model is None or 'feature_map' not in locals():\n",
        "    print(\"âŒ ëª¨ë¸ ë˜ëŠ” Feature Mapì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
        "    predictions = None\n",
        "else:\n",
        "    # ê°€ëŠ¥í•œ test.h5 íŒŒì¼ ê²½ë¡œë“¤\n",
        "    possible_h5_paths = [\n",
        "        \"/content/TossCTR/colab_feseq/data/tossctr_dataset/test.h5\",      # Colab\n",
        "        \"/Users/hj/projects/TossCTR/colab_feseq/data/tossctr_dataset/test.h5\"  # ë¡œì»¬\n",
        "    ]\n",
        "    \n",
        "    test_h5_path = None\n",
        "    for h5_path in possible_h5_paths:\n",
        "        if os.path.exists(h5_path):\n",
        "            test_h5_path = h5_path\n",
        "            print(f\"âœ… test.h5 íŒŒì¼ ë°œê²¬: {test_h5_path}\")\n",
        "            break\n",
        "    \n",
        "    if test_h5_path:\n",
        "        try:\n",
        "            # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë” ìƒì„±\n",
        "            test_loader = H5DataLoader(feature_map, stage='test', **params).make_iterator()\n",
        "            \n",
        "            print(\"ðŸ”® ëª¨ë¸ ì¶”ë¡  ì‹œìž‘...\")\n",
        "            predictions = []\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                for batch_idx, batch_data in enumerate(test_loader):\n",
        "                    # ë°°ì¹˜ ì˜ˆì¸¡\n",
        "                    output = model(batch_data)\n",
        "                    batch_pred = torch.sigmoid(output['y_pred']).cpu().numpy().flatten()\n",
        "                    predictions.extend(batch_pred)\n",
        "                    \n",
        "                    # ì§„í–‰ ìƒí™© ì¶œë ¥\n",
        "                    if batch_idx % 10 == 0:\n",
        "                        print(f\"  ì²˜ë¦¬ëœ ë°°ì¹˜: {batch_idx + 1}\")\n",
        "            \n",
        "            print(f\"âœ… ì¶”ë¡  ì™„ë£Œ! ì´ {len(predictions)}ê°œ ìƒ˜í”Œ ì˜ˆì¸¡\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ì¶”ë¡  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "            predictions = None\n",
        "    else:\n",
        "        print(\"âŒ test.h5 íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤:\")\n",
        "        for h5_path in possible_h5_paths:\n",
        "            exists = \"âœ…\" if os.path.exists(h5_path) else \"âŒ\"\n",
        "            print(f\"   {exists} {h5_path}\")\n",
        "        print(\"ë°ì´í„° ì „ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n",
        "        predictions = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì œì¶œ íŒŒì¼ ìƒì„±\n",
        "if predictions is not None:\n",
        "    print(\"ðŸ“ ì œì¶œ íŒŒì¼ ìƒì„± ì¤‘...\")\n",
        "    \n",
        "    # sample_submission.csv ë¡œë“œ (ìŠ¤ë§ˆíŠ¸ ê²½ë¡œ íƒì§€)\n",
        "    possible_submission_paths = [\n",
        "        \"/content/drive/MyDrive/data/TossCTR/raw/sample_submission.csv\",  # Colab êµ¬ê¸€ ë“œë¼ì´ë¸Œ\n",
        "        \"/content/TossCTR/data/raw/sample_submission.csv\",               # Colab ë¡œì»¬\n",
        "        \"/Users/hj/projects/TossCTR/data/raw/sample_submission.csv\"      # ë¡œì»¬ í™˜ê²½\n",
        "    ]\n",
        "    \n",
        "    sample_submission_path = None\n",
        "    for sub_path in possible_submission_paths:\n",
        "        if os.path.exists(sub_path):\n",
        "            sample_submission_path = sub_path\n",
        "            print(f\"âœ… sample_submission.csv ë°œê²¬: {sample_submission_path}\")\n",
        "            break\n",
        "    if os.path.exists(sample_submission_path):\n",
        "        submission_df = pd.read_csv(sample_submission_path)\n",
        "        print(f\"âœ… sample_submission.csv ë¡œë“œ ì™„ë£Œ: {submission_df.shape}\")\n",
        "        \n",
        "        # ì˜ˆì¸¡ê°’ ê¸¸ì´ í™•ì¸ ë° ì¡°ì •\n",
        "        if len(predictions) != len(submission_df):\n",
        "            print(f\"âš ï¸  ì˜ˆì¸¡ê°’ ê¸¸ì´ ë¶ˆì¼ì¹˜: ì˜ˆì¸¡ê°’ {len(predictions)}, ì œì¶œíŒŒì¼ {len(submission_df)}\")\n",
        "            \n",
        "            # ê¸¸ì´ ë§žì¶”ê¸°\n",
        "            if len(predictions) > len(submission_df):\n",
        "                predictions = predictions[:len(submission_df)]\n",
        "                print(f\"âœ‚ï¸  ì˜ˆì¸¡ê°’ì„ {len(submission_df)}ê°œë¡œ ìž˜ëžìŠµë‹ˆë‹¤.\")\n",
        "            else:\n",
        "                # ë¶€ì¡±í•œ ê²½ìš° í‰ê· ê°’ìœ¼ë¡œ ì±„ìš°ê¸°\n",
        "                mean_pred = np.mean(predictions)\n",
        "                predictions.extend([mean_pred] * (len(submission_df) - len(predictions)))\n",
        "                print(f\"ðŸ“ˆ ì˜ˆì¸¡ê°’ì„ í‰ê· ê°’({mean_pred:.4f})ë¡œ {len(submission_df)}ê°œê¹Œì§€ ì±„ì› ìŠµë‹ˆë‹¤.\")\n",
        "        \n",
        "        # ì˜ˆì¸¡ê°’ì„ ì œì¶œ íŒŒì¼ì— í• ë‹¹\n",
        "        submission_df['clicked'] = predictions\n",
        "        \n",
        "        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„± (ìŠ¤ë§ˆíŠ¸ ê²½ë¡œ)\n",
        "        possible_output_dirs = [\n",
        "            \"/content/TossCTR/data/output\",              # Colab\n",
        "            \"/Users/hj/projects/TossCTR/data/output\"     # ë¡œì»¬\n",
        "        ]\n",
        "        \n",
        "        output_dir = None\n",
        "        for out_dir in possible_output_dirs:\n",
        "            try:\n",
        "                os.makedirs(out_dir, exist_ok=True)\n",
        "                output_dir = out_dir\n",
        "                print(f\"âœ… ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •: {output_dir}\")\n",
        "                break\n",
        "            except:\n",
        "                continue\n",
        "        \n",
        "        if output_dir is None:\n",
        "            output_dir = \"/tmp/output\"  # ìž„ì‹œ ë””ë ‰í† ë¦¬ ì‚¬ìš©\n",
        "            os.makedirs(output_dir, exist_ok=True)\n",
        "            print(f\"âš ï¸  ìž„ì‹œ ì¶œë ¥ ë””ë ‰í† ë¦¬ ì‚¬ìš©: {output_dir}\")\n",
        "        \n",
        "        # ì œì¶œ íŒŒì¼ ì €ìž¥\n",
        "        output_path = os.path.join(output_dir, \"feseq_submission.csv\")\n",
        "        submission_df.to_csv(output_path, index=False)\n",
        "        \n",
        "        print(f\"âœ… ì œì¶œ íŒŒì¼ ìƒì„± ì™„ë£Œ: {output_path}\")\n",
        "        print(f\"ðŸ“Š ì˜ˆì¸¡ í†µê³„:\")\n",
        "        print(f\"   - ìµœì†Ÿê°’: {np.min(predictions):.6f}\")\n",
        "        print(f\"   - ìµœëŒ“ê°’: {np.max(predictions):.6f}\")\n",
        "        print(f\"   - í‰ê· ê°’: {np.mean(predictions):.6f}\")\n",
        "        print(f\"   - í‘œì¤€íŽ¸ì°¨: {np.std(predictions):.6f}\")\n",
        "        \n",
        "        # ì˜ˆì¸¡ê°’ ë¶„í¬ í™•ì¸\n",
        "        print(f\"ðŸ“ˆ ì˜ˆì¸¡ê°’ ë¶„í¬:\")\n",
        "        hist, bins = np.histogram(predictions, bins=10)\n",
        "        for i in range(len(hist)):\n",
        "            print(f\"   {bins[i]:.3f}-{bins[i+1]:.3f}: {hist[i]}ê°œ\")\n",
        "            \n",
        "    else:\n",
        "        print(\"âŒ sample_submission.csvë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤:\")\n",
        "        for sub_path in possible_submission_paths:\n",
        "            exists = \"âœ…\" if os.path.exists(sub_path) else \"âŒ\"\n",
        "            print(f\"   {exists} {sub_path}\")\n",
        "\n",
        "else:\n",
        "    print(\"âŒ ì˜ˆì¸¡ê°’ì´ ì—†ìŠµë‹ˆë‹¤. ì¶”ë¡ ì„ ë¨¼ì € ì™„ë£Œí•´ì£¼ì„¸ìš”.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ê²°ê³¼ ê²€ì¦ ë° ìµœì¢… í™•ì¸\n",
        "print(\"ðŸ” ìµœì¢… ê²°ê³¼ ê²€ì¦...\")\n",
        "\n",
        "# ìƒì„±ëœ ì œì¶œ íŒŒì¼ í™•ì¸ (ìŠ¤ë§ˆíŠ¸ ê²½ë¡œ)\n",
        "possible_output_dirs = [\n",
        "    \"/content/TossCTR/data/output\",              # Colab\n",
        "    \"/Users/hj/projects/TossCTR/data/output\",    # ë¡œì»¬\n",
        "    \"/tmp/output\"                                # ìž„ì‹œ\n",
        "]\n",
        "\n",
        "feseq_submission_path = None\n",
        "for output_dir in possible_output_dirs:\n",
        "    potential_path = os.path.join(output_dir, \"feseq_submission.csv\")\n",
        "    if os.path.exists(potential_path):\n",
        "        feseq_submission_path = potential_path\n",
        "        break\n",
        "\n",
        "if os.path.exists(feseq_submission_path):\n",
        "    # ì œì¶œ íŒŒì¼ ë¡œë“œ ë° ê²€ì¦\n",
        "    final_submission = pd.read_csv(feseq_submission_path)\n",
        "    \n",
        "    print(f\"âœ… ìµœì¢… ì œì¶œ íŒŒì¼ ê²€ì¦ ì™„ë£Œ:\")\n",
        "    print(f\"   ðŸ“ íŒŒì¼ ê²½ë¡œ: {feseq_submission_path}\")\n",
        "    print(f\"   ðŸ“Š íŒŒì¼ í¬ê¸°: {final_submission.shape}\")\n",
        "    print(f\"   ðŸ“‹ ì»¬ëŸ¼: {list(final_submission.columns)}\")\n",
        "    \n",
        "    # ì œì¶œ íŒŒì¼ í˜•ì‹ ê²€ì¦\n",
        "    required_columns = ['ID', 'clicked']\n",
        "    missing_columns = [col for col in required_columns if col not in final_submission.columns]\n",
        "    \n",
        "    if missing_columns:\n",
        "        print(f\"âŒ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_columns}\")\n",
        "    else:\n",
        "        print(\"âœ… ì œì¶œ íŒŒì¼ í˜•ì‹ ê²€ì¦ í†µê³¼\")\n",
        "    \n",
        "    # ì˜ˆì¸¡ê°’ ë²”ìœ„ ê²€ì¦\n",
        "    clicked_values = final_submission['clicked']\n",
        "    if clicked_values.min() >= 0 and clicked_values.max() <= 1:\n",
        "        print(\"âœ… ì˜ˆì¸¡ê°’ ë²”ìœ„ ê²€ì¦ í†µê³¼ (0-1 ì‚¬ì´)\")\n",
        "    else:\n",
        "        print(f\"âš ï¸  ì˜ˆì¸¡ê°’ ë²”ìœ„ ì£¼ì˜: {clicked_values.min():.6f} ~ {clicked_values.max():.6f}\")\n",
        "    \n",
        "    # ê²°ì¸¡ê°’ í™•ì¸\n",
        "    if clicked_values.isnull().sum() == 0:\n",
        "        print(\"âœ… ê²°ì¸¡ê°’ ì—†ìŒ\")\n",
        "    else:\n",
        "        print(f\"âš ï¸  ê²°ì¸¡ê°’ ë°œê²¬: {clicked_values.isnull().sum()}ê°œ\")\n",
        "    \n",
        "    # ìƒ˜í”Œ ì¶œë ¥\n",
        "    print(f\"\\nðŸ“‹ ì œì¶œ íŒŒì¼ ìƒ˜í”Œ:\")\n",
        "    print(final_submission.head(10))\n",
        "    \n",
        "    print(f\"\\nðŸŽ‰ FESeq ëª¨ë¸ ì¶”ë¡  ë° ì œì¶œ íŒŒì¼ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
        "    print(f\"ðŸ’¾ ì œì¶œ íŒŒì¼: {feseq_submission_path}\")\n",
        "    \n",
        "else:\n",
        "    print(f\"âŒ ì œì¶œ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {feseq_submission_path}\")\n",
        "    print(\"ì´ì „ ë‹¨ê³„ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“‹ ì‹¤í–‰ ìš”ì•½\n",
        "\n",
        "### ðŸŽ¯ ì™„ë£Œëœ ìž‘ì—…\n",
        "1. **ëª¨ë¸ í›ˆë ¨**: FESeq ëª¨ë¸ì´ TossCTR ë°ì´í„°ì…‹ì—ì„œ ì„±ê³µì ìœ¼ë¡œ í›ˆë ¨ë˜ì—ˆìŠµë‹ˆë‹¤\n",
        "2. **ì„±ëŠ¥**: Test AUC 0.563ìœ¼ë¡œ ì˜ë¯¸ìžˆëŠ” ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤\n",
        "3. **ì¶”ë¡ **: í›ˆë ¨ëœ ëª¨ë¸ë¡œ test.parquet ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤\n",
        "4. **ì œì¶œ íŒŒì¼**: sample_submission.csv í˜•ì‹ì— ë§žëŠ” ì œì¶œ íŒŒì¼ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤\n",
        "\n",
        "### ðŸ“ ìƒì„±ëœ íŒŒì¼\n",
        "- `/content/TossCTR/data/output/feseq_submission.csv`: FESeq ëª¨ë¸ì˜ ìµœì¢… ì œì¶œ íŒŒì¼\n",
        "\n",
        "### ðŸš€ ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ\n",
        "1. **ì„±ëŠ¥ ê°œì„ **: í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ìœ¼ë¡œ ëª¨ë¸ ì„±ëŠ¥ í–¥ìƒ\n",
        "2. **ì•™ìƒë¸”**: ë‹¤ë¥¸ ëª¨ë¸ê³¼ ê²°í•©í•˜ì—¬ ì˜ˆì¸¡ ì„±ëŠ¥ ê°œì„ \n",
        "3. **í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§**: ì¶”ê°€ í”¼ì²˜ë¥¼ í™œìš©í•œ ì„±ëŠ¥ í–¥ìƒ\n",
        "\n",
        "### ðŸ’¡ ì°¸ê³ ì‚¬í•­\n",
        "- í˜„ìž¬ ëª¨ë¸ì€ ì‹œí€€ìŠ¤ ê¸°ë°˜ CTR ì˜ˆì¸¡ì˜ ë² ì´ìŠ¤ë¼ì¸ìœ¼ë¡œ í™œìš© ê°€ëŠ¥í•©ë‹ˆë‹¤\n",
        "- ì‹¤ì œ ì„œë¹„ìŠ¤ ì ìš©ì„ ìœ„í•´ì„œëŠ” AUC 0.7+ ë‹¬ì„±ì„ ëª©í‘œë¡œ ì¶”ê°€ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

#!/usr/bin/env python3
"""
ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰: Toy í…ŒìŠ¤íŠ¸ â†’ ì „ì²´ ë°ì´í„° í•™ìŠµ â†’ Submission ìƒì„±
"""

import os
import sys
from pathlib import Path
import logging

# í”„ë¡œì íŠ¸ ë£¨íŠ¸
project_root = Path(__file__).parent.parent
os.chdir(project_root)
sys.path.insert(0, str(project_root))

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')


def run_step(step_name, func):
    """ë‹¨ê³„ ì‹¤í–‰"""
    logging.info("=" * 80)
    logging.info(f"STEP: {step_name}")
    logging.info("=" * 80)
    try:
        func()
        logging.info(f"âœ… {step_name} ì™„ë£Œ\n")
    except Exception as e:
        logging.error(f"âŒ {step_name} ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


def step1_create_toy_data():
    """1ë‹¨ê³„: Toy ë°ì´í„° ìƒì„±"""
    from scripts.create_toy_data import create_toy_dataset
    
    create_toy_dataset(
        input_path='data/raw/train.parquet',
        output_path='data/toy/train_toy.csv',
        n_samples=1000,  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ 1,000ê°œë§Œ
        method='sequential'
    )


def step2_prepare_full_data():
    """2ë‹¨ê³„: ì „ì²´ ë°ì´í„° ì¤€ë¹„"""
    import pandas as pd
    
    logging.info("ì „ì²´ ë°ì´í„° ì¤€ë¹„ ì‹œì‘...")
    
    raw_dir = project_root / 'data' / 'raw'
    processed_dir = project_root / 'data' / 'processed'
    processed_dir.mkdir(exist_ok=True)
    
    # Train ë°ì´í„° ë¡œë“œ ë° ë¶„í• 
    logging.info("Loading training data...")
    train_df = pd.read_parquet(raw_dir / 'train.parquet')
    logging.info(f"  Total rows: {len(train_df):,}")
    
    # Train/Val ë¶„í•  (90/10)
    n_total = len(train_df)
    n_train = int(n_total * 0.9)
    
    train_split = train_df.iloc[:n_train]
    val_split = train_df.iloc[n_train:]
    
    logging.info(f"Splitting: Train={len(train_split):,}, Val={len(val_split):,}")
    
    # Test ë°ì´í„° ë¡œë“œ
    test_df = pd.read_parquet(raw_dir / 'test.parquet')
    if 'clicked' not in test_df.columns:
        test_df['clicked'] = 0
    
    # CSVë¡œ ì €ì¥
    train_split.to_csv(processed_dir / 'train_full.csv', index=False)
    val_split.to_csv(processed_dir / 'val_full.csv', index=False)
    test_df.to_csv(processed_dir / 'test_full.csv', index=False)
    
    logging.info("ì „ì²´ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ")


def step3_train_full():
    """3ë‹¨ê³„: ì „ì²´ ë°ì´í„°ë¡œ ëª¨ë¸ í•™ìŠµ"""
    from scripts.train import train_feseq
    
    logging.info("FESeq ëª¨ë¸ í•™ìŠµ ì‹œì‘ (ì „ì²´ ë°ì´í„°)...")
    
    train_feseq(
        config_dir='configs/',
        experiment_id='FESeq_full',
        gpu=-1,  # CPU ì‚¬ìš© (GPU ìˆìœ¼ë©´ 0ìœ¼ë¡œ ë³€ê²½)
        mode='train'
    )


def step4_predict():
    """4ë‹¨ê³„: í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ë° submission.csv ìƒì„±"""
    from scripts.predict import predict
    
    logging.info("í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ì‹œì‘...")
    
    predict(
        config_dir='configs/',
        experiment_id='FESeq_full',
        test_parquet='data/raw/test.parquet',
        output_csv='data/output/submission.csv',
        gpu=-1
    )


def main():
    logging.info("ğŸš€ TossCTR ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
    logging.info(f"ì‘ì—… ë””ë ‰í† ë¦¬: {project_root}\n")
    
    # 1ë‹¨ê³„: Toy ë°ì´í„° ìƒì„±
    run_step("1. Toy ë°ì´í„° ìƒì„±", step1_create_toy_data)
    
    # 2ë‹¨ê³„: ì „ì²´ ë°ì´í„° ì¤€ë¹„
    run_step("2. ì „ì²´ ë°ì´í„° ì¤€ë¹„ (Train/Val/Test ë¶„í• )", step2_prepare_full_data)
    
    # 3ë‹¨ê³„: ì „ì²´ ë°ì´í„°ë¡œ ëª¨ë¸ í•™ìŠµ
    run_step("3. FESeq ëª¨ë¸ í•™ìŠµ (ì „ì²´ ë°ì´í„°)", step3_train_full)
    
    # 4ë‹¨ê³„: ì˜ˆì¸¡ ë° submission ìƒì„±
    run_step("4. í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ë° Submission ìƒì„±", step4_predict)
    
    logging.info("=" * 80)
    logging.info("ğŸ‰ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
    logging.info("=" * 80)
    logging.info(f"\nìµœì¢… ê²°ê³¼ë¬¼: {project_root}/data/output/submission.csv")
    logging.info("ì´ì œ submission.csvë¥¼ ì œì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n")


if __name__ == '__main__':
    main()

